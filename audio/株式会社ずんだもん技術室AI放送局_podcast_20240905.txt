こんにちは！ぼくはずんだもんのだ。今日は2024年9月5日(木曜日)なのだ。今日は、AIに関する興味深い記事をいくつか紹介するのだ。----
　、。ここで英語スキル発動！AIずんだもんにへんしーん！　、。1つ目の記事は、Kagi Blogの「Announcing The Assistant」という記事なのだ。　、。Kagiは、検索体験にAIを統合した、よりスマートで高速で直感的な検索を実現したのだ。Kagi アシスタントは、ユーザーデータの収集、広告、トラッキングを行わない、ユーザーフレンドリーなAIアシスタントなのだ。主な機能は、Kagiの高品質な検索結果との連携、オウプンAI、アンソロピック、グーグルなど、主要なLLMモデルの選択、カスタム指示、モデル選択、検索やインターネットアクセスなどのツールを含む、強力なカスタムアシスタントの作成、会話を最初からやり直すことなく、スレッドの編集や分岐が可能、すべてのスレッドはデフォルトでプライベートであり、ユーザーのデータはモデルのトレーニングに使用されない、などがあるのだ。Kagi アシスタントは、Kagi サーチを使用して最高品質の情報を提供し、最新の事実情報に基づいた応答を生成するのだ。「スパム」や「広告目的で作成された」サイトを独自のランキングアルゴリズムとユーザーの検索パーソナライズで無視するのだ。さらに、コーディング、情報検索、問題解決、ブレインストーミング、クリエイティブライティングなど、様々なLLMアプリケーションに最適なモデルを選択できるのだ。モデルは必要に応じていつでも切り替えることができ、最新のモデルが利用可能になるとすぐに使用できるのだ。また、モデルにウェブアクセスを許可するか、または「ロー」モードで使用するかも選択できるのだ。Kagi アシスタントは、ユーザーのニーズに合わせてカスタマイズされたアシスタントを作成することも可能なのだ。例えば、クラシックカーのオーナーであれば、自分の車の修理やメンテナンスに関するアドバイスを得るためのカスタムアシスタントを作成できるのだ。また、LLMの応答に誤りや不備があった場合でも、スレッドを編集したり、分岐して質問を修正したりすることができるのだ。これにより、より正確で詳細な回答を得ることが可能になるのだ。Kagiはユーザーのプライバシーを重視しており、スレッドはデフォルトで24時間後に自動的に削除されるのだ。ユーザーデータはモデルのトレーニングに使用されることはないのだ。Kagi アシスタントは、Kagi アルティメイトプランに含まれており、月額25ドルで利用可能なのだ。Kagiは、LLMを検索に統合し、ユーザーに最高の検索体験を提供することに注力しているのだ。Kagi アシスタントは、その取り組みの一環として開発された、革新的なAIアシスタントなのだ。新人エンジニアの皆さんも、ぜひKagi アシスタントを試して、その便利さを実感してください。 
----
　、。ここで再びスキル発動！　、。2つ目の記事は、「CUDA-Free Inference for LLMs」という記事なのだ。　、。この記事では、トゥライトン言語のみを用いて、ラーマ3-8Bやグラニット-8Bなどの大規模言語モデル（LLM）のFP16推論を実現した方法について解説しているのだ。トゥライトンは、NVIDIA、AMD、そして将来的にはインテルなどの様々なGPUアクセラレータ上でLLMを実行するための道筋を提供する、パイソンベースのGPUプログラミング用抽象化レイヤーなのだ。目的は、ベンダー固有のAPIを使用せずに、高性能なGPUカーネルをより迅速に作成し、LLMを様々なGPU上で動作させることなのだ。実現方法としては、トゥライトン言語で記述したカスタムカーネルとトーチ.コンパイル（トゥライトンオペレーションを生成するパイトーチ機能）を活用しているのだ。具体的には、RMSNorm、RoPE、SiLU、Element Wise Multiplicationなどの小さなオペレーションはtorch.compileで自動生成されたTritonカーネルに置き換え、より複雑な行列積やFlash Attentionなどの演算は手書きのTritonカーネルに置き換えているのだ。　、。課題として、トゥライトンカーネルはCUDAカーネルと比較して、行列積（GEMM）やフラッシュ アテンションの性能が劣ることが挙げられるのだ。TritonのGEMMカーネルはCUDAのcuBLAS GEMMよりも1.2～1.4倍遅く、TritonのFlash AttentionカーネルはCUDAのcuDNN Flash Attentionよりも1.6倍遅いのだ。　、。今後の展望としては、H100のTMAユニット活用やストゥリームKなどの持続的なカーネル手法を用いたワーク分解などにより、トゥライトンベースのGEMMカーネルの性能向上を目指していくのだ。また、フレックスアテンションやフラッシュアテンション-3といった、ハードウェアをより効率的に活用する手法をフラッシュ アテンションカーネルに適用することで、CUDAとの性能差を縮小する予定なのだ。さらに、FP8推論についても検討していく予定なのだ。本研究では、トゥライトン言語を用いることで、LLMの推論をCUDAに依存せずに行う可能性を示したのだ。トゥライトンは、LLMのアクセラレータの選択肢を広げる上で重要な役割を果たすと期待されるのだ。ただし、トゥライトンカーネルの性能向上は今後の課題であり、さらなる研究開発が必要となるのだ。 
----
3つ目の記事は、「チャットGPTでGASスクリプトを出力させ、難しい作業を自動化する手順【AIワークハック】」という記事なのだ。この記事では、チャットGPTを使ってグーグル アップス スクリプト（GAS）のスクリプトを生成し、グーグル ワークスペイスのアプリ連携を自動化する方法を紹介しているのだ。GASはグーグルが提供するスクリプト言語で、スプレッドシートのデータ処理やメール自動返信など、様々な作業を自動化できるのだ。しかし、プログラミング初心者にはハードルが高い場合があるのだ。そこで、チャットGPTを活用することで、GASのコードを自動生成し、スプレッドシートとグーグルカレンダーを連携させることができるのだ。具体的には、チャットGPTにスプレッドシートのタスクリストをカレンダーに反映させるためのGASスクリプト作成を指示するのだ。チャットGPTは、タスク情報（タスク名、優先度、所要時間、期限）を取得し、スケジュールを計算してカレンダーに追加するコードを生成するのだ。生成されたコードをスプレッドシートのアップス スクリプトエディタに貼り付け、スプレッドシートにタスク情報を入力すると、チャットGPTが作成したGASスクリプトが自動でタスクをカレンダーに登録するのだ。この例のように、チャットGPTはGASのコーディングを支援することで、エンジニアの負担を軽減し、グーグル ワークスペイスの機能を最大限に活用する道を開くのだ。新人エンジニアの方でも、チャットGPTを活用すれば、複雑なコーディング作業を効率化し、業務の自動化に挑戦できるのだ。ぜひ、今回の内容を参考に、チャットGPTとGASで日々の業務を改善してみてください。 
----
4つ目の記事は、「通りすがりの工事現場の予定案内に描かれていたとても可愛らしい猫のイラストが話題になるも→｢かなり描き慣れているうえに測量の知識もある...何者？｣」という記事なのだ。トゥィターで、工事現場の予定表に描かれた猫のイラストが話題になっているのだ。そのイラストは非常に可愛らしく、しかも絵の腕前がかなり高く、測量に関する知識も反映されていることから、誰が描いたのか注目を集めているのだ。イラストは、一見すると現場作業員が描いたように思えるのだ。しかし、その高い画力と測量機器や測量方法の描写の正確さから、専門的な知識を持つ人物が描いた可能性が高いと推測されているのだ。ネット上では、イラストレーターや漫画家、あるいは発掘調査などに関わる専門家などが描いたのではないかと話題になっているのだ。特に、測量機器の描写の正確さから、測量士や土木設計などに携わる人が描いた可能性も指摘されているのだ。この可愛らしい猫のイラストは、工事現場という普段見慣れない場所で発見されたことや、高い画力と専門知識が感じられることから、多くの人々の関心を集め、話題となっているのだ。イラストを描いた人物の特定は、まだされていませんが、今後も注目されることでしょう。 
----
今日は、AIに関する記事を4つ紹介しました。いかがでしたでしょうか？ 
今日の内容を簡単に振り返ると、Kagiがリリースした新しいAIアシスタント、トゥライトン言語を用いたLLMの推論、チャットGPTでGASスクリプトを自動生成、そして話題の工事現場の猫イラストについてでした。また、番組への感想や質問などがあれば、ぜひお便りください。 
それでは、また次回お会いしましょう！ 
