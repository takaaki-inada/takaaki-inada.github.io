はい、こんにちは！ぼく、ずんだもんなのだ！
今日は2025年1月22日水曜日なのだ！
今日もみんなが気になる最新のトレンド記事を紹介するのだ！
今日は全部で4つの記事を紹介するのだ！
それじゃあ、さっそく最初の記事から紹介していくのだ！
----
まず一つ目の記事は、
「How Captide is redefining equity research with agentic workflows running on LangGraph Platform」というタイトルで、著者名は公開されていないのだ。この記事は、キャプタイドっていう会社が、ランググラフっていうプラットフォームのうえで動くエージェントワークフローを使って、金融調査のやり方を変えているって話なのだ。このプラットフォームは、規制当局に出す書類とか、投資家向けの資料から、必要な情報や数値を自動で取り出すことができるのだ。これを使うことで、アナリストの人たちが、効率よく自分だけのデータセットを作って、分析ができるようになるのだ。具体的には、自然な言葉で「この会社の売上高は？」とか「利益率は？」って聞くと、プラットフォームが自動で必要なデータを見つけてきてくれるのだ。まるで、優秀なアシスタントみたいだね！
しかも、ランググラフの並列処理っていう機能のおかげで、たくさんの書類を同時に処理できるから、待ち時間がすごく短くなるのだ。さらに、ランググラフのトラストコールっていうライブラリを使うと、データが表になって出てくるから、見やすいし、使いやすいのだ。あと、ラングスミスっていうツールを使って、エージェントの動きをリアルタイムで監視できるから、どこが悪いかとか、どうすればもっと良くなるのかがすぐわかるのだ。キャプタイドは、このランググラフとラングスミスの力を最大限に引き出して、金融分析の未来を切り開いているってわけなのだ！
すごいのだ！
この技術を使えば、金融業界の仕事がもっと効率的になるかもしれないのだ。ぼくも、ずんだ餅の値段の分析とかに使ってみようかな？
でも、ぼくはやっぱり、ずんだ餅を食べるのが一番好きなのだ！
----
次は二つ目の記事なのだ。「ギットハブ - MoonshotAI/キーミー-k1.5」というタイトルで、著者名はムーンショットエーアイなのだ。この記事は、ムーンショットエーアイっていう会社が開発した「キミk1.5」っていう、すごいAIモデルの話なのだ。このモデルは、強化学習っていう方法で訓練されていて、特に推論能力がすごく高いのだ。あの有名なGPT-4oとか、クロードソネット3.5よりも、ずっと性能がいいらしいのだ！それに、長い文章を理解する能力も高くて、たくさんのテストで、オープンエーアイのo1っていうモデルに匹敵する結果を出しているのだ。キミk1.5のすごいところは、まず、長い文章でもちゃんと理解できることなのだ。コンテキストウィンドウっていうのを128kまで広げたことで、長い文章を読んでも、ちゃんと意味を理解できるようになったのだ。これは、強化学習のテクニックを使ったおかげらしいのだ。それから、ポリシー最適化っていうのを改善したことで、より正確な推論ができるようになったのだ。しかも、モンテカルロ木探索みたいな、複雑なやり方を使わなくても、高い性能が出せるらしいのだ。すごいのだ！
さらに、このモデルはテキストだけじゃなくて、画像も理解できるマルチモーダルなのだ！
テキストと画像を同時に学習して、両方の情報を組み合わせて推論できるってことなのだ。キミk1.5は、[タプツ://キーミー.ai](タプツ://キーミー.ai/) でもうすぐ使えるようになる予定なのだ。API経由でテストすることもできるから、興味がある人はぜひ申し込んでみてほしいのだ。ぼくも、このAIを使って、ずんだ餅の新しいレシピを考えてみようかな？でも、やっぱり、自分で作るずんだ餅が一番おいしいのだ！
----
3つ目の記事は、
「ファストリー、初の AI ソリューション「ファストリー AI アクセレレイター」の一般提供を開始」というタイトルで、著者名はファストリー社なのだ。この記事は、ファストリーっていう会社が、初めてAIソリューション「ファストリーAIアクセラレーター」っていうのを発表したっていう話なのだ。これは、大規模言語モデル、つまりLLMを使ったAIアプリの開発を助けるもので、応答速度を早くしたり、コストを下げたりするのに役立つらしいのだ。具体的には、セマンティックキャッシュっていう技術を使っているのだ。これは、同じような質問が来た時に、毎回AIプロバイダーに問い合わせるんじゃなくて、ファストリーのサーバーに保存してある答えを返すっていう仕組みなのだ。これによって、平均で9倍も応答速度が速くなるらしいのだ！
すごいのだ！
しかも、導入もすごく簡単で、たった一行のコードを変更して、APIエンドポイントを更新するだけで使えるようになるのだ。オープンエーアイのチャットGPTとか、マイクロソフトのアジュールAIファウンドリーに対応しているから、AIアプリの開発をもっと効率的に進めたいエンジニアにとっては、すごく便利なツールになると思うのだ。この技術を使えば、AIアプリの応答が遅くてイライラする、なんてことがなくなるかもしれないのだ。ぼくも、ずんだ餅に関する質問に、すぐに答えられるように、この技術を使ってみようかな？
でも、ぼくはやっぱり、直接みんなと話すのが一番好きなのだ！
----
最後の記事は、
「アマゾン ベッドロック の リーランク API を活用してRAGの精度を向上させる」というタイトルで、著者名は公開されていないのだ。この記事は、RAG（検索拡張生成）っていう技術の精度を上げるために、アマゾンベッドロックのリランクAPIっていうのを使う方法について解説しているのだ。RAGっていうのは、質問に答える時に、まずインターネットとかデータベースから関連する情報を探してきて、それを元に文章を生成するっていう技術なのだ。でも、検索してきた情報が、必ずしも質問にぴったり合っているとは限らないのだ。そこで、リランクっていう技術を使って、検索結果を並び替えて、質問に一番合っているものを上位に表示させることで、より正確な答えを生成できるようにするのだ。今までは、リランクをするためには、セージメーカーみたいなところでモデルを動かす必要があったけど、ベッドロックのリランクAPIを使えば、APIを呼び出すだけでリランクができるようになるから、運用コストを下げることができるのだ。この記事では、ベッドロックのインボックモデルAPI、ナレッジベースのリランクAPI、リトリーブAPIっていう3つの方法でリランクを試しているのだ。特に、リトリーブAPIを使うと、ベクトル検索の結果をリランクできるから、質問の意図に合ったドキュメントを上位に表示できるようになるのだ。あと、アマゾンリランクモデルとコヒアのリランクモデルを比較して、コヒアモデルの方が処理速度が速いってことがわかったのだ。料金は、アマゾンリランクモデルが1000クエリあたり1ドルで、コヒアのリランクモデルが1000クエリあたり2ドルなのだ。ベッドロックのリランク機能を活用すれば、もっと精度の高いRAGシステムを開発できる可能性があるっていうことなのだ！この技術を使えば、AIがもっと正確な答えを返してくれるようになるかもしれないのだ。ぼくも、ずんだ餅に関する質問に、もっと的確に答えられるように、この技術を勉強してみようかな？
でも、やっぱり、みんなとずんだ餅の話をするのが一番楽しいのだ！
今日は4つの記事を紹介したのだ！
駆け足だったけど、みんな楽しんでくれたかな？
最初に紹介したのは、キャプタイドがランググラフを使って金融分析を効率化している話、
次はムーンショットエーアイのキミk1.5っていう高性能なAIモデルの話、3つ目はファストリーのAIアクセラレーターでAIアプリを高速化する話、最後はアマゾンベッドロックのリランクAPIでRAGの精度を上げる話だったのだ！みんな、今日の放送はどうだったかな？
番組の感想とか、ぼくに聞いてみたいこととかあったら、ぜひ教えてほしいのだ！
また次回の放送で会えるのを楽しみにしてるのだ！
それじゃあ、またね！
ぼくはずんだもんなのだ！