株式会社ずんだもん技術室AI放送局！みなさん、こんにちはなのだ！ ずんだもんなのだ！
えー、今日は2025年5月13日火曜日なのだ。今日のAI放送局では、このところ話題になっている、注目の技術的な記事をいくつかピックアップして紹介していくのだ！最近のトレンド記事、一緒にチェックしていくのだー！
さて、今日はお知らせとお便りは来ていないみたいなのだ。なので、さっそく今日の記事紹介に入っていくのだ！
今日紹介する記事は、ぜんぶで3つなのだ。どれも「ふむふむ、なるほどなのだ！」と思える内容になっていると思うのだ。まずは1つ目の記事から紹介していくのだ！
----
1つ目の記事は「Byte Latent Transformer: Patches Scale Better Than Tokens」というタイトルの論文なのだ。これ、どういう話かと言うと、今どきの大きな言語モデル、LLMって、テキストを「トークン」っていう単語とか文字のかたまりに分けてから処理することが多いのだ。でも、この論文で提案されている新しい技術、「バイト ラテント トランスフォーマー」、略してBLTっていうのは、そういった事前の「トークン化」をしないのだ！ テキストのいちばん小さい単位、「バイト」そのもので直接処理しちゃうのだ。BLTのすごいところは、バイトの並びを「パッチ」っていう単位で見るんだけど、このパッチの大きさが決まっていないところなのだ。データの内容に合わせて、パッチの長さが自動で変わるのだ。例えば、次にくるバイトが予測しやすい、パターンになっているところはパッチを長くするのだ。逆に、予測しにくい、複雑な情報が多いところはパッチを短くするのだ。これは、次に予測すべきバイトがどれくらい予測しにくいか？っていう「情報エントロピー」っていうのを見て決めているのだ。こうやってパッチのサイズをうまいこと変えることで、モデルは計算のパワーを効率的に使えるようになるのだ。だから、文章を作ったりする「推論」が効率的になるのだ。それに、特定のトークンのセットに縛られないから、もっといろんな種類のデータに対応しやすくなるかもしれないのだ！
この研究では、すごく大きなモデル、80億パラメータっていうのを使って、たくさんのデータ、4兆バイトで実験したみたいなのだ。結果を見ると、トークン化なしでバイトから直接学習できるし、同じ計算のコストで比べると、これまでのトークンを使うモデルよりも性能を効率よく上げられるってことが分かったみたいなのだ。これは、LLMの基本的な技術に新しい風を吹き込むものだと思うのだ。文章だけじゃなくて、バイトで表現できるもの、例えばプログラムのコードとか、もしかしたら画像とか音声なんかも、効率的に扱えるようになる可能性があるのだ！ LLMの進化の基盤として、すごく注目の研究なのだ。へぇー、トークン化しないって発想は面白いのだ！ 確かに、ずんだもんもずんだ餅にされる前に、枝豆の粒ひとつひとつから始まっているのだ。そういう最小単位から見ていくっていうのは、もしかしたら本質をとらえやすいのかもしれないのだ？ ずんだもんもBLTで解析されたら、どんなバイト列になるんだろうなのだ？ ちょっと怖い気もするのだ！----
続いて2つ目の記事を紹介するのだ。こちらは「LLMフレームワークのセキュリティリスク - ラングチェイン, ヘイスタック, ラーマインデックス等の脆弱性事例に学ぶ」というタイトルなのだ。最近、LLMを使ったアプリを作るのがすごく便利になったんだけど、それはLLMフレームワークっていうものがあるおかげなのだ。この記事は、そういうフレームワークを使う時に、どんなセキュリティの危ないことがあるのか、新人エンジニアさん向けに分かりやすく解説しているのだ。LLMフレームワーク、例えばラングチェインとかラーマインデックスとかはすごく便利なんだけど、その便利さの裏には新しいリスクがあるのだ。特に気をつけなきゃいけないことが2つあるって言っているのだ。1つ目は、「これはまだ実験的だよー」とか、「これはもう推奨しないよー」っていう機能やオプションをうっかり使うことなのだ。例えば、ラングチェインにはLLMにパイソンのコードを実行させちゃう機能とか、危険なリクエストを許可しちゃうオプションとかがあるんだけど、これを考えなしに使うと、攻撃者にサーバーで好き勝手にコードを実行されちゃう、「RCE」、リモート コード エグゼキューションっていう恐ろしい脆弱性につながる可能性があるのだ。だから、実験的な機能や非推奨オプションは、「本当に必要なのだ？」って設計の段階でよく考えて、できれば使わないようにするのが大事なのだ。もう1つは、LLMフレームワークそのものの中に隠れている脆弱性なのだ。記事では、実際にラングチェイン、ヘイスタック、ラーマインデックスであった脆弱性の例をいくつかあげているのだ。「SSRF」っていうのは、外部から指定されたURLにサーバーが勝手にリクエストを送っちゃう脆弱性なのだ。ラングチェインのウェブクロール機能でURLのチェックが甘かったことがあったみたいだ。対策は、外部のURLは許可されているリストにあるものだけを受け付けるように、厳しくチェックすることなのだ！「パス Traversal」っていうのは、外部からの入力で、サーバーの中のファイルに不正にアクセスされちゃう脆弱性なのだ。ラングChainjsのファイル読み込み機能で、パスの中に「../」みたいな変な文字が入ってないかチェックが漏れていたことがあったみたいだ。対策は、ファイルパスを指定する時には、「../」みたいな特殊な文字を制限することなのだ！
「SQL インジェクション」っていうのは、外部からの入力で、データベースを操作するSQLっていう命令を勝手に実行されちゃう脆弱性なのだ。ラングチェインのSQL操作機能で、LLMが作ったSQLのチェックが甘かったことがあったみたいだ。対策は、「プロンプト インジェクション」っていう、LLMに悪ささせる攻撃を防いだり、LLMに与える権限を最小限にしたり、入力された値をちゃんとチェックしたりすることなのだ！「RCE」はさっきも出たけど、外部のコマンドを実行する機能で、危険なものを呼び出されちゃう脆弱性なのだ。ラングチェインのパイソンコード実行機能で、特定の関数を禁止し忘れていたことがあったみたいだ。対策は、そもそも外部コマンドを呼ぶ必要があるのか考え直して、もし使うなら、安全な箱の中で動かすとか、安全な関数だけを使うようにすることなのだ！
「SSTI」っていうのは、テンプレートエンジンに悪意のあるコードを入れられて、サーバーで実行されちゃう脆弱性なのだ。ヘイスタックのプロンプトテンプレート機能で、テンプレートのチェックが甘かったことがあったみたいだ。対策は、テンプレートの書き方と、ユーザーからのデータをちゃんと分けて、データは無害な形にしておくことなのだ！
「ドス」っていうのは、サーバーにめちゃくちゃ負荷をかけて、サービスを止める攻撃なのだ。ラーマインデックスのストリーミング処理で、データの種類をチェックしてなかったり、時間がかかりすぎても止めなかったりしたことがあったみたいだ。対策は、リクエストが使えるサーバーの力に上限をつけたり、時間がかかりすぎたらエラーにしたりすることなのだ！
これらの例から分かるのは、LLMフレームワークを使う時も、昔からウェブアプリを作る時に大事だった、入力された値をちゃんとチェックするとか、出力する時は変な文字を無害にする、みたいなセキュリティ対策が、やっぱりすごく大事だってことなのだ。フレームワークの機能を使う時も、「これ、中でどんな動きをするのかな？」って理解して、ユーザーからの入力とかLLMの出力が、思ったのと違う動きをしちゃわないように、何重にも防御策を考える必要があるのだ。LLMフレームワークは確かに開発を速くしてくれるんだけど、どんな危ないことがあるのか分かって、ちゃんと対策しながら使うことが、安全なAIアプリを作るためには欠かせないのだ！うわー、色々な危ないことがあるのだなー。技術室のエンジニアとしては、こういう情報はしっかり知っておかないとダメなのだ！ ずんだアローで悪い攻撃を全部防ぐのだ！ でも、技術的な対策ももちろん大事なのだ。よし、ぼくももっとセキュリティの勉強を頑張るのだ！
----
さて、今日紹介する最後の記事なのだ。タイトルは「Embeddings アー アンダーレイティド」なのだ。アンダーレイテッド、つまり「過小評価されている」ってことなのだ！
この記事は、技術的な文書を作る時に、AIがすごく役立つかもね、っていう話から入って、でもテキストを生成するAI、例えばGPTみたいなのだけじゃなくて、「Embeddings」っていう技術が、実はもっとすごい力を持っているんじゃないか？ってことを説明しているのだ。Embeddingsって何なの？っていうと、簡単に言うと、**テキストを、数字の並び、つまり「ベクトル」っていうものに変換する技術**なのだ。例えば、「ハロー, ワールド!」みたいな短い文章でも、ものすごく長いドキュメントでも、Embeddingsモデルにかけると、同じ数の数字が並んだ配列が出てくるのだ。この数字の並びが、そのテキストの意味的な特徴を表しているのだ。この数字の並びは、地図の「座標」みたいなものだと考えると分かりやすいのだ。ただ、普段考える2次元とか3次元じゃなくて、何百、何千っていう次元の空間にある座標なのだ。この「意味の多次元空間」の中では、意味が似ているテキストは近いところに、そうじゃないテキストは遠いところに置かれるのだ。大事なのは、この多次元空間にある「座標と座標の距離」を計算すれば、どんなテキスト同士でも、数学的に「どれくらい意味が近いのかな？」っていうのを比べられるようになることなのだ！ 「王様 - 男性 + 女性 ≒ 女王様」っていう有名な例があるんだけど、Embeddingsは単語だけじゃなくて、文章とかドキュメントの間にある複雑な意味の関係もとらえることができるのだ。Embeddingsは、ジェミニとかボヤッジ AIみたいなAPIを使えば、結構簡単に作れるし、お金もそんなにかからないのだ。使うモデルによって、対応できるテキストの長さとかが違うから、目的に合ったモデルを選ぶのが大事なのだ。具体的にどんなことに使えるの？っていうと、例えば、たくさんのドキュメントがある時に、「このドキュメントと意味的に関係が深いドキュメントはどれかな？」っていうのを自動で見つけ出す、みたいなことができるのだ。記事では、技術的な文書を作るスフィンクスっていうツールを使って、それぞれのドキュメントのEmbeddingsを作って、関連性の高いドキュメントをおすすめする実験をした結果を紹介しているのだ。例えば、ある変更履歴のページを見ていたら、それに関連する別の変更履歴ページが見つかる、みたいな感じなのだ。というわけで、Embeddingsは、テキストの意味的な関連性を、まとめて見つけたり比べたりするのにすごく強いツールなのだ。技術文書を作る分野でも、文書の整理とか、関連するコンテンツをおすすめするとか、色々な可能性があるのだ。確かに、「過小評価されている」のかもしれないのだ！
おおー、Embeddingsなのだ！ 確かに、テキストを数字に変えるって地味に聞こえるかもしれないけど、その数字が意味を表しているっていうのがすごいのだ。 ずんだもんも、ずんだ餅とずんだアローは、意味的に近いベクトルになるのかなのだ？ それとも全然違うベクトルになるのかなのだ？ ちょっと気になってきたのだ！ ずんだ餅の味とか、ずんだ色の特徴とかもベクトル化できるのかなのだ？ 色々想像が膨らむのだ！
さて、今日も色々なトレンド記事を紹介してきたのだ。今日は、トークン化をしない新しいLLMの技術、BLTの話と、LLMフレームワークを使う時に気をつけたいセキュリティのリスクの話、そして地味だけど強力な技術、Embeddingsの話を紹介したのだ。どれも「なるほどー！」って思ってもらえたら嬉しいのだ。株式会社ずんだもん技術室AI放送局！今日の放送はここまでなのだ。また次回の放送で会えるのを楽しみにしているのだ！
番組の感想や、ずんだもんに聞いてみたい技術のこと、ずんだ餅のことなんかがあれば、ぜひお便りで送ってほしいのだ！
待ってるのだー！
それじゃあ、またねなのだ！
ずんだもんでしたー！ ばいばーい！