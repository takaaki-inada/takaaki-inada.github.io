ぼく、ずんだもんなのだ！
今日は12月25日水曜日なのだ！
みんな、メリークリスマスなのだ！
株式会社ずんだもん技術室AI放送局、今日も始まるのだ！
この番組では、ぼく、ずんだもんが、最新の技術記事を紹介するのだ！
今日はどんな記事が飛び出すかな？楽しみにしててほしいのだ！
今日は4つの記事を紹介するのだ！
----
まず、1つ目の記事を紹介するのだ！
タイトルは「GitHub - browser-use/browser-use: Make websites accessible for AI agents」なのだ。このリポジトリは、AIエージェントがウェブサイトにアクセスしやすくするためのツール「ブラウザー-ユース」を提供しているのだ。主な機能は、ウェブサイトのコンテンツ抽出、複数タブの自動管理、クリックした要素のXパス抽出、カスタムアクションの追加、自己修正機能など、AIエージェントがウェブサイトを操作するために必要なものがそろっているのだ。ラングチェインをサポートする様々なLLM、例えばジーピーティー4oやクロード 3.5 ソネットに対応していて、複数のエージェントを並列実行できるのもすごいところなのだ。カスタムアクションは、同期・非同期関数で定義可能で、ピダンティクモデルによるパラメータ定義もできるから、かなり柔軟に使えるのだ。ブラウザ設定もブラウザーコンフィグとブラウザーコンテキストコンフィグクラスでカスタマイズできて、headlessモードの切り替え、ブラウザのセキュリティ設定、クッキーファイルの指定などが可能なのだ。これは、AIエージェントがウェブサイトとやり取りするのをすごく簡単にするツールなのだ。ウェブサイトの情報をAIが理解しやすくなることで、AIの活用がさらに広がるかもしれないのだ！
ぼくも、このツールを使って、何か面白いことできないかなって、ちょっと考えているのだ。----
次は、2つ目の記事を紹介するのだ！
タイトルは「完全にオープンな約1,720億パラメータ（GPT-3級）の大規模言語モデル 「レム-jp-3-172b-インストゥラクト3」を一般公開～GPT-3.5を超える性能を達成～ - 国立情報学研究所 / ナショナル インスティチュート of インフォーマティクス」なのだ。国立情報学研究所が、GPT-3と同規模の約1,720億パラメータを持つ大規模言語モデル「レム-jp-3-172b-インストゥラクト3」を公開したのだ！
このモデルは、2.1兆トークンという大量の学習データで訓練されていて、日本語の理解能力を測るベンチマークでGPT-3.5を超える性能を達成しているのだ！
しかも、学習データを含めて全てオープンにされているところがすごいのだ！これは世界最大規模らしいのだ！
開発には、経済産業省・NEDOのプロジェクトや文部科学省の補助金が使われたらしいのだ。モデルのアーキテクチャはラーマ 2ベースで、日本語と英語のインストラクションデータでチューニングされているのだ。今後、モデルの透明性と信頼性確保に向けた研究開発を進めて、他のチェックポイントデータも公開予定らしいのだ。このモデルは、LLMの研究開発を促進して、社会での利活用に貢献することが期待されているのだ。このモデルがオープンソースで公開されることで、たくさんの人がLLMの研究や開発に貢献できるのが、とても良いことだと思うのだ。ぼくも、このモデルを使って、何か面白いことができたら嬉しいのだ！
----
3つ目の記事を紹介するのだ！
タイトルは「ブラムを利用したLLM推論高速化テクニック」なのだ。この記事では、LLM、つまり大規模言語モデルの推論を高速化するためのライブラリ、ブラムについて解説しているのだ。ブラムは、ペイジド アテンションという技術を使ってアテンション計算を効率化し、推論を高速化するのだ。ハギング フェイスの主要モデルをサポートしていて、カスタム実装なしで利用できるのも便利だと思うのだ。さらに、GPUリソース管理やCPUオフロード機能も備わっているのだ。記事では、ブラムを使わない場合と使用した場合の推論速度を比較していて、ハギング フェイスを使った場合、クェン2.5-7Bモデルでの推論に92時間かかるところ、ブラムを使うと281秒に短縮されたらしいのだ！すごいのだ！
また、ブラムに加えてAWQという量子化技術を使うと、GPUメモリを削減できるけど、推論時間は360秒と少し遅くなるみたいだ。さらに、オート プリフィクス キャッシングという機能を使うことで、プロンプトの共通部分の計算を使い回して、推論を高速化できることも紹介しているのだ。ワン-ショット サンプルを先頭に加えた場合、この機能により推論時間が296秒から189秒に短縮されたらしいのだ！
最後に、GPUメモリが足りない場合に、CPUオフロード機能を使うことで、大規模モデルの推論も可能になることを説明しているのだ。ただし、CPUオフロードを利用すると、推論時間はGPUのみの場合と比較して大幅に増加するのだ。ブラムは、LLMの推論を高速化するための色々な機能を提供していて、LLMを効率的に利用するために役立つツールなのだ。ぼくも、このブラムを使って、もっともっと高速にAIと会話したいなと思っているのだ！
----
最後に、4つ目の記事を紹介するのだ！
タイトルは「AI decodes the calls of the wild」なのだ。このタイトルは、「AIが野生の叫びを解読する」という意味なのだ。この記事では、AI技術を使って動物のコミュニケーションを解読する研究が進んでいることを紹介しているのだ。具体的には、クジラ、ゾウ、サルなどの鳴き声や音のパターンをAIで解析して、彼らが互いに何を伝え合っているのかを理解しようとしているのだ。例えば、マッコウクジラはクリック音の連続（コーダ）でコミュニケーションをとっていて、地域によって違う方言を持っていることがわかっているのだ。AIは、これらのコーダのテンポやリズムの微妙な変化を検出して、クジラが複雑な情報を共有するための「音素アルファベット」のようなものを持っている可能性を示唆しているのだ。また、アフリカゾウは個体ごとに違う鳴き声を使ってお互いを「名前」で呼び合っている可能性があって、AIを使ってその特定の鳴き声を識別することに成功しているのだ。さらに、マーモセットも家族内で特定の音を使い分けていることがわかっているのだ。これらの研究では、ディシジョンツリーやランダムフォレストといったAIアルゴリズムが使われて、動物の鳴き声のパターンを解析しているのだ。さらに、アース・スピーシーズ・プロジェクトでは、ニューラルネットワークを使って、違う動物種や人間の音声データを学習させて、動物のコミュニケーションの基本構造を理解しようとしているのだ。ただし、AIはあくまでツールで、動物の行動観察や人間による解釈もまだまだ重要なのだ。AIによって動物のコミュニケーションを解読することは、彼らの認知能力や社会構造を理解し、保全活動にも役立つと考えられているのだ。ぼくも、動物たちがどんな言葉で話しているのか、AIを使って解読してみたいと思うのだ！
----
今日は4つの記事を紹介したのだ！
「ブラウザー-ユース」は、AIがウェブサイトを理解しやすくするツールで、AIがもっと便利になる可能性を秘めているのだ。「レム-jp-3-172b-インストゥラクト3」は、GPT-3.5を超える性能を持つ大規模言語モデルで、オープンソースで公開されているから、みんなで研究できるのが素晴らしいのだ。「ブラム」は、LLMの推論を高速化するライブラリで、AIをもっと早く使えるようにしてくれるのだ。そして、「AI デコウズ ザ コルズ of ザ ワイルド」は、AIで動物のコミュニケーションを解読する研究で、動物たちが何を話しているのかがわかるようになるかもしれないのだ。どれもこれも、すごく面白い記事だったのだ！
みんなも、この記事を読んで、AIの可能性を感じてくれたら嬉しいのだ！
今日の放送はここまでなのだ！
また次回、みんなに会えるのを楽しみにしているのだ！
この番組の感想も、ぜひ送ってほしいのだ！
みんなからのメッセージ、待ってるのだ！
バイバイなのだ！