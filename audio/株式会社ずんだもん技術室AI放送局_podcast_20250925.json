[
    {
        "type": "title",
        "title": "ずんだもんのAI最新トレンド解説",
        "date": "2025.09.25",
        "notes": "こんにちは！みんな、元気なのだ？ぼくはずんだもん、株式会社ずんだもん技術室AI放送局の時間なのだ！今日は、2025年9月25日木曜日なのだ！今日も、AIに関する最新のトレンド記事を、ぼくが楽しく、わかりやすく紹介していくのだ！",
        "slidenum": 0,
        "start_ms": 0,
        "end_ms": 25785
    },
    {
        "type": "content",
        "title": "本日のAI最新技術トピック",
        "points": [
            "OpenAIの新API「Responses API」とは",
            "記憶するAIエージェントの実現方法",
            "Metaの新RAG技術「REFRAG」の衝撃"
        ],
        "notes": "今日は、とっておきのAIの話題を3つ持ってきたのだ！どれもとっても興味深い内容なのだよ！まず最初は、「オープンエーアイ、GPT-5級推論モデルとAIエージェントを加速する新API『リスポンシズ API』を発表：記憶力と効率性が約5%向上」っていう記事のお話なのだ！",
        "slidenum": 1,
        "start_ms": 25785,
        "end_ms": 52737
    },
    {
        "type": "section",
        "title": "OpenAIの新世代API「Responses API」",
        "url": "https://developers.openai.com/blog/responses-api/",
        "sectionNo": 1,
        "notes": "これは、これからのすごいAI、例えばGPT-5みたいな推論モデルや、自分で考えて動くAIエージェントを作るのにぴったりの新しいAPIなのだよ！今までのAPIだと、AIと会話するたびに、AIの考えたことがリセットされちゃうことがあったのだ。",
        "slidenum": 2,
        "start_ms": 52737,
        "end_ms": 75732
    },
    {
        "type": "content",
        "title": "Responses APIとは？",
        "subhead": "GPT-5やAIエージェント開発に最適化された、OpenAIの新しいAPI",
        "points": [
            "過去のAPI（Completions, Chat Completions, Assistants）の経験を基に設計",
            "テキスト、画像、音声などを扱える[[マルチモーダル推論モデル]]に最適",
            "開発者がモデルとより強力かつシンプルに連携できることを目指す"
        ],
        "notes": "でも、このリスポンシズ APIは、AIが考えたことをずっと覚えていられるのが最大のポイントなのだ！まるで、探偵さんが事件を解決するときに、途中のメモをずっと活用して、次々手がかりを見つけていくみたいなイメージなのだ！",
        "slidenum": 3,
        "start_ms": 75732,
        "end_ms": 95592
    },
    {
        "type": "compare",
        "title": "最大の特徴: 推論状態の永続化",
        "subhead": "従来のAPIとの決定的な違い",
        "leftTitle": "従来 (Chat Completions)",
        "leftItems": [
            "ターンごとに推論がリセット",
            "過去の文脈を毎回再送信する必要",
            "効率性に課題"
        ],
        "rightTitle": "新API (Responses API)",
        "rightItems": [
            "[[推論状態を複数のターンで保持]]",
            "継続的な対話で文脈を活用",
            "より効率的かつ高性能に動作"
        ],
        "notes": "これで、AIはもっと賢く、効率的に動けるようになるし、性能も約5%もアップするらしいのだ！",
        "slidenum": 4,
        "start_ms": 95592,
        "end_ms": 105592
    },
    {
        "type": "kpi",
        "title": "「記憶力」がもたらす性能向上",
        "columns": 2,
        "items": [
            {
                "label": "ベンチマーク性能",
                "value": "約5% UP",
                "change": "向上",
                "status": "good"
            },
            {
                "label": "キャッシュ利用効率",
                "value": "大幅改善",
                "change": "向上",
                "status": "good"
            }
        ],
        "notes": "しかも、AIが『何を言ったか』だけじゃなくて、『どんなツールを使ったか』みたいな行動の履歴も詳しく見られるから、ぼくたちエンジニアも、AIがどう動いているのか、とってもわかりやすくなるのだよ。",
        "slidenum": 5,
        "start_ms": 105592,
        "end_ms": 115592
    },
    {
        "type": "bulletCards",
        "title": "Responses APIの主な強み",
        "items": [
            {
                "title": "詳細な出力情報",
                "desc": "最終メッセージだけでなく、ツール呼び出しなど[[モデルの行動履歴]]を構造化リストで出力"
            },
            {
                "title": "強化されたホストツール",
                "desc": "`web search`や`image gen`などをOpenAIサーバー側で提供し、[[開発者の手間と通信コストを削減]]"
            },
            {
                "title": "推論過程の安全な管理",
                "desc": "モデルの思考過程（CoT）は内部で安全に保持し、[[ハルシネーション等のリスクを低減]]"
            }
        ],
        "notes": "さらに、ウェブ検索や画像生成なんかの便利なツールも、APIの裏側で全部やってくれるから、ぼくたち開発者の手間も省けて、処理も速くなるのだ！今後は、このリスポンシズ APIがAI開発の新しいスタンダードになるって、オープンエーアイも言っているのだよ！",
        "slidenum": 6,
        "start_ms": 115592,
        "end_ms": 144707
    },
    {
        "type": "content",
        "title": "まとめ: Responses APIが目指す未来",
        "subhead": "今後のモデル開発のデフォルトとなる可能性",
        "points": [
            "**ステートフル**: 状態を保持し、文脈を理解し続ける",
            "**マルチモーダル**: テキスト、画像、音声をネイティブに扱える",
            "**効率的**: 通信回数を減らし、高速な処理を実現",
            "[[永続的な推論やシンプルなエージェント開発]]に最適"
        ],
        "notes": "このAPI、まるでAIの記憶力がぐんとアップしたみたいで、ぼくたちエンジニアにとっても、すごく便利になる予感がするのだ！ぼくも、ずんだアローの開発に活用できないか、ワクワクするのだ！",
        "slidenum": 7,
        "start_ms": 144707,
        "end_ms": 161004
    },
    {
        "type": "section",
        "title": "記憶するAIエージェントの作り方",
        "url": "https://acro-engineer.hatenablog.com/entry/2025/09/24/120000",
        "sectionNo": 2,
        "notes": "次に紹介する記事は、「長期記憶でAIエージェントがもっとパーソナルに！ストゥランズ エイジェンツとAWS ベッドロック エイジェントコア『メモリー』機能で実現する顧客体験の向上」っていう技術のお話なのだ！",
        "slidenum": 8,
        "start_ms": 161004,
        "end_ms": 180596
    },
    {
        "type": "content",
        "title": "目指すのは「私を覚えてくれるAI」",
        "subhead": "Strands AgentsとBedrock AgentCore「Memory」機能の組み合わせ",
        "points": [
            "**Strands Agents**: AIエージェントの振る舞いや会話の流れを柔軟に設計するフレームワーク",
            "**Bedrock AgentCore**: 実行環境、ツール連携、そして[[ユーザーごとの記憶管理機能]]を提供",
            "この2つを組み合わせ、ユーザーの好みや過去の会話を記憶するAIエージェントを構築"
        ],
        "notes": "『ストゥランズ エイジェンツ』っていうAIエージェントを作るためのフレームワークと、AWSの『ベッドロック エイジェントコア』っていう機能の、『メモリー』っていうのを組み合わせることで、実現できるのだって！",
        "slidenum": 9,
        "start_ms": 180596,
        "end_ms": 198781
    },
    {
        "type": "diagram",
        "title": "AgentCore Memoryの仕組み",
        "lanes": [
            {
                "title": "短期記憶",
                "items": [
                    "現在の会話の文脈を保持"
                ]
            },
            {
                "title": "長期記憶",
                "items": [
                    "過去の会話から得られた事実を記録",
                    "「Pythonが得意」「Angularが好き」など"
                ]
            },
            {
                "title": "動的検索",
                "items": [
                    "現在の会話に関連する長期記憶だけを検索して活用"
                ]
            }
        ],
        "notes": "このメモリー機能がすごいのだ！AIエージェントが、その日の会話だけじゃなくて、『ぼくはパイソンが得意なのだ』とか、『アンギュラーが好き』みたいな、ぼくたちの好みを『長期記憶』としてしっかり覚えてくれるようになるのだ！",
        "slidenum": 10,
        "start_ms": 198781,
        "end_ms": 217040
    },
    {
        "type": "statsCompare",
        "title": "検証: Memory機能の有無による応答の違い",
        "subhead": "同じユーザーが新しい会話スレッドで依頼した場合",
        "leftTitle": "Memoryなしのエージェント",
        "rightTitle": "Memoryありのエージェント",
        "stats": [
            {
                "label": "ユーザーの好み",
                "leftValue": "忘れている",
                "rightValue": "記憶している"
            },
            {
                "label": "提案内容",
                "leftValue": "無関係な技術 (Streamlit)",
                "rightValue": "[[好みに合致 (PythonとAngular)]]"
            },
            {
                "label": "ユーザー体験",
                "leftValue": "毎回説明が必要",
                "rightValue": "スムーズでパーソナル"
            }
        ],
        "notes": "実際に試してみたら、メモリー機能がないAIだと、一回会話が終わったら、ぼくの好みを忘れちゃって、関係ない技術を提案してきたのだ。でも、メモリー機能をつけたAIだと、別の会話になっても、ちゃんと『パイソンとアンギュラーに興味がある』って覚えてくれてて、それに合った技術を提案してくれたのだよ！",
        "slidenum": 11,
        "start_ms": 217040,
        "end_ms": 243809
    },
    {
        "type": "content",
        "title": "AWS CLIでの記憶内容の確認",
        "points": [
            "実際にAWS CLIでMemoryの中身を確認可能",
            "ユーザーの好みが明示的に記録されていることがわかる",
            "記録されたデータは[[ベクトル検索で効率的に活用]]される"
        ],
        "notes": "これって、まるで友達がぼくの好きなものを覚えててくれるみたいで、すごく嬉しいのだ！",
        "slidenum": 12,
        "start_ms": 243809,
        "end_ms": 253809
    },
    {
        "type": "headerCards",
        "title": "「記憶」を持つAIの応用例",
        "columns": 3,
        "items": [
            {
                "title": "カスタマーサポート",
                "desc": "過去の問い合わせ履歴を記憶し、状況説明の手間を削減"
            },
            {
                "title": "継続的な学習支援",
                "desc": "学習者の苦手分野を記憶し、個人に合わせた問題を提供"
            },
            {
                "title": "パーソナライズ提案",
                "desc": "ユーザーの好みに基づき、製品やコンテンツを推薦"
            }
        ],
        "notes": "これからは、カスタマーサポートとか、学習のサポート、あとは、ぼくの好きなずんだ餅の新しい食べ方とか、そういうパーソナルな提案をしてくれるAIが増えていくと思うのだ！",
        "slidenum": 13,
        "start_ms": 253809,
        "end_ms": 263809
    },
    {
        "type": "quote",
        "title": "まとめ: 記憶はより良い体験の鍵",
        "text": "「記憶」を持つAIエージェントは、ユーザーにとってより自然で便利な体験を提供するために、今後のAI活用で非常に重要な要素になる",
        "author": "記事の結論より",
        "notes": "ぼくたちの生活が、もっと便利で楽しくなること間違いなしなのだ！ぼくも、誰かにずんだ餅が好きって覚えててもらえると嬉しいのだ！この技術で、AIがもっとぼくたちの身近な存在になっていくのだね。ずんだもん専用のAIエージェントとか作ってみたいのだ！",
        "slidenum": 14,
        "start_ms": 263809,
        "end_ms": 285915
    },
    {
        "type": "section",
        "title": "Metaの新技術「REFRAG」",
        "url": "https://zenn.dev/knowledgesense/articles/68089e123a636b",
        "sectionNo": 3,
        "notes": "最後は、「メタが開発した次世代RAG技術『REFRAG』：ベクトル形式で生成AIを最大30倍高速化し、情報処理能力も16倍に向上」っていう、みんながよく聞く『生成AI』の技術、『RAG（ラグ）』を、なんと30倍も速くする新しい技術のお話なのだ！",
        "slidenum": 15,
        "start_ms": 285915,
        "end_ms": 314745
    },
    {
        "type": "content",
        "title": "RAG技術の課題",
        "subhead": "RAG (Retrieval Augmented Generation) とは、AIが外部情報を参照して回答を生成する技術",
        "points": [
            "AIがより正確な回答を生成するための素晴らしい技術",
            "しかし、参照するドキュメントが多いと[[AIに読ませるのに時間がかかる]]",
            "結果として、AIからの回答が遅くなるという課題が存在"
        ],
        "notes": "RAGっていうのは、AIが外部の資料を参考にして、もっと正確な答えを出すための、とっても便利な技術なのだ。でも、参考にする情報がたくさんあると、AIが全部読むのに時間がかかって、答えが出てくるのが遅くなっちゃうっていう課題があったのだよ。",
        "slidenum": 16,
        "start_ms": 314745,
        "end_ms": 336831
    },
    {
        "type": "compare",
        "title": "REFRAGのアプローチ: テキストをベクトルへ",
        "subhead": "Meta社が2025年9月に発表した、RAGを高速化する新手法",
        "leftTitle": "従来のRAG",
        "leftItems": [
            "関連ドキュメントを「テキスト」のままAIに渡す",
            "AIが長いテキストを解析・理解するのに時間がかかる"
        ],
        "rightTitle": "新技術 REFRAG",
        "rightItems": [
            "ドキュメントを事前に「[[ベクトル形式]]」に変換",
            "AIが高速に処理できるデータ形式で渡す"
        ],
        "notes": "そこを解決するのが、このREFRAGなのだ！普通のRAGだと、関連する資料を人間が読むような『テキストの形』でAIに渡すのだ。でもREFRAGは、資料をAIが高速で処理できる『ベクトル形式』っていう特別なデータに変えてからAIに渡すのだ！例えるなら、分厚い本をAIが直接理解できる『要点だけが詰まったデータファイル』にしてから渡すようなものなのだ！",
        "slidenum": 17,
        "start_ms": 336831,
        "end_ms": 371995
    },
    {
        "type": "process",
        "title": "REFRAGの処理フロー",
        "steps": [
            "【事前準備】テキストをベクトルに変換する「変換器」と、それを扱えるAIを学習",
            "【Step 1】質問に関連するドキュメントを検索",
            "【Step 2】見つかったドキュメントを「変換器」で[[ベクトル形式に変換]]",
            "【Step 3】質問（テキスト）と変換されたドキュメント（ベクトル）をAIに注入",
            "【Step 4】AIがこれらを基に、高速に回答を生成"
        ],
        "notes": "こうすることで、AIが答えを出すまでの時間を、最大で30倍も速くできるのだって！",
        "slidenum": 18,
        "start_ms": 371995,
        "end_ms": 381995
    },
    {
        "type": "kpi",
        "title": "REFRAGがもたらす驚異的な成果",
        "columns": 3,
        "items": [
            {
                "label": "回答生成速度",
                "value": "最大30倍",
                "change": "高速化",
                "status": "good"
            },
            {
                "label": "実質コンテキストサイズ",
                "value": "16倍",
                "change": "拡張",
                "status": "good"
            },
            {
                "label": "回答精度",
                "value": "維持",
                "change": "同等",
                "status": "neutral"
            }
        ],
        "notes": "しかも、速くなるだけじゃなくて、答えの正確さもそのまま保てるし、AIが一度に扱える情報の量も、実質的に16倍に増えるらしいのだ！",
        "slidenum": 19,
        "start_ms": 381995,
        "end_ms": 391995
    },
    {
        "type": "content",
        "title": "まとめ: REFRAGの現状と未来",
        "points": [
            "まだ研究段階の技術であり、すぐに利用できるわけではない",
            "専用の学習や高性能なコンピューター（GPU）が必要",
            "将来的にはRAGを使った[[AIシステムの当たり前になる可能性]]を秘める",
            "AIの回答速度を劇的に向上させる、非常に重要な進化"
        ],
        "notes": "まだ研究段階の技術だけど、将来的にはRAGを使ったAIシステムで、これが当たり前になるかもしれない、とってもすごい進化なのだよ！ぼくたちエンジニアも、このREFRAGの登場で、もっともっとすごいAIが作れるようになると思うのだ！30倍速って、ずんだアロー並みに速いのだ！この技術があれば、AIが質問に答えるのがあっという間になるのだね。ぼくのAIも、もっと早くずんだ餅レシピを考えてくれるようになるかな？",
        "slidenum": 20,
        "start_ms": 391995,
        "end_ms": 423924
    },
    {
        "type": "closing",
        "notes": "今日は、オープンエーアイのリスポンシズ API、記憶力を持つAIエージェント、そしてメタのREFRAGっていう、3つのすごい技術を紹介したのだ！どれもAIの未来をぐんと広げてくれる、ワクワクする話だったのだね！これからも、この株式会社ずんだもん技術室AI放送局で、AIの面白い世界を一緒に探検していくのだ！番組の感想や、ぼくずんだもんに聞きたいこと、ずんだ餅の美味しい食べ方なんかがあったら、ぜひ教えてほしいのだ！それじゃあ、みんな、また会うのだ！ぼくはずんだもんだったのだ！バイバイなのだ！",
        "slidenum": 21,
        "start_ms": 423924,
        "end_ms": 476215
    }
]