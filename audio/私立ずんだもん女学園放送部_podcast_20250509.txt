マリア様のお庭に集う乙女達が、今日も天使のような無垢な笑顔で、背の高い門をくぐり抜けていく。汚れを知らない心身を包むのは、深い色の制服。スカートのプリーツは乱さないように、セーラーカラーと枝豆は翻さないように、ゆっくりと歩くのがここでのたしなみ。私立ずんだもんじょがくえん。『ここは乙女のその』。。。ごきげんよう！「私立ずんだもんじょがくえん放送部」、お嬢様ずんだもんですわ。本日、二〇二五年五月九日、金曜日。お天気は少し雲行きが怪しいですけれど、わたくしのお心は晴れやかでございますわ。本日も、世間で話題となっております興味深い記事をいくつかご紹介させていただきますの。さて、本日は三つの記事をご紹介させていただきますわ。皆様の知的好奇心をお満たしできるよう、心を込めてお話しいたしますので、どうぞ最後までお付き合いくださいませ。それでは、最初にご紹介する記事ですわ。タイトルは「AI エージェントを仕組みから理解する」というものですの。最近、AIさんがまるでご自身で考えてお仕事をしているかのように見えますけれど、あれはどのようにして実現されているのか、というお話ですわ。わたくしたちが「AIエージェント」と呼んでいるものは、ファイルを見たり、インターネットを見たりと、様々な道具を使ってお仕事をこなせますの。でも、その根っこにあるAIさん（大規模言語モデル、LLMと申しますわね）は、本当は「文字を入力したら文字を出す」ことしかできない、非常にシンプルなお方なのですって。では、なぜあんなに賢く動けるのかと申しますと、それはAIさんの能力に「仕組み」を組み合わせているから、とのことですのよ。AIさんは、前の会話を覚えておくことができません。ですから、前の会話や必要な情報は、「コンテキスト」として、お話を伺うたびに毎回一緒にお渡しして、文脈を保っているのですわ。ただ、お渡しできる情報の量には限りがございますので、大切な情報だけを選んでお渡しする必要があるそうですわ。それに、AIさんは、わたくしたちのようにご自身で外の世界を見に行くことができませんの。パソコンの中のファイルを見たり、インターネットを見たりすることは、そのままではできないのですわ。そこで、AIさんに「こういうことをしてほしい」と文字で指示していただいて、その指示を別のプログラムさんが受け取って、実際に道具を動かすという仕組みが使われていますの。これを「トゥール ユース」とか「ファンクション コーリング」と呼ぶそうですわ。まるで、お人形に「あの本を取ってきてください」と指示を出して、別のお手伝いさんがその指示を聞いて、本を持ってきてくれるようなものですわね。そして、AIさんが色々な道具とスムーズにお話しするために、「MCP」というお約束事（通信プロトコル）が使われることもございますの。私たちが使っているAIエージェントは、このように、AIさんへの指示や、これまでのやり取りを丁寧にお渡しすることで動いていますのよ。もしエラーが出ても、その情報をAIさんにお伝えすると、ご自身で間違いに気づいて直してくださることもあるそうですわ。たった二年ほどで、AIさんの能力は驚くほど高まっており、そのおかげで今のAIエージェントが使えるようになっているのですわね。この仕組みを知ることは、これからAIさんがどのように進化していくのかを考える上で、大変役に立ちますわ。まあ、まるで執事やメイドさんを雇うような感覚で、AIさんに色々な作業をお願いできるようになるなんて、本当にすごい時代になりましたわね。わたくし、読書のお供に、面白い記事を探してきてくれるAIエージェントさんがいたら、とても嬉しいと思うのですけれど、皆様はいかがですの？----
続きまして、二つ目の記事をご紹介いたしますわ。タイトルは「ローカルRAGを手軽に構築できるMCPサーバーを作りました」というものですの。先ほどご紹介した記事にもございました「MCP」という技術と、ご自身の持っている資料を活用する「RAG（リトゥリーヴァル-オーグメンティド ジェネレイション）」という技術を組み合わせて、ご自身のパソコンの中で安全に使えるAIシステムを簡単に作るためのサーバを開発された、というお話ですわ。RAGとは、あらかじめご用意した書類や資料の中から、AIさんがお答えを考える際に役立つ情報を見つけ出して、その情報を使ってより正確で詳しいお答えを作らせる技術なのですわ。これにより、AIさんは学習していない、例えば会社の秘密の資料なども参考にして、専門的なお答えができるようになりますの。今回開発された「MCP RAG サーバー」は、このRAGを実現するための「資料探し」の部分を担当するサーバですわ。AIさんからの「このことについて教えてください」というお問い合わせに対して、登録しておいた資料の中から関連する情報を見つけ出し、その結果をAIさんにお返ししますの。このサーバは、インターネット上のAIサービスを使わないため、ご自身の情報が外に漏れる心配がなく、完全にプライベートな環境で安全にお使いいただけますわ。このサーバを作られたきっかけは、AIを使ったプログラム作成の際に、ご自身のプログラムのコードや資料をAIさんに賢く扱ってほしいと思ったからだそうですわ。このサーバは、様々な種類の資料（文章やPDFなど）を扱えたり、資料の意味内容で検索できたり、日本語にも対応していたりと、たくさんの優れた特徴がございますの。難しい技術にあまり頼らず作られているため、比較的安定してお使いいただけるそうですわ。このサーバをご自身のパソコンで動くAIさんと組み合わせれば、ご自身の持っている資料だけを使った、完全にプライベートなAIシステムを簡単に作ることができますのよ。会社の皆様が持つ知識をAIさんがまとめてお答えしてくれるようにしたり、個人的なメモをAIさんに整理してもらったりと、様々な活用が考えられますわね。ご自身の大切な情報を守りつつ、AIさんに賢くお手伝いしていただけるようになるなんて、大変素晴らしいですわね。わたくし、お気に入りの本の感想ノートをAIさんに整理してもらえたら、僕・・・あっ違う、わたくしの読書記録がもっと充実するのでは、と思ったのだですわ！あ、なのだですわ！----
さて、最後にご紹介する記事ですわ。タイトルは「Building Nemotron-CC, A High-Quality Trillion Token Dataset for LLM Pretraining from Common Crawl」というものですの。AIさん（大規模言語モデル、LLM）が賢くなるためには、質の高いお勉強材料（学習データセット）が欠かせませんわ。ただ、インターネットにあるたくさんの情報から、良いお勉強材料だけを選び出すのは難しく、せっかくのデータがたくさん捨てられてしまうことが課題でしたの。特に、AIさんに高度な思考力を身につけさせるには、より洗練されたデータが必要ですわ。NVIDIAという会社は、この課題を解決するために、「ネメトロン-CC」という、質の高いお勉強材料を作る新しい方法を開発したそうですわ。そして今回、この方法が「ネモー キューレイター」という道具に組み込まれて、皆様もお使いいただけるようになったとのことですの。この新しい方法のすごいところは、ただ不要なデータを取り除くのではなく、捨てられがちな質の低いデータからも役に立つ情報を取り出したり、もともと良いデータから新しいテキストを作り出したりする「合成データ生成」という技術を組み合わせている点ですわ。これにより、お勉強材料の量と質を同時に高めることができますのよ。記事によりますと、元のデータから最大で二兆トークンもの、大変な量の高品質なデータを作り出せるそうですわ。この方法では、まずインターネットのページからテキストを取り出して整理し、同じ内容をなくしますわ。この作業には、NVIDIAの素晴らしいコンピューター（GPU）を活用した技術が使われており、大変効率的ですわ。次に、複数のAIモデルを使ってテキストの質を評価し、データの質ごとに分類しますの。そして最後に、この品質評価の結果をもとに、AIさんを使って新しい合成データを作り出しますわ。質の低いデータからは役に立つ情報を抜き出して書き直したり、質の高いデータからは要約や質問と答えの組み合わせなど、様々な形式のデータを作り出すそうですわ。この方法で作られたお勉強材料を使って、最新のAIさんを学習させたところ、AIさんの思考力を示す評価で、成績が大きく向上したと報告されていますの。これは、やはり質の高いお勉強材料が、AIさんの性能に直接貢献することを示していますわね。この素晴らしい方法が皆様もお使いいただけるようになったことで、AIさんの開発に取り組む方々は、複雑なお勉強材料の準備を効率的に行えるようになりますわ。これは、これからAIの開発や活用に取り組む新人エンジニアさんにとって、高性能なモデルを作るための基礎となるお勉強材料の大切さを理解し、実際に準備するための強力な道具となるでしょうとのことですわ。この技術は、AIさんを基礎から学ぶだけでなく、特定の作業が得意になるように教え込む際のお勉強材料作りにも応用できますのよ。まるで、優秀な家庭教師が、生徒さんの理解度に合わせて最適な教材を選び、時にはオリジナルの問題まで作ってくれるような、そんなイメージですわね。良いデータが、良いAIさんを育てるのですね。私たちも、日々の学びの中で質の良い情報を集め、自身の糧とすることが大切だと改めて感じ入りましたわ。さて、本日は三つの記事をご紹介させていただきましたわ。最初はAIエージェントの仕組みのお話。まるで賢いお手伝いさんのように動くAIさんが、実はシンプルなAIさんと複雑な仕組みの組み合わせで実現されているというお話でしたわね。次に、ご自身の大切な情報を活用できるローカルRAGサーバのお話。安全な環境で、ご自身の資料を使ってAIさんと連携できるという大変興味深い内容でしたわ。そして最後に、AIさんを賢く育てるための、高品質な学習データセットを効率的に作る新しい方法のお話でしたわ。どれも、これからAIさんがどのように進化していくのかを考える上で、大変示唆に富む記事でしたわね。この番組の感想や、わたくし、お嬢様ずんだもんへのお便りなど、随時募集しておりますわ。皆様からの温かいメッセージを心よりお待ちしております。それでは、本日はこの辺でお開きの時間となりました。皆様、どうぞ素敵な週末をお過ごしくださいませ。また来週お耳にかかれますことを、楽しみにしておりますわ。ごきげんよう！