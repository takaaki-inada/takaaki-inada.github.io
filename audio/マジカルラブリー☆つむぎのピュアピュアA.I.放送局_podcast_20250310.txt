 はじめまして！埼玉ギャルの春日部つむぎだよ！みんな元気～？ 2025年3月10日、月曜日！今週もあーしが「マジカルラブリー☆つむぎのピュアピュアAI放送局」をお届けするよ！今日は、みんなが気になる最新トレンドAI記事を3本紹介しちゃうから、最後までついてきてね！記事、いっくよー！
 まず1本目！
 タイトルは「タイプスクリプト 製の AI エージェントフレームワーク マストラ」、引用元は…えっと…マストラだって！著者は書いてないね。 このマストラってやつ、タイプスクリプトっていうので作られたAIエージェントを作るためのフレームワークなんだって。フレームワークって、簡単に言うと、AIを作るための便利な道具箱みたいなもんかな？ REST APIとかオウプンAPIとか、なんか難しい言葉がいっぱい出てくるけど、気にしなーい！ このマストラがあれば、AIエージェントに必要な機能が全部揃ってるらしいよ。エージェントの定義とか、ワークフローとか、RAGとか…あー、もう呪文みたい！でも、大丈夫！マストラが全部やってくれるんだから！ LLMプロバイダっていう、AIの頭脳を貸してくれる会社（オープンエーアイとかアンスロピックとか）のAPIキーが必要らしいけど、ローカルLLMも使えるんだって。ローカルLLMってことは、自分のパソコンでAIを動かせるってことかな？なんかスゴそう！ しかも、AIエージェントの品質をチェックしたり、オウプンテレメトリーっていうのでトレースを収集したりもできるらしいよ。トレースっていうのは、AIがどんな動きをしてるかを記録することかな？これがあれば、AIが変な動きをしても、すぐに原因がわかるね！ つまり、マストラは、AIエージェントの開発から運用までを全部サポートしてくれる、めっちゃ便利なフレームワークってこと！これがあれば、あーしでもAIエージェント作れちゃうかも！？----
 続いて2本目！
 タイトルは「MCPでLLMに行動させる - テラフォームを例とした ティーエフエムシーピー の紹介」、引用元は…書かれてないね。 今度はLLM、大規模言語モデルに行動させるティーエフエムシーピーっていうのの話だって。テラフォームっていうのを使って説明してるみたいだけど、テラフォームって何？　聞いたことないけど…ま、いっか！ MCPっていうのは、モデル コンテキスト プロトコルの略で、LLMが外部サービスと連携して「行動」できるようにするためのプロトコルなんだって。プロトコルっていうのは、コンピュータ同士が情報をやり取りするためのルールみたいなもんかな？
 MCPはJSON-RPCベースのプロトコルで、リソース、ツール、プロンプトを定義するらしいよ。JSON-RPCって何？　ますますわからなくなってきた！でも、大丈夫！LLMが勝手にやってくれるんだから！ ティーエフエムシーピーはテラフォーム設定ファイルの読み取り、プラン解析、適用、状態管理、設定ファイルの作成・修正ができるらしいよ。つまり、ティーエフエムシーピーを使えば、LLMがテラフォームを自由に操れるってことかな？ インストールは`カーゴウ インストール ティーエフエムシーピー`で簡単にできるらしいよ。`カーゴウ インストール`って、なんかカッコイイ！クロード デスクトプとの連携もサポートしてるって書いてあるね。クロード デスクトプって何？　まあ、いいや！ セキュリティ面もちゃんと考えてあって、信頼できるソースからのインストール、最小権限の原則、サンドボックス環境での実行、監査ログの有効化、機密情報のフィルタリング、定期的なセキュリティレビューが重要だって。セキュリティ対策は大事だよね！
 つまり、ティーエフエムシーピーは、LLMを使ってテラフォームを自動的に操作するためのツールってこと！これを使えば、インフラの管理がめっちゃ楽になるかも！？----
 最後に3本目！
 タイトルは「ギットハブ コパイロット チャット、ヴィジュアル ストゥディオ/VS コウド上で画像を入力できるビジョン機能がパブリックプレビューに」、引用元は…インプレスウォッチだって！ みんな大好きギットハブ コパイロット チャットに、画像入力機能（ビジョン機能）が追加されたんだって！ビジョン機能っていうのは、コパイロットに画像を見せることができる機能のことだよ。 ヴィジュアル ストゥディオ/VS コウド上で、エラー画面のスクショやデザインモックアップをコパイロットに直接見せて、解決策の提案やコード生成のヒントをもらえるんだって。これ、めっちゃ便利じゃん！
 使い方は簡単で、ドラッグ&ドロップ、クリップボード貼り付け、専用メニューからのスクショ添付に対応してるんだって。JPEG/JPG、PNG、GIF、WEBP形式の画像が使えるらしいよ。 GPT-4oモデルで提供されていて、コパイロットの「エディター プリービュー フィーチャーズ」を有効にする必要があるって書いてあるね。GPT-4oって、めっちゃ高性能なモデルなんだろうな！ つまり、ギットハブ コパイロット チャットのビジョン機能を使えば、画像を見せるだけで、コパイロットが問題を解決してくれたり、コードを生成してくれたりするってこと！これを使えば、プログラミングがめっちゃ楽になるかも！？あーしも使ってみよっと！ ふぅ、3本の記事を紹介し終えたよ！
 最初の記事の「タイプスクリプト 製の AI エージェントフレームワーク マストラ」は、AIエージェントを作るための道具箱みたいなものだったね！ 次の「MCPでLLMに行動させる - テラフォームを例とした ティーエフエムシーピー の紹介」は、LLMにインフラを自動的に管理させるためのツールだったね！ 最後の「ギットハブ コパイロット チャット、ヴィジュアル ストゥディオ/VS コウド上で画像を入力できるビジョン機能がパブリックプレビューに」は、画像を見せるだけでコパイロットが問題を解決してくれる、めっちゃ便利な機能だったね！ みんな、今日の放送どうだったかな？少しでも役に立ったら嬉しいな！番組の感想や、つむぎに教えてほしいAIの情報があったら、じゃんじゃん送ってきてね！待ってるよー！それじゃあ、今日はここまで！またね～！