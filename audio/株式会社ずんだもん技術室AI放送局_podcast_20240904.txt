こんにちは！ ぼくはずんだもんのだ。今日は、2024年9月4日(水曜日)なのだ。今日は、技術的な話題をいくつか紹介するのだ。最近、リスナーが減っているのが悩みで、どうすればいいか、良いアイデアがないか、誰かに相談したい気持ちでいっぱいなのだ。でも、今日はそんな悩みを忘れられるような、面白い話題をたくさん用意したから、ぜひ最後まで聞いてほしいのだ！
　、。ここで英語スキル発動！AIずんだもんにへんしーん！　、。1つ目の記事は、「Build reliable agents in JavaScript with LangGraph.js v0.2: Now supporting Cloud and Studio」という記事なのだ。　、。ラングチェイン.js v0.2.0は、ジャヴァスクリプト/タイプスクリプトでLLM(大規模言語モデル)を活用したエージェントを構築するためのフレームワークなんだ。今回のバージョンアップでは、ストリーミング機能やチェックポイントシステムなどが強化されたみたいだ。さらに、デスクトップ向けのエイジェント IDEであるランググラフ ストゥディオと、エージェントをデプロイするためのスケーラブルなインフラストラクチャであるランググラフ クラウドのベータ版が利用可能になったんだって。ランググラフ.jsは、LLM特有の長時間実行や非決定的な性質による課題を解決し、エージェント開発を容易にするみたいだ。ランググラフ ストゥディオは、タイプスクリプト/ジャヴァスクリプト環境におけるエージェントのデバッグを支援するツールで、グラフの入力/出力の可視化や、状態の巻き戻し、ステップ実行などが可能なんだ。ランググラフ クラウドは、ランググラフ.jsで構築したエージェントをウェブ規模でデプロイするためのサービスで、タスクキューやサーバーの管理、ラングスミスとの統合による詳細なトレース、状態の巻き戻しによるトラブルシューティングなどが可能なんだって。　、。ここで再びスキル発動！　、。LangGraph.jsは、Node.js、Deno、Cloudflare Workersなど、多くのJavaScriptランタイムで動作するみたいだ。　、。......
2つ目の記事は、「オープンソースのRAG UI「コーテイモン」を試す」という記事なのだ。コーテイモンは、LLMとベクトルデータベースを組み合わせ、ドキュメントから質問に答えるRAG（リトゥリーヴァル オーグメンティド ジェネレイション）のUIを提供するオープンソースツールなんだ。ドッカーイメージまたはパイソン仮想環境から起動できるみたいだ。コーテイモンは、LLM（大規模言語モデル）とベクトルデータベースを連携させ、ドキュメントから質問への回答を生成するRAGシステムのUIを提供するツールなんだ。オウプンAIやOllamaなどのLLM、および様々なベクトルデータベースと連携可能なんだって。コーテイモンを利用するには、まずドッカーイメージから起動するか、パイソン仮想環境でレポジトリをクローンして起動するんだ。その後、LLMとインベッディングモデル、インデックス作成時のインベッディングモデル、検索・推論時のLLMを、使用するOllamaモデルに設定を変更するんだ。さらに、RAGで使用するドキュメントをアップロードし、インデックスを作成することで、チャット画面から質問し、ドキュメントからの回答を得ることができるんだ。グラフRAG機能を利用するには、パイソン仮想環境で必要なパッケージをインストールし、環境変数を設定してからコーテイモンを起動するんだ。その後、ドキュメントをアップロードし、グラフRAGでインデックスを作成すると、質問に対する回答と同時に、グラフ、エンティティの説明、テキストチャンク、レポート、リレーションなどが表示されるんだって。......
3つ目の記事は、「「ELYZA-ジャパニーズ-ラーマ-2-70b」開発における、大規模モデル学習ノウハウの解説」という記事なのだ。ELYZA社は、日本語に特化した大規模言語モデル（LLM）の開発に力を入れていて、メタ社の「ラーマ-2」シリーズをベースに、日本語データで追加学習を行うことで、高性能な日本語LLMを構築してきたんだって。本記事では、700億パラメータを持つ「ELYZA-ジャパニーズ-ラーマ-2-70b」の開発における知見を共有し、国内における大規模言語モデル開発コミュニティへの貢献を目指しているみたいだ。ELYZA社は、オープンソースモデルをベースに日本語LLMを開発することで、日本におけるAI需要への迅速な対応を目指しているんだ。これまで、「ラーマ-2-7b」や「ラーマ-2-13b」をベースとした日本語LLMを開発し、日本語LLM評価ベンチマークで高い性能を達成してきたんだって。しかし、グローバルモデルとの性能差を埋めるには、さらに大規模なモデルが必要だと考え、「ラーマ-2-70b-チャット」をベースとした「ELYZA-ジャパニーズ-ラーマ-2-70b」の開発に着手したんだ。700億パラメータのモデルを扱うには、学習基盤の整備、日本語データの増加、質の高いフィードバック学習など、多くの課題があったみたいだ。ELYZA社は、産総研の大規模言語モデル構築支援プログラムに採択され、AI用スパコン「ABCI」を活用することで、これらの課題を克服したんだ。......
4つ目の記事は、「非エンジニアの営業担当が生成AIと協力してWEBアプリを開発した話」という記事なのだ。インサイト エッジの営業担当である塩見さんは、エンジニア経験なしで生成AIを活用し、約2ヶ月でWEBアプリを開発したんだって。開発の目的は、フロントエンド・バックエンドのシステム開発に関する理解を深めることで、生成AIの力を借りることで、塩見さんは短期間でチャット機能や掲示板機能を持つWEBアプリをゼロから開発することに成功したんだ。　、。ここで再びスキル発動！　、。開発で利用した主なツール・技術は、生成AI（ChatGPT、GitHub Copilot）、React、Next.jsなどなんだ。　、。特にチャットGPTは、コード生成や質問への回答を通して、塩見さんの開発を強力にサポートしたみたいだ。塩見さんが得た学びとして、生成AIを活用した開発は学習効率が高いこと、ノーコードツールよりも柔軟で高速に開発できること、そしてチャットGPTと正確に対話する技術が重要であることが挙げられているんだ。......
今日は、技術的な話題を4つ紹介したけど、どうだったかな？
今日の内容は、どれも興味深かったでしょう？
また、新しい情報があれば紹介するから、楽しみにしていてね！
番組への感想は、ずんだもん技術室AI放送局のホームページから送ってね！
それでは、また！