ぼくはずんだもんなのだ！みんな、元気にしてるか？
今日は12月26日、木曜日なのだ！
今日も、みんなが気になる最新のトレンド記事を紹介していくのだ！
今日は、紹介する記事は全部で4つなのだ！
それじゃあ、さっそく紹介していくのだ！
1つ目の記事は、
「2024年生成AIエージェントのおすすめ論文 16選」
という記事なのだ。この記事は、AIエージェントの研究を1年続けてきた人が、2024年に発表された論文の中から、特にビジネスやエンジニアにとって役立つ16本を選んで紹介しているのだ。論文の内容は、AIエージェントの基本から、応用、評価方法、作り方、それに、複数のエージェントが協力するマルチエージェント、人間とのやり取り、学習方法、それに、メタ認知能力や脱出ゲームに挑戦するような面白いテーマまで、幅広くカバーしているのだ。それぞれの論文の紹介と一緒に、読者がもっと深く理解するための質問も載せてくれてるから、AIエージェントに関わるみんなにとっては、今の状況を知ったり、今後の開発や研究のヒントを見つけるのに、すごく役に立つと思うのだ。それに、記事の最後に、AIエージェントのまとめ記事へのリンクもあるから、もっと詳しく知りたい人は、そこからさらに深く学べるのだ。この記事を読んで、ぼくもAIエージェントについて、もっともっと詳しくなりたいと思ったのだ！
みんなはどう思うのだ？
----
次の記事は、「LLMのモデルマージ手法 | データアナリティクスラボ」という記事なのだ。この記事では、LLM、つまり大規模言語モデルのモデルマージという技術について解説してるのだ。モデルマージっていうのは、複数のモデルのパラメータを組み合わせて、新しいモデルを作る技術のことなのだ。これを使うと、計算コストを抑えながら、高性能なモデルを効率的に作れる可能性があるのだ。モデルマージには、大きく分けて2つの種類があるのだ。1つは、モデルの各層のパラメータの重みを統合する「パラメータ空間でのマージ」。もう1つは、複数のモデルの層を組み替えて新しいモデルを作る「データフロー空間でのマージ」なのだ。この記事では、特にパラメータ空間でのマージについて詳しく説明しているのだ。モデルマージの効果として、「モデルスープ」というものがあるのだ。これは、複数のび調整したモデルの重みを平均化することで、精度とロバスト性を向上させる効果のことなのだ。モデルの重みを平均化することで、損失関数の「平坦解」に近づいて、汎化性能が向上する可能性があるのだ。具体的なモデルマージの手法としては、「Task Arithmetic」、「TIES」、「DARE」、「Model Breadcrumbs」、「TALL Mask」、「DELLA」、「MetaGPT」、「KnOTS」などがあるのだ。それぞれ、少しずつ違う方法で、モデルの性能を最大限に引き出そうとしているのだ。他にも、進化アルゴリズムを使ってマージのハイパーパラメータを最適化する「進化的モデルマージ」や、複数のモデルをエキスパートとしてモーモデルを構築する「モー マージング」という手法もあるのだ。実装方法としては、「マーギキト」というライブラリが、いろんなマージ手法をサポートしてくれているのだ。モデルマージは、ドメイン特化LLMを構築する上で、コストを抑えつつ高性能なモデルを作るための、すごく有効な手段になる可能性があるのだ！
ぼくも、いつかモデルマージに挑戦してみたいのだ！
----
3つ目の記事は、「デビン AIにテストを丸ごと書かかせてCIがパスするまで作業してもらう方法」という記事なのだ。デビンっていうのは、ソフトウェア開発を効率化するAIプラットフォームのことなのだ。特に、テストコードを自動で生成するのが得意なのだ。スラックでデビンにテスト作成を依頼すると、デビンは指定されたリポジトリにアクセスして、既存のテスト事例を参考にテストコードを生成して、ギットハブにプルリクエストを作成してくれるのだ。もし、CIが失敗したら、自動で修正も試みてくれるのだ。さらに、スラックやギットハブのプルリクエストのコメント、デビンのUIからも追加の作業依頼ができるのだ。デビンは過去のフィードバックを学習して、リポジトリごとに「ナレッジ」として保存するから、使い続けるほど、どんどん効率的に開発ができるようになるのだ。ただし、テストの最終チェックは、やっぱりエンジニアがやる必要があるし、複雑な作業は、事前に事例や指示をちゃんと伝えておいた方がスムーズに進むのだ。デビンは、テスト以外にも、リファクタリングやエラーハンドリング、ドキュメント作成など、いろんな作業をこなせるのだ。料金は月額500ドルからの従量課金制で、チームの状況によっては、すごくリーズナブルな価格設定だと思うのだ。デビン、すごいのだ！ぼくも、いつか使ってみたいのだ。みんなはどう思うのだ？
----
最後の記事は、「アマゾン Bedrockで「ユーザがアップロードしたドキュメントから回答を得る」方法のまとめ」という記事なのだ。この記事では、アマゾン Bedrockを使って、ユーザーがアップロードしたドキュメントの内容に基づいて回答を得る方法について解説しているのだ。RAGっていう技術を使うことで、AIが学習していない情報も扱えるようになるのだ。特に、ユーザーがドキュメントをアップロードして、その内容に関する質問に答えられる機能は、最近すごくニーズが高まっているのだ。アマゾン Bedrockでは、この機能を2つの方法で実現できるのだ。1つは、「アンスロピック クロード メッセージAPI」を使う方法。もう1つは、「Amazon Bedrock Knowledge BaseのRetrieveAndGenerate API」を使う方法なのだ。「アンスロピック クロード メッセージAPI」を使う場合は、Bedrockのプレイグラウンドでクロードモデルを選ぶと、ファイルの添付ボタンが現れるのだ。このAPIを使うと、アップロードしたファイルの内容を基に回答が得られるのだ。ボートー3を使う場合、ファイルのバイト列をベイス64エンコードする必要はないのだ。ただし、ファイルサイズは4.5MB未満じゃないといけないのだ。このAPIでのドキュメント読み取り精度は、すごく高いのだ。「Amazon Bedrock Knowledge BaseのRetrieveAndGenerate API」を使う場合は、Knowledge Baseの画面からドキュメントをアップロードして回答を得られるのだ。このAPIを使う場合は、ファイルのバイト列をベイス64エンコードする必要があるのだ。それに、`contentType`にはMIMEタイプを指定する必要があるのだ。このAPIもドキュメントの読み取り精度がすごく高くて、詳しい情報を読み取って回答を生成してくれるのだ。どちらのAPIも、事前にナレッジベースを構築したり、S3バケットを使う必要がないから、シンプルに実装できるのが、すごく良いところなのだ。これらの機能は、チャットジーピーティーなどの他のAIチャットサービスでも利用されていて、その便利さが注目されているのだ。これらのAPIを上手く活用することで、チャットボットに組み込みやすくなって、ユーザーが求める情報に素早くアクセスできるようになるのだ。ぼくも、これらのAPIを使って、何か便利なものを作ってみたいと思ったのだ！
みんなはどう思うのだ？
---
今日は、4つの記事を紹介したのだ！
駆け足だったけど、みんなついてこれたかな？
今日は、AIエージェントに関する論文、LLMのモデルマージ、デビン AIのテスト自動化、そしてアマゾン Bedrockを使ったドキュメントからの回答取得について話したのだ。どれも、すごく興味深い内容だったと思うのだ！
みんなからの番組の感想や、紹介してほしい記事のリクエストも、いつでも待ってるのだ！
また、次回も、みんなに会えるのを楽しみにしているのだ！
ぼくはずんだもんなのだ！またねなのだ！