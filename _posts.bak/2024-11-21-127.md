---
actor_ids:
  - ずんだもん
audio_file_path: https://storage.googleapis.com/podcast-zund-arm-on/audio/株式会社ずんだもん技術室AI放送局_podcast_20241121.mp3
audio_file_size: 0
date: 2024-11-21 05:00:00 +0900
description: 'AIやテクノロジーに関する記事を紹介  
工数6割削減! 生成AIとOCRを組み合わせ、店舗毎に形式が異なるレストランメニューを読み取らせてみた、Agent Protocol: Interoperability for LLM agents、イオンの“レシートレス機能”開発秘話。現実世界の複雑なオペレーションをどう実装したのか。 ｜AEON TECH HUB、『ググって正解が出る時代は終わり』ネットで検索したら、専門家の目から見て誤りばかりのAI画像が出てきた「紙資料が大事になった」'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20241121
information: 
---

## 関連リンク


- [工数6割削減! 生成AIとOCRを組み合わせ、店舗毎に形式が異なるレストランメニューを読み取らせてみた](https://tech-blog.tabelog.com/entry/ai-menu-ocr)  



食べログのメニューデータ入稿業務において、生成AIとOCRを組み合わせたツールを開発し、作業工数を6割削減することに成功しました。従来の手作業によるメニュー情報の入力は、時間と労力を要するものでした。本プロジェクトでは、まずOCR技術を用いてメニュー画像内の文字情報を座標情報と共に取得。その後、生成AIにOCR結果と画像データを渡し、料理名と価格を抽出し、入力フォームへ自動入力するシステムを構築しました。

生成AI単体では精度の問題がありましたが、OCRによる位置情報との連携により、生成AIの出力結果が画像上のどの部分に対応するかを特定できるようになり、精度の向上と確認作業の効率化を実現しました。ツールは、AIによる高速入力と、人による確認・修正作業を組み合わせた設計となっており、AIと人間の強みを活かす仕組みとなっています。  UIについても徹底的に作り込み、ハイライト機能、消し込み機能、入力支援機能などを搭載することで、確認・修正作業を大幅に効率化しました。

開発においては、常に最新技術の動向をウォッチし、GPT-4やClaude 3.5 Sonnetといった生成AIモデルの特性を踏まえた柔軟な方針転換が成功の鍵となりました。  特に、当初はOCRのみを利用する方針でしたが、GPT-4の登場を機に、画像データとOCR結果を組み合わせることで、精度と効率性が大幅に向上しました。また、完全自動化を目指さず、人による確認作業を残すことで、精度の高いデータ入力を実現しました。

本プロジェクトの成功要因は、生成AIだけでなくOCR技術など幅広い技術を組み合わせたこと、ユーザビリティを重視したUIの徹底的な作り込み、そして最新技術への対応と柔軟な方針転換にあります。  この経験から、生成AIの業務活用においては、フルスタックエンジニアのような幅広い技術を持つ人材が不可欠であることが示唆されました。  彼らは、生成AIの特性を理解した上で、様々な技術を駆使し、最適なソリューションを生み出すことができます。


引用元: https://tech-blog.tabelog.com/entry/ai-menu-ocr


- [Agent Protocol: Interoperability for LLM agents](https://blog.langchain.dev/agent-protocol-interoperability-for-llm-agents/)  



LangChainは、様々なエージェントを連携させるマルチエージェントフレームワークLangGraphを発表しました。異なるフレームワークのエージェント間の相互運用性を高めるため、`Agent Protocol`という共通インターフェースをオープンソース化しました。これは、LLMエージェントを本番環境で運用するために必要な、フレームワークに依存しないAPIを標準化しようとする試みです。

`Agent Protocol`は、エージェント実行(`Runs`)、複数ターン実行の整理(`Threads`)、長期記憶の操作(`Store`)といった主要なAPIを定義しています。LangGraphだけでなく、AutoGen、OpenAI Assistant API、CrewAI、LlamaIndexなど、他のフレームワークや独自実装のエージェントもこのプロトコルを実装することで、相互運用が可能になります。

さらに、LangGraph Studioのローカル実行環境を提供することで、開発者の利便性を向上させました。以前はMac専用でDockerを使用していましたが、Pythonパッケージとしてインストール可能な、Docker不要のバージョンが提供されています。これは、`langgraph-cli` を使用してローカルで起動し、`Agent Protocol`を実装したサーバーとして機能します。これにより、あらゆるプラットフォームでLangGraph Studioを使用し、低レイテンシで効率的なデバッグが可能になります。

また、AutoGenなどの他のフレームワークのエージェントをLangGraphのサブエージェントとして統合する方法や、LangGraph Platformを使用してそれらをデプロイする方法も公開されました。LangGraph Platformを利用することで、水平スケーラブルなインフラストラクチャ、バースト処理のためのタスクキュー、短期記憶と長期記憶のための永続化レイヤーなどのメリットを活用できます。これにより、様々なフレームワークのエージェントを柔軟に組み合わせた、高度なマルチエージェントシステムの構築が可能になります。


本記事では、`Agent Protocol` の詳細な使用方法や、LangGraph Studio、AutoGenとの統合方法については触れていません。詳細は、記事中に記載されているリンク先を参照ください。


引用元: https://blog.langchain.dev/agent-protocol-interoperability-for-llm-agents/


- [イオンの“レシートレス機能”開発秘話。現実世界の複雑なオペレーションをどう実装したのか。 ｜AEON TECH HUB](https://engineer-recuruiting.aeon.info/aeon-tech-hub/interview_receiptless)  



この記事は、イオンが開発したレシートレス機能の開発背景と実装方法について解説しています。  日本の小売業界の巨人であるイオンが、レシートレス化という技術的にも運用面でも非常に複雑な課題にどのように取り組んだのか、その詳細を技術的な視点から紐解いています。

レシートレス化は、単にレシートを発行しないというだけでなく、顧客への情報伝達、会計処理、エラー処理、そして何よりも現実世界の複雑な店舗オペレーションとの整合性が大きな課題となります。  記事では、これらの課題を解決するために、イオンがどのような技術やシステムを導入し、どのような工夫を凝らしたのかが説明されていると考えられます。

具体的には、以下のような点が詳細に記述されていると推測されます。

* **システム設計:** レシートレス化を実現するためのシステムアーキテクチャ、データ管理方法、セキュリティ対策など。  おそらく、POSシステムとの連携、顧客データの適切な管理、個人情報保護への配慮などが重要な要素として取り上げられているでしょう。
* **開発プロセス:** アジャイル開発手法の採用、テスト環境の構築、様々なケースに対応するためのエラーハンドリングなど、開発における工夫や苦労が記述されているはずです。
* **運用面への考慮:**  レジ操作の変更、従業員の教育、顧客への周知方法など、システム導入による運用上の変更と、その円滑な移行のための対策が説明されていると考えられます。
* **技術的な課題と解決策:**  システム開発中に発生した問題点とその解決策、技術的な選択理由などが詳細に解説されているでしょう。  例えば、特定のハードウェアやソフトウェアの選定理由、パフォーマンス向上のための最適化、データ整合性の確保など。

記事全体を通して、大規模な小売企業におけるシステム開発の難しさ、そして現実世界の問題を解決するための技術的なアプローチが示されていると考えられます。 新人エンジニアにとって、大規模システム開発における課題や、現実世界の複雑さを考慮したシステム設計・開発の重要性を学ぶ上で貴重な事例となるでしょう。  ただし、記事本文にはアクセスできないため、上記は推測に基づいた要約となります。  詳細な技術的な内容や具体的な実装方法は、記事本文を参照する必要があります。


引用元: https://engineer-recuruiting.aeon.info/aeon-tech-hub/interview_receiptless


- [『ググって正解が出る時代は終わり』ネットで検索したら、専門家の目から見て誤りばかりのAI画像が出てきた「紙資料が大事になった」](https://togetter.com/li/2468174)  



ヒストリカルコスチューム研究家の汐音凛氏（@shione_kageki）が、生成AIによる歴史コスチューム画像の精巧な偽造に警鐘を鳴らしています。以前はネット検索で正確なファッションプレートなどの画像が見つかったのに対し、現在はAI生成によるロココ風の画像が大量に表示され、真偽の判別が困難になっているとのことです。

同氏は、歴史研究においてネット検索が信頼できない状況になっていると指摘。AI生成画像は、リボン位置の不自然さ、現代的な顔立ち、時代考証に合わない装飾など、専門家であれば誤りと判断できる点が多いものの、専門知識を持たない者にとっては真偽の判断が難しいと懸念しています。

多くのユーザーも、AI生成画像の精巧さに驚き、容易に騙されてしまう可能性を指摘しています。例えば、古代ローマの衣装やロココ時代のドレスなどを検索した際に、歴史的正確性に欠けたAI生成画像が大量に表示されるという報告が多数上がっています。

この状況を受けて、汐音氏は紙資料や原典の重要性を改めて強調。ネットの情報は嘘と真実が入り混じった状態であり、正確な情報を取得するには、従来の紙媒体による調査が不可欠になっていると訴えています。  専門知識を持つ者でも見分けが難しいほど精巧なAI生成画像が出回っている現状は、歴史研究のみならず、デザイン等の分野においても大きな課題となっています。  日本のエンジニアの皆様も、情報収集においては、AI生成された情報の信憑性を慎重に確認する必要があることを認識しておくべきでしょう。  特に専門性の高い分野では、紙媒体の資料を参照することを強く推奨します。


引用元: https://togetter.com/li/2468174



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
