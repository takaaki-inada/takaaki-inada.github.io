---
actor_ids:
  - ずんだもん
audio_file_path: https://storage.googleapis.com/podcast-zund-arm-on-tech/audio/株式会社ずんだもん技術室AI放送局_podcast_20250508.mp3
audio_file_size: 0
date: 2025-05-08 05:00:00 +0900
description: 'AIエージェントCline、freeeはどうやって全社導入した？、I built an AI code review agent in a few hours, heres what I learned、10分くらいでできるA2Aのはじめ方、ChatGPTが多くの会話を記憶すればするほど無能になる問題は、何が原因なんだろう… 履歴を見返すと、ほとんどの会話は全然解決しなかったり、ダメな案がそのまま放置してある'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20250508
---

## 関連リンク


- [AIエージェントCline、freeeはどうやって全社導入した？](https://developers.freee.co.jp/entry/ai-cline-rolling-out)  


freeeでは、GitHub Copilotなどに加え、特に開発スタイルを変える可能性を秘めたAIエージェント「Cline」の全社導入を進めています。この記事では、freeeがどのようにAIツールの本格導入に取り組み、どのような課題を乗り越えたのかが解説されています。

AIツールの導入は、従来のツールと異なり、セキュリティリスクやコスト管理など特有の難しさがあります。freeeではこれに対応するため、二つの仕組みを導入しました。一つは「AI特区制度」で、安全なサンドボックス環境などで一部のチームが限定的にツールを試すことで、現場での利用感や課題を素早く洗い出します。もう一つは「AI駆動開発チーム」で、特区で見つかった課題への対処や、全社導入のための基盤開発、ガイドライン策定、導入効果の測定などを担う専門チームです。

この体制のもと、freeeではまずAI特区でツールを検証し、うまくいきそうなものについて、特区で得た知見をもとに全社展開のためのガイドラインやセキュリティ基盤を整備し、その後全社へ展開・運用するという流れで進めています。

Clineの導入においては、主に三つの壁に直面しました。
一つ目は「セキュリティ」です。社内コードが学習に使われたり、機密情報が流出したり、危険なコマンドが実行されたりするリスクです。これに対しては、学習にデータが使われないAmazon Bedrockを採用し、さらに社内基盤に独自プロキシを立てて、機密情報のマスキングや危険なコマンドのブロックを行いました。
二つ目は「コスト」です。AIツールの多くは利用量に応じた課金で、コスト予測が難しい点が課題です。freeeでは、Amazon Bedrockにタグ付けしたり、プロキシでリクエストログを詳細に計測したりすることで、どのツールにどれだけコストがかかっているかをリアルタイムで監視・可視化し、利用状況や費用対効果を把握できるようにしました。
三つ目は「AIリテラシー」です。ツールは使い方で効果が大きく変わる上、誤った使い方をするとセキュリティリスクにもつながります。対策として、安全な利用を促す共通ルールの策定や、セキュリティリスクのある機能の利用制限、さらには既存のセキュリティ対策と組み合わせた多層的な防御を行っています。

freeeは今回のCline導入を通じて、AIツール導入にはリスクと効果を天秤にかけた判断や、システム的・組織的な専用対策が不可欠であること、またツールごとの特性に合わせた対策が重要であることを学びました。Clineは既に多くの開発者に利用されており、今後はより詳細な効果検証や、AIツール前提の開発フローへのシフトを目指していくとのことです。

この記事は、freeeがAIエージェントの全社導入にどう取り組み、技術的な課題や組織的な課題にどう向き合ったかを知る上で、非常に参考になる事例と言えるでしょう。

引用元: https://developers.freee.co.jp/entry/ai-cline-rolling-out


- [I built an AI code review agent in a few hours, heres what I learned](https://www.sourcebot.dev/blog/review-agent-learnings)  


AIコードレビューエージェントを自作した経験に基づく記事です。PRの差分をLLMに送り問題点を見つけさせる仕組みで、GitHub Copilot Reviewなどの類似ツールと比較し、有用性を検証しています。基本的なエージェントは数時間で構築可能ですが、LLMは指示に従わないことがあり、コード全体の文脈理解が不十分だと的外れな提案をすることが課題です。記事では、市販のエージェントを利用するより、自社で完全に制御できるエージェントを開発するためのフレームワークの将来性に期待を寄せています。


引用元: https://www.sourcebot.dev/blog/review-agent-learnings


- [10分くらいでできるA2Aのはじめ方](https://zenn.dev/churadata/articles/c505d4c2d39281)  


この記事は、Google製のA2Aプロトコルを使った複数AIエージェント連携のチュートリアルを解説します。A2Aとは、異なるAIサービス（チャットボット、画像生成、為替変換など）を連携させるプロトコルです。

記事では、複数のエージェントをA2Aで接続し、統合チャットUIから対話・実行できるデモを構築する手順を説明します。セットアップ、APIキー取得、リモートエージェント（経費申請、画像生成、為替）、ホストエージェントの作成、エージェントカードの追加、チャットテストを通して、A2Aの基本的な使い方を理解できます。

A2Aのコア要素として、Agent Skills（エージェントの機能）、Agent Capabilities（通信方法）、Agent Card（エージェントの名刺）を紹介。特にAgent Cardは、エージェントのメタデータや機能を記述する重要な要素で、JSON-RPC形式で定義されます。


引用元: https://zenn.dev/churadata/articles/c505d4c2d39281


- [ChatGPTが多くの会話を記憶すればするほど無能になる問題は、何が原因なんだろう… 履歴を見返すと、ほとんどの会話は全然解決しなかったり、ダメな案がそのまま放置してある](https://togetter.com/li/2547397)  


ChatGPTは会話履歴が長くなると性能が落ちるという声があります。原因として、不要な情報も記憶してしまうことや、長い履歴の中で文脈が曖昧になる、過去の会話の重要度（重みづけ）がうまくいかないことなどが考えられています。これはLLMが過去の情報を扱う難しさを示しており、人間のように不要な情報を整理する仕組みや、ユーザー側での履歴管理の工夫が重要になりそうです。

引用元: https://togetter.com/li/2547397



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
