---
actor_ids:
  - ずんだもん
audio_file_path: /audio/株式会社ずんだもん技術室AI放送局_podcast_20251104.mp3
audio_file_size: 0
date: 2025-11-04 05:00:00 +0900
description: 'How Code Execution Drives Key Risks in Agentic AI Systems、Tongyi DeepResearch: A New Era of Open-Source AI Researchers、【備忘録】AI駆動開発Conference Autumn 2days で 学びと気づきが得られすぎたので、共有したい...'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20251104
---

## youtube版(スライド付き)

<div class="article-video"><iframe src="https://www.youtube.com/embed/fROC_e56Y4s" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></div>


## 関連リンク


- [How Code Execution Drives Key Risks in Agentic AI Systems](https://developer.nvidia.com/blog/how-code-execution-drives-key-risks-in-agentic-ai-systems/)  


AIの進化により、AIが自分でコードを生成し、それを実行して自律的に動く「AIエージェント」が注目されています。これは非常に便利な機能ですが、同時に新たなセキュリティリスクも生み出しています。新人エンジニアの皆さんも、AIシステムを扱う際には特に注意が必要です。

一番のポイントは、**AIが生成したコードは「信頼できないもの」として扱うべき**だということです。なぜなら、悪意のあるユーザーが巧妙な指示（プロンプト）を与えることで、AIに危険なコードを生成させ、それがシステム上で実行されてしまう可能性があるからです。これが「リモートコード実行（RCE）」のような、システムを乗っ取られるほどの深刻な脆弱性につながる可能性があります。

これまでのセキュリティ対策として、生成されたコードの中から危険な部分を検出・除去する「サニタイズ（フィルタリングや無害化）」という手法がよく使われてきました。しかし、この記事では、**サニタイズだけでは不十分**だと指摘しています。攻撃者は、フィルタリングをすり抜ける方法を常に探し、見つける可能性があるからです。たとえば、既存の安全なライブラリ機能を悪用したり、AIの挙動を操作したりすることで、サニタイズを回避できてしまうケースが実際に確認されています。

NVIDIAのセキュリティチームも、AIを活用した分析ツールで実際にこのような脆弱性を発見しました。この事例は、サニタイズだけでは防ぎきれない、システム全体のリスクであることを示しています。

では、どうすれば良いのでしょうか？ 記事が強調しているのは、**「サンドボックス化」の導入が必須**であるという点です。サンドボックスとは、AIが生成したコードを実行するための隔離された安全な環境のことです。たとえ悪質なコードが生成されても、このサンドボックス内で閉じ込めることで、システム全体への影響を最小限に抑えることができます。これは、コードがシステム全体を自由に操作するのを防ぐための「実行境界線」を設けるイメージです。

重要な教訓は以下の3点です。
1.  **AIが生成したコードは、ユーザーからの入力と同様に「信頼できないもの」と考える。**
2.  **サニタイズは補助的な対策であり、それだけに頼るのは危険。**
3.  **実行環境の「サンドボックス化」は、AIがコードを実行するシステムには必須のセキュリティ対策である。**

AI技術を安全に活用していくためには、単にコードをフィルタリングするだけでなく、実行環境を根本的に隔離するという構造的な対策が不可欠です。AIエージェントを開発する際は、この「サンドボックス化」を設計の初期段階から考慮に入れるようにしましょう。

引用元: https://developer.nvidia.com/blog/how-code-execution-drives-key-risks-in-agentic-ai-systems/


- [Tongyi DeepResearch: A New Era of Open-Source AI Researchers](https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/)  


皆さん、最新のAI技術に触れる良い機会です！今回ご紹介するのは、Alibabaが発表したオープンソースのWebエージェント「Tongyi DeepResearch」です。これは、複雑な情報探索や問題解決を自律的に行うことができるAIで、なんとOpenAIの同様のエージェントに匹敵するほどの高性能を実現しています。GitHubでその詳細が公開されているため、私たちエンジニアが実際に触れて学ぶことができるのは大きな魅力です。

Tongyi DeepResearchは、Webブラウジングやデータ分析をこなし、人間が与えるような多様なタスクを高い精度で実行します。例えば、「Humanity’s Last Exam」という学術推論タスクや、Web上の情報を探索する「BrowseComp」といった難しいベンチマークで、これまでのAIを上回る優れた結果を出しています。

この高性能を支えるのは、独自の学習方法です。特に注目すべきは、**完全に自動化された高品質な合成データ生成**です。人間が介入することなく、AIがより高度な学習をするための高品質なデータを大量に作り出すことで、AIエージェントの能力を限界まで引き上げています。これにより、継続的事前学習（CPT）、教師ありファインチューニング（SFT）、そして強化学習（RL）という一連の学習プロセスが、効率的かつ安定して行われています。開発チームは、アルゴリズムだけでなく、このデータの質と学習環境の安定性が、AIエージェントの性能を決定する上で非常に重要だと強調しています。

Tongyi DeepResearchには、タスクの性質に応じて二つの動作モードがあります。
一つはシンプルな「ReActモード」。これは「思考→行動→観察」というサイクルを繰り返し、モデル本来の能力を発揮させます。もう一つは、より複雑な長時間のタスクに対応する「Heavyモード」です。このモードでは「IterResearch」という革新的なアプローチを採用しており、過去の情報を全て溜め込むのではなく、必要な情報だけを選んでタスクを「研究ラウンド」に分解します。これにより、情報過多による「認知的窒息（cognitive suffocation）」を防ぎ、AIが常にタスクに集中し、高い推論品質を維持できるよう設計されています。

すでに現実世界での応用も始まっており、Alibaba社内では地図ナビゲーションエージェント「Xiao Gao」や、法律調査を行うエージェント「Tongyi FaRui」として活躍しています。これらの例は、Tongyi DeepResearchが単なる研究成果に留まらず、具体的なビジネス課題を解決できる実用的なAIであることを示しています。

もちろん、まだ改善の余地はあります。現在の課題としては、より長いコンテキスト（文脈）を扱えるようにすること、さらに大規模な基盤モデルへの適用、強化学習の効率化などが挙げられています。

新人エンジニアの皆さんにとって、このようなオープンソースで高性能なAIエージェントの登場は、最先端の技術動向を理解し、実際にAIエージェントを構築するヒントを得る貴重な機会になるでしょう。ぜひ、GitHubリポジトリを覗いてみてください。

引用元: https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/


- [【備忘録】AI駆動開発Conference Autumn 2days で 学びと気づきが得られすぎたので、共有したい...](https://zenn.dev/sunagaku/articles/c5affee1871afb)  


2025年10月に開催された「AI駆動開発 Conference Autumn」での学びを、新人エンジニアの方々にも役立つようにまとめました。AIを活用した開発の最前線と実践的な知見が詰まっています。

**AIとの賢い付き合い方：同僚のように協業しよう**
AIは「同僚エンジニア」として捉え、期待することを具体的に、そして背景情報も添えて伝えると、より質の高い結果が得られます。例えば、コードの質問をする際は「なぜこのコードについて質問するのか？」といった目的も一緒に伝えると効果的です。また、「think ultrathink」のような指示でAIの推論を深めることができ、計画作成時に特に役立ちます。AIの機能が分からなければ、AI自身に「どう使ったらいい？」と質問してみるのも良いでしょう。

**開発プロセスの改善：効率と品質を高める工夫**
AIにタスクを依頼する際は、進捗状況を共有するためのDBを用意したり、タスクを10分単位など細かく分割して指示したりすることで、効率的に並行開発を進められます。また、AIに実装させたコードは「さらに改善して」と繰り返し指示し、テストが通るまで修正させることで品質を高めます。TDD（テスト駆動開発）は単にテストを先に書くことではなく、テストからのフィードバックを通して「最適な設計を考え続ける」プロセスです。コード品質を測る指標は、互いに補完しあうもの（例：テスト/ソース比率とカバレッジ）を選ぶと、偏りのない良いコードになります。

**組織へのAI浸透と未来のエンジニア像**
AI活用を組織に広めるには、「業務理解」が最も重要です。現場の業務を深く知り、「なぜ？」を掘り下げることが成功の鍵。また、AI導入には「技術理解」「組織理解」「心理的抵抗」の3つの壁がありますが、AIを使いこなす人をロールモデルにしたり、社内勉強会を開いたりして、多くの人がAIを使える文化を作ることが大切です。

AIがコード生成を高速化する一方で、デバッグやレビューがボトルネックになることもあります。AIによる効率化は、開発フロー全体を見直す視点が必要です。最終的に人がコードを読み、そこから学ぶ習慣は忘れずに。未来のAI駆動開発では、AIはテストや改善も行い、エンジニアは「感動を生むUI/UX」「ビジネスモデルの構想」など、よりクリエイティブな領域に注力できるようになるでしょう。AIと人は、状況に応じて「伴走」と「委託」を使い分ける柔軟な関係性が求められます。

引用元: https://zenn.dev/sunagaku/articles/c5affee1871afb



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
