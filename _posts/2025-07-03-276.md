---
actor_ids:
  - ずんだもん
audio_file_path: /audio/株式会社ずんだもん技術室AI放送局_podcast_20250703.mp3
audio_file_size: 0
date: 2025-07-03 05:00:00 +0900
description: 'DeNA AI LinkがAIソフトウェアエンジニア『Devin』の日本展開を開始  株式会社ディー・エヌ・エー  DeNA、Context Engineering、Claude CodeとGemini CLIで対話させると雑プロンプトでもかなりいい感じの出力が出る気がする、AIが情報収集する時にWebサイト側が料金を請求できる仕組みを発表「HTTP 402エラーが役に立つ日が来るとは」'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20250703
---

## 関連リンク


- [DeNA AI LinkがAIソフトウェアエンジニア『Devin』の日本展開を開始  株式会社ディー・エヌ・エー  DeNA](https://dena.com/jp/news/5269/)  


DeNAの子会社であるDeNA AI Linkが、革新的なAIソフトウェアエンジニア「Devin（デヴィン）」の日本展開を、開発元のCognition AI社との戦略的パートナーシップによって開始しました。この取り組みは、日本で課題となっているエンジニア不足の解消と、ソフトウェア開発現場の生産性向上を大きく進めることを目指しています。

Devinは、一般的なAIによるコード作成補助ツールとは一線を画し、ソフトウェア開発の全工程を自律的に実行できるのが最大の特徴です。具体的には、「どんなシステムを作るか（要件定義）」から「どう設計するか（設計）」、「実際にコードを書く（コーディング）」、「ちゃんと動くか確認する（テスト）」、そして「実際にサービスとして使えるようにする（デプロイ）」まで、AI自身が考えて一連のタスクをこなします。まるで、新しく優秀なエンジニアがチームに加わり、自律的にプロジェクトを進めてくれるようなイメージです。

Devinを導入することで、開発現場には大きな変化が期待されます。まず、エンジニア一人ひとりの生産性が劇的に向上し、同じ時間でより多くの機能を開発できるようになります。DeNA社内ではすでにDevinが先行導入されており、サービスの新規開発や技術調査、コード品質向上、日々の定型作業の自動化など、様々な場面で業務効率が「倍以上」になった実績が報告されています。例えば、数分の指示で高速にプロトタイプが完成したり、複雑なコードの仕様調査時間が大幅に削減されたりしています。

さらに、プログラミングの専門知識がない非エンジニアでも、Devinに分かりやすく指示を出すだけでコードを生成してもらえるようになります。これにより、アイデアをすぐに形にできる「モノづくり」の機会が広がり、開発の裾野が拡大することが期待されます。

Devinには、開発を強力にサポートする便利な機能が多数搭載されています。「Devin Wiki」は、既存のコードから自動でドキュメントや設計図を生成し、新規プロジェクトメンバーのオンボーディング（業務に慣れるための支援）を迅速にします。「Ask Devin」を使えば、コードについて質問すると対話形式で教えてくれるため、まるでベテランエンジニアに相談するかのようです。「Devin Playbook」は、繰り返しの開発タスク手順をテンプレートとして保存・共有できるため、誰でも同じ品質で作業を進められます。

DeNA AI Linkは、Devinの導入を検討している企業に対し、単にツールを導入するだけでなく、各企業のニーズに合わせた最適な活用方法のコンサルティングや、共同でのシステム開発、さらにはDevinを最大限に活用できるチーム作りまで、手厚くサポートしていくとのことです。

AIが単なるツールではなく、私たちと一緒に働く「パートナー」として開発を加速させる時代が到来しました。新人エンジニアの皆さんも、これからのAI技術の進化と、それによって変わる開発の常識にぜひ注目してみてください。

引用元: https://dena.com/jp/news/5269/


- [Context Engineering](https://blog.langchain.com/context-engineering-for-agents/)  


新人エンジニアの皆さん、今回はAIエージェント開発で非常に重要な「Context Engineering（コンテキストエンジニアリング）」という技術について解説します。

LLM（大規模言語モデル）は、一度に処理できる情報量に限りがあります。これを「コンテキストウィンドウ」と呼び、パソコンの「RAM（メモリ）」のようなものです。AIエージェントは複雑なタスクをこなすために、対話やツールの使用を通じて多くの情報（コンテキスト）を生成し続けます。情報が多すぎると、コンテキストウィンドウの限界を超えたり、コストが増えたり、処理が遅くなったり、LLMの性能が落ちて誤った回答をする問題が生じます。

Context Engineeringは、このコンテキストウィンドウに「エージェントが次のステップで本当に必要とする、最適な情報だけ」を効率的に詰め込むための「技術と工夫」です。これにより、エージェントの性能を最大限に引き出し、安定した動作を実現します。主な戦略は以下の4つです。

1.  **Write (書き出す)**:
    *   LLMのコンテキストウィンドウの外に、重要な情報を保存する戦略です。
    *   **スクラッチパッド**: 作業中のメモのように、一時的な情報を外部に記録し、必要なときに参照します。
    *   **長期記憶（メモリー）**: エージェントが過去の対話や経験から学習した内容を、複数のセッションにわたって記憶させる仕組みです。ユーザーとの対話を通じて記憶を保持する機能がその例です。

2.  **Select (選ぶ)**:
    *   保存された膨大な情報の中から、現在のタスクに最も関連性の高い情報だけを選び、コンテキストウィンドウに読み込む戦略です。
    *   RAG（検索拡張生成）などの技術を使って効率的に選び、LLMがノイズに惑わされずに本質的な情報に集中できるようにします。

3.  **Compress (圧縮する)**:
    *   コンテキストウィンドウ内の情報を要約したり、不要な部分を削ったりして、トークン数（LLMが言葉を数える単位）を減らす戦略です。
    *   **要約**: 長い対話履歴やツールの実行結果を、LLM自身に短いサマリーにまとめてもらう方法です。
    *   **トリミング**: 古いメッセージを削除するなど、単純なルールに基づいて情報を除去します。

4.  **Isolate (分離する)**:
    *   コンテキストを複数の部分に分割して管理する戦略です。
    *   **マルチエージェント**: 大きなタスクを複数のサブエージェントに分割し、それぞれが独自の小さなコンテキストを持つことで、全体の情報過多を防ぎます。
    *   **サンドボックスや状態オブジェクト**: ツール実行結果など、LLMに直接見せる必要のない重い情報を、隔離された環境や特定の変数に保存し、必要な部分だけを渡します。

これらのContext Engineeringの戦略を実装するには、LangGraphのようなフレームワークが役立ち、LangSmithでエージェントの動作を分析し、効果を測定することで、開発を効率的に進めることができます。

Context Engineeringは、高性能で賢いAIエージェントを作るための重要な技術です。ぜひ、この概念を理解し、今後のAI開発に役立ててください。

引用元: https://blog.langchain.com/context-engineering-for-agents/


- [Claude CodeとGemini CLIで対話させると雑プロンプトでもかなりいい感じの出力が出る気がする](https://zenn.dev/suthio/articles/9a44061200b733)  


この記事では、プログラマー向けのAIアシスタント「Claude Code」と、Googleの対話型AI「Gemini」のコマンドラインインターフェース（CLI）を連携させる、実践的なAI活用術が紹介されています。複数のAIを組み合わせることで、お互いの得意な部分を活かし、開発中のコードに対してより深く、多角的な分析や具体的な改善提案を引き出すことを目的としています。

この連携の主なアイデアは、まずClaude Codeがプロジェクトの状況（例えばGitリポジトリの変更点や履歴）を把握します。次に、その情報を元にGemini CLIと対話形式で議論を進める、というものです。これにより、単一のAIだけでは見逃しがちな問題点や、より良い解決策を発見し、実践的なアクションプランの生成を目指します。

具体的な連携のプロセスは以下の通りです。
1.  **状況の収集**: Claude Codeが、現在開発中のコードやGitの最新の変更点などのプロジェクト情報を集めます。
2.  **Geminiとの多角的な議論**: 集めた情報を活用し、Claude Codeはコードの設計、パフォーマンス、保守性、セキュリティ、ベストプラクティスなど、様々な観点からGeminiに質問を投げかけ、議論を開始します。この議論は複数回（例えば3〜5ラウンド）行われ、問題点の深掘りや代替案の検討、具体的なコード例の提示など、より詳細な検討が進められます。
3.  **アクションプランの生成**: Geminiとの議論で得られた洞察や提案に基づいて、Claude Codeが具体的な改善策をまとめた実行可能なアクションプランを作成します。この計画には、優先度の高い即時対応事項から、長期的な改善点までが含まれます。
4.  **議論ログの保存**: 一連の議論内容は、将来の参照や意思決定の記録として保存され、後から振り返ることができます。

この連携システムを利用するためには、事前にGemini CLIをインストールし、認証を済ませておく必要があります。

この手法の大きなメリットは、AI同士が協力し合うことで、たとえ指示（プロンプト）がざっくりしていても、かなり質の高い出力が期待できる点です。これにより、開発者はより効率的にコードの品質を高め、潜在的な問題を早期に発見し、開発プロセスをスムーズに進めるための強力なサポートを得られます。新人エンジニアの方々も、AIの力を最大限に引き出すためのヒントとして、ぜひ参考にしてみてください。

引用元: https://zenn.dev/suthio/articles/9a44061200b733


- [AIが情報収集する時にWebサイト側が料金を請求できる仕組みを発表「HTTP 402エラーが役に立つ日が来るとは」](https://togetter.com/li/2571125)  


Cloudflareが、AIクローラーがWebサイトの情報を収集する際に料金を請求できる新システム「Pay per crawl」を発表しました。この仕組みでは、これまでほとんど使われなかったHTTP 402エラー（支払いが必要）を活用し、AIクローラーからのアクセスを制御します。これにより、Webサイトのコンテンツ提供者は、AIによるデータ利用を管理し、収益を得る可能性が生まれます。日本のエンジニアの間では、この革新的なアプローチがWebとAIの関係をどう変えるか、大きな注目が集まっています。

引用元: https://togetter.com/li/2571125



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
