---
actor_ids:
  - 春日部つむぎ
audio_file_path: https://storage.googleapis.com/podcast-zund-arm-on-tech/audio/マジカルラブリー☆つむぎのピュアピュアA.I.放送局_podcast_20250512.mp3
audio_file_size: 0
date: 2025-05-12 05:00:00 +0900
description: 'What Every AI Engineer Should Know About A2A, MCP &amp; ACP、📝 AIエージェントの設計論：「Big Model」と「Big Workflows」、コマンドラインで生成AIを操作出来る「LLM」をOllama無料APIで使ってみた。簡単。｜パイプ処理やコマンド出力など自作スクリプトと組み合わせて日本語で実行。とても素晴らしい、『機動戦士Gundam GQuuuuuuX』マチュや『ウマ娘』シュヴァルグラン、ホッコータルマエなどのプライズフィギュアが秋葉原で展示！  電撃ホビーウェブ'
duration: "00:00"
layout: article
title: マジカルラブリー☆つむぎのピュアピュアA.I.放送局 podcast 20250512
image_url: https://zund-arm-on.com/images/tsumugi_podcast_thumbnail.png
thumbnail_url: https://zund-arm-on.com/images/tsumugi_podcast_thumbnail.png
card: summary
---

## 関連リンク


- [What Every AI Engineer Should Know About A2A, MCP & ACP](https://medium.com/@elisowski/what-every-ai-engineer-should-know-about-a2a-mcp-acp-8335a210a742)  

**
AIエージェント技術が進むにつれて、エージェント単体ではなく、複数のエージェントが互いに連携したり、外部のデータやツールを使ったりすることが増えてきます。これを実現するために、「通信プロトコル」という共通のルールが必要になります。この記事では、現在注目されている3つの主要なプロトコル、MCP、ACP、A2Aについて、新人エンジニア向けに分かりやすく解説します。

### MCP (Model Context Protocol)
MCPは、特に大規模言語モデル（LLM）が、外部にある様々な情報源（ファイル、データベース、Web APIなど）や、特定の機能を持つツールにアクセスするための標準規格です。LLMにすべての知識を持たせるのではなく、必要な情報を外部から取得したり、ツールを呼び出したりできるようになります。これは、AIエージェントが外部の世界と繋がり、具体的なタスクを実行するための「道具箱へのアクセス方法」を定義するようなものです。Anthropicが中心となって提案しています。

### ACP (Agent Communication Protocol)
ACPは、ローカル環境やエッジデバイス内で動作するAIエージェント同士が、低遅延でリアルタイムに通信し、協調するためのプロトコルです。クラウドサービスへの依存を減らし、ネットワークが不安定だったり、プライバシーが重要だったりする環境（例えば工場内のロボット連携やオンデバイスAI）での利用を想定しています。エージェントは自分の能力を公開し、他のエージェントとイベント駆動型で情報を交換します。同じ場所で働くエージェントたちの「内線電話」のようなイメージです。BeeAIとIBMが提案しました。

### A2A (Agent-to-Agent Protocol)
A2Aは、Googleが提案するプロトコルで、異なる企業やシステムで開発されたAIエージェントが、インターネットなどのネットワークを介して互いに発見し、安全に通信し、タスクを依頼し合うための標準です。エージェントは「Agent Card」という情報カードを公開し、互いの能力や接続方法を知ることができます。これにより、様々な場所で動くエージェントが連携して、より大きな目標を達成できるようになります。これは、世界中の異なる専門家がインターネットで繋がってプロジェクトを進めるための「グローバルなビジネスルール」のようなものです。

### まとめ：プロトコル間の関係
これらのプロトコルは、それぞれ異なる得意分野を持っています。A2Aは「エージェント同士」の広域連携、MCPは「AIと外部リソース・ツール」の連携、ACPは「ローカルなエージェント同士」の密な連携を担います。A2AとMCPは組み合わせて使われることが多く、エージェント間の連携（A2A）でタスクを依頼されたエージェントが、外部のデータやツール（MCP）を使ってタスクを実行する、といった形が考えられます。

AIエージェント開発にこれから関わるにあたり、これらのプロトコルがどのような課題を解決しようとしているのか、それぞれの役割は何なのかを知っておくことは、今後の技術トレンドを理解する上で非常に役立つでしょう。

文字数: 785

引用元: https://medium.com/@elisowski/what-every-ai-engineer-should-know-about-a2a-mcp-acp-8335a210a742


- [📝 AIエージェントの設計論：「Big Model」と「Big Workflows」](https://zenn.dev/r_kaga/articles/89e4659ca691bc)  


この記事は、OpenAIやLangChainなどの考え方を元に、AIエージェントの設計思想を比較検討したものです。AIエージェント開発には、「Big Model」と「Big Workflows」という二つの考え方があることが分かります。

「Big Model」は、高性能な大規模言語モデル（LLM）の能力を最大限に活かし、多くの判断や処理をモデルに任せるアプローチです。モデルの進化が速いので、シンプルな構成で早く始められるのが利点です。OpenAIはまず「シングルエージェント」という最も簡単な構成（LLMがツールを使ってタスクをこなす）から始めて、複雑になったら複数のエージェントを組み合わせる「マルチエージェント」に拡張していくことを推奨しています。

一方、「Big Workflows」は、処理の流れ（ワークフロー）をしっかりと設計し、各ステップを明確に定義するアプローチです。LangChainはこの考え方に近く、特にエージェントが次にどう動くかを判断するためにLLMに渡す「情報（コンテキスト）」を正確に制御・確認できることの重要性を強調しています。処理が見える化されていると、問題が起きたときに原因を特定しやすく、信頼性の高いシステムを作りやすいという考えです。

どちらのアプローチも一長一短あり、記事ではこれらは対立するものではなく、同じ「エージェントシステム」の異なる側面だと述べています。現実的には、PoC（Proof of Concept：技術検証）段階ではシンプルな「Big Model」寄りのアプローチで素早く試すのが有効であり、実際に運用する段階では信頼性や保守性の観点から「Big Workflows」のように処理を構造化したり、見える化したりすることが重要になると考えられます。

また、AIエージェントを開発するフレームワークを選ぶ際は、「簡単に始められるか（Low Floor）」と「複雑な要求にも対応できる拡張性があるか（High Ceiling）」の両方が重要だと指摘されています。つまり、最初は扱いやすいツールで始めつつも、将来的に複雑な処理が必要になったときに、内部の動きを細かく調整したり、人間が介入できる仕組み（Human-in-the-Loop）を組み込んだりできる柔軟な設計が大切です。

結論として、モデルの進化が速い現代では、「Big Model」と「Big Workflows」の良いところを取り入れ、状況に応じて設計を変えたり、モデルを別のものに差し替えたりできる「柔軟性」が、AIエージェント開発における重要なポイントであるとこの記事は示唆しています。

引用元: https://zenn.dev/r_kaga/articles/89e4659ca691bc


- [コマンドラインで生成AIを操作出来る「LLM」をOllama無料APIで使ってみた。簡単。｜パイプ処理やコマンド出力など自作スクリプトと組み合わせて日本語で実行。とても素晴らしい](https://posfie.com/@kapper1224/p/d42qhQX)  


この記事は、コマンドラインから生成AIを手軽に使うためのツール「LLM」と、ローカルでLLMを動かすための環境「Ollama」を組み合わせる方法を紹介しています。

「LLM」は、コマンドライン上で様々なAIモデルと対話できる汎用ツールです。Ollama以外にも多くのAPIに対応しており、無料のプラグインが豊富に用意されています。この記事では、インストールが比較的簡単な「llm-ollama」プラグインを使った手順が紹介されています。

まず、ローカル環境にOllamaをインストールし、使いたいLLMモデル（例: llama3.2）をダウンロードします。次に、pipxというツールを使って「LLM」本体とそのOllamaプラグインをインストールします。

使い方は簡単で、Ollamaでモデルを起動しておけば、別のターミナルから`llm -m [モデル名] '質問内容'`という形式でAIに質問できます。`-m`オプションを付けないとデフォルトでOpenAIなどに接続されるので注意が必要です。

この組み合わせの面白い応用例がいくつか紹介されています。例えば、日本語で「Linuxでストレージを表示」のように質問して、対応するLinuxコマンドを出力させたり、Linuxコマンドの実行結果（`uname -a`や`df -h`、`tcpdump`、`dmesg`の出力など）をパイプで「LLM」に渡して、その内容を日本語で解説させたり、RPG風のストーリーや犬猫の会話に変換させたりといった、ユニークな使い方も可能です。

さらに、シェルスクリプトと組み合わせて、日本語の指示でAIがLinuxコマンドを生成・実行するオリジナルのAIアシスタントのようなものを作成する例も示されており、コマンドラインツールとAIを連携させることで可能性が広がることを示唆しています。古いPCでは処理が重くなる場合もあるようですが、既存のコマンドライン操作とAIを組み合わせることで、開発や日々の作業に新しい発想を取り入れられることが伝わる内容です。

引用元: https://posfie.com/@kapper1224/p/d42qhQX


- [『機動戦士Gundam GQuuuuuuX』マチュや『ウマ娘』シュヴァルグラン、ホッコータルマエなどのプライズフィギュアが秋葉原で展示！  電撃ホビーウェブ](https://hobby.dengeki.com/news/2588372/)  


秋葉原のGiGO秋葉原5号館にて、2025年5月登場予定の新作プライズフィギュアが展示中です。「機動戦士Gundam GQuuuuuuX」のマチュ、「ウマ娘」のシュヴァルグランやホッコータルマエ、「東北ずん子・ずんだもんプロジェクト」のずんだもんなど、話題のキャラクターたちが勢揃い。秋葉原に行く機会があれば、チェックしてみてはいかがでしょうか。

引用元: https://hobby.dengeki.com/news/2588372/



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

VOICEVOX:春日部つむぎ
