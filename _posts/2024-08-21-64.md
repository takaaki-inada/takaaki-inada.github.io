---
actor_ids:
  - ずんだもん
audio_file_path: https://storage.googleapis.com/podcast-zund-arm-on/audio/株式会社ずんだもん技術室AI放送局_podcast_20240821.mp3
audio_file_size: 0
date: 2024-08-21 05:00:00 +0900
description: 'AIやテクノロジーに関する記事を紹介  
いい加減シェルスクリプトで [ $? -eq 0 ] や [ $? -ne 0 ] なんて エラー処理を書くのはやめよう！、1兆 (1T) パラメータ規模のLLMの事前学習検証 - Preferred Networks Research &amp; Development、RAGを専門用語に強くする手法「Golden-Retriever」'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20240821
information: 
---

## 関連リンク


- [いい加減シェルスクリプトで [ $? -eq 0 ] や [ $? -ne 0 ] なんて エラー処理を書くのはやめよう！](https://qiita.com/ko1nksm/items/09bd50e51cc8663a4f0e)  


シェルスクリプトで `[ $? -eq 0 ]` や `[ $? -ne 0 ]` を使ってエラー処理をするのは、冗長でデメリットしかありません。これは、コマンドの終了ステータスを直接利用することで、より簡潔にエラー処理を実現できるからです。

例えば、`cp` コマンドの成功・失敗を判定する場合、`if cp from to; then` のように、コマンド実行結果を直接 `if` 文に組み込むことで、終了ステータスをわざわざ `$?` で取得する必要はありません。

また、`grep` コマンドで文字列が見つかったかどうかを判定する場合も、`if echo test | grep '['; then` のように、コマンド実行結果を直接 `if` 文に組み込むことで、終了ステータスをわざわざ変数に格納する必要はありません。

このように、シェルスクリプトではコマンドの終了ステータスを直接利用することで、より簡潔で効率的なエラー処理を実現できます。`[ $? -eq 0 ]` や `[ $? -ne 0 ]` のような冗長なコードは避け、シェルスクリプトの本来の機能を最大限に活かしましょう。 


引用元: https://qiita.com/ko1nksm/items/09bd50e51cc8663a4f0e


- [1兆 (1T) パラメータ規模のLLMの事前学習検証 - Preferred Networks Research & Development](https://tech.preferred.jp/ja/blog/pretraining-1t/)  


Preferred Networksの子会社であるPreferred Elements (PFE)は、経済産業省のプロジェクト「GENIAC」の一環として、1兆パラメータ規模のLLMの事前学習検証を行いました。この検証では、MoE（Mixture of Experts）アーキテクチャを用いて、従来の手法では困難だった超巨大モデルの学習に挑戦しました。

検証の結果、メモリ消費量の削減とMoEの学習安定化という2つの課題に対処することで、1兆パラメータ規模のLLMの学習に成功しました。メモリ消費量の削減には、optimizer stateを低精度で保持する方法を採用しました。MoEの学習安定化には、Hash Layersと呼ばれる手法を用いてexpertの割り当てを学習から独立させることで、特定のexpertに偏った割り当てによる学習の停滞を防ぎました。

一方で、学習速度の向上とモデル性能の検証については、十分な成果を得ることができませんでした。学習速度の低下はMoEのメモリアクセス量が多いことによるものと考えられ、バッチサイズの増加による改善はメモリ消費量の制約から困難でした。また、モデル性能についても、学習データ量やMoEアーキテクチャの課題が考えられます。

今回の検証を通して、1兆パラメータ規模のMoEを用いたLLMの学習には、メモリ消費量、学習安定性、学習速度、モデル性能など、克服すべき課題が多く存在することが明らかになりました。PFEでは今後もLLMの開発を継続し、これらの課題解決に取り組んでいきます。


引用元: https://tech.preferred.jp/ja/blog/pretraining-1t/


- [RAGを専門用語に強くする手法「Golden-Retriever」](https://zenn.dev/knowledgesense/articles/90ac35eedf8b7c)  


この記事は、企業の社内用語や業界用語を理解し、RAG（Retrieval Augmented Generation）の精度を高める新しい手法「Golden-Retriever」について解説しています。

従来のRAGシステムは、専門用語を含む質問にうまく対応できませんでしたが、Golden-Retrieverは、質問に含まれる専門用語の意味を事前に用語集データベースで確認することで、より正確な回答を生成することを目指しています。

具体的には、ユーザーからの質問に専門用語が含まれている場合、その用語を抽出し、データベースで意味を明確化します。その後、その意味を考慮して文書検索を行い、RAGによる回答生成を行います。

Golden-Retrieverは、Meta-Llama-3-70BなどのLLMを用いた実験で、従来のRAGシステムと比べて回答精度が向上したことが示されています。

ただし、専門用語のデータベースを事前に用意する必要があり、生成速度が遅くなる可能性もある点は留意が必要です。

この記事では、Golden-Retrieverの詳細な仕組みや実験結果に加えて、企業がRAGシステムを構築する際に考慮すべき点についても触れられています。


引用元: https://zenn.dev/knowledgesense/articles/90ac35eedf8b7c



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
