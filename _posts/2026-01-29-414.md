---
actor_ids:
  - ずんだもん
audio_file_path: /audio/株式会社ずんだもん技術室AI放送局_podcast_20260129.mp3
audio_file_size: 0
date: 2026-01-29 05:00:00 +0900
description: 'We Got Claude to Build CUDA Kernels and teach open models!、「Google AI Plus」日本でも開始--月額1200円でGemini 3 Proや200GBドライブ付き（訂正）、GitHub CopilotでClaude Code（とCodex CLI）が使えるようになるぞ！、株式会社アイホンのHPの“よくあるご質問”のところに『iPhoneの調子が悪いです』という項目があって草「今までのFAQの中で1番好き」'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20260129
---

## youtube版(スライド付き)

<div class="article-video"><iframe src="https://www.youtube.com/embed/9iGumJKPpvk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></div>


## 関連リンク


- [We Got Claude to Build CUDA Kernels and teach open models!](https://huggingface.co/blog/upskill)  


Hugging Faceが公開したこの記事では、Claude Opusのような非常に高性能なモデル（ティーチャーモデル）を活用して、より小規模で安価なオープンソースモデル（スチューデントモデル）の能力を底上げする「エージェント・スキルのアップスケーリング」という手法と、それを支援する新ツール『upskill』を紹介しています。

### 1. 「エージェント・スキル」とは何か？
エージェント・スキルとは、LLMが特定の複雑なタスクを実行するための「指示書（Markdown形式）」や「スクリプト（コード）」をパッケージ化したものです。これにより、モデルのコンテキストを構造化し、異なるモデル間でも特定の専門能力を共有・再利用できるようになります。

### 2. 手法の核：ティーチャーからスチューデントへの知識移転
高度な専門知識が必要なタスク（例：CUDAカーネルの記述）において、以下のプロセスで小規模モデルを強化します。
- **スキルの生成:** まず、Claude Opus 4.5のようなSOTA（最先端）モデルに難しいタスクを解かせ、その過程（トレース）を記録します。
- **スキルの変換:** `upskill`ツールを使用して、そのトレースを汎用的な「スキルファイル」に変換します。
- **評価と検証:** 生成されたスキルをスチューデントモデルに適用し、性能が向上するかをベンチマークします。

### 3. 実践例：CUDAカーネルの構築
記事では、特に難易度の高い「NVIDIA H100 GPU向けの最適化されたCUDAカーネルの作成」を例に挙げています。
- 通常、H100のアーキテクチャ（Compute Capability 9.0）やメモリ共有の仕様など、最新のドキュメントを読み込むには数時間かかります。
- しかし、これらを「スキル」として500トークン程度に凝縮してLLMに与えることで、小規模なモデルでも適切なプロジェクト構造やPyTorchバインディングを生成できるようになります。
- 実験では、特定のオープンソースモデルにおいて、スキルを導入することでタスクの成功率が40%から85%へと劇的に向上しました。

### 4. エンジニアにとっての利点
- **コスト最適化:** 常に高価な高性能LLMを使うのではなく、一度スキルを作ってしまえば、日々の実行は安価なモデルやローカルLLMで行えるようになります。
- **トークン効率:** 闇雲に長いプロンプトを投げるのではなく、検証済みの「スキル」を読み込ませることで、トークン消費を抑えつつ精度を確保できます。
- **ナレッジの形式知化:** チーム内の特定のエンジニアしか持っていない「秘伝のタレ」のような知識を、LLMが利用可能なスキルとして保存・共有できます。

### 概要と制約
`upskill`ツールは、Hugging Faceのレポジトリから`pip install upskill`で導入可能です。
- **概要:** エージェントスキルの生成、テストケースの自動作成、複数モデル間での性能比較（精度・トークン消費量）を行うCLIツール。
- **制約:** 現時点ではAnthropic Claude Opus-4.5をデフォルトのティーチャーとして推奨していますが、OpenAIやローカルのOpenAI互換エンドポイントも利用可能です。また、スキルの効果はモデルによって異なり、高性能すぎるモデルにスキルを与えても逆にトークン消費が増えるだけのケースもあるため、事前の評価が重要です。

新人エンジニアの方にとっても、「高性能なAIに教官役をさせ、現場で使う軽量なAIを賢くする」というこのアプローチは、今後のAI活用における非常に実用的なパラダイムとなるでしょう。

引用元: https://huggingface.co/blog/upskill


- [「Google AI Plus」日本でも開始--月額1200円でGemini 3 Proや200GBドライブ付き（訂正）](https://japan.cnet.com/article/35243269/)  


Googleは2026年1月28日、最新のAI機能をパッケージ化した新しいサブスクリプションサービス「Google AI Plus」を日本国内で提供開始しました。月額1,200円という、エンジニアが個人開発や学習用として手っ取り早く導入しやすい価格設定ながら、Googleの最先端技術を凝縮した内容となっています。

### 1. 「Gemini 3 Pro」とリサーチ機能の強化
目玉となるのは、Googleの最新大規模言語モデル（LLM）である「Gemini 3 Pro」の利用権です。さらに、高度な調査・分析を支援する「Deep Research」機能も解放されます。新人エンジニアにとって特に注目なのは、情報整理ツール「NotebookLM」の拡張です。音声概要の作成やノートブックの利用上限が通常の5倍に引き上げられるため、技術ドキュメントの読み込みや学習効率が劇的に向上することが期待されます。

### 2. 強力なマルチモーダル生成機能
画像・動画生成の分野でも最新モデルが投入されました。
- **画像生成:** 「Nano Banana Pro」により、より精緻なビジュアル生成が可能。
- **動画生成:** 「Veo 3.1 Fast 6」へのアクセス権や、映画のようなシーンを作れる「Flow」、画像から動画を生む「Whisk」が利用可能です。これらに利用できる「AIクレジット」が毎月200付与されます。

### 3. Googleエコシステムとのシームレスな統合
エンジニアに馴染み深いGmailやGoogleドキュメント、Googleドライブなどのツール上で直接Geminiを呼び出せるようになります。さらに、200GBのクラウドストレージが付属しており、最大5人の家族と特典を共有できるなど、実用面でも非常にコストパフォーマンスの高い内容です。

### 4. ユーザーニーズに合わせた上位プランの展開
より高度なリソースを求める層向けに、2つの上位プランも用意されています。
- **Google AI Pro（月額2,900円）:** 2TBのストレージに加え、AIクレジットが毎月1,000に増量。
- **Google AI Ultra（月額36,400円）:** 30TBのストレージ、毎月25,000クレジット、YouTube Premiumも付帯する、プロフェッショナル・エンタープライズ向けの最高峰プランです。

### 5. 既存ユーザーへの対応と注意点
現在「Google One プレミアム（2TB）」を契約しているユーザーには、数日以内に「Google AI Plus」の特典が順次自動で提供されます。一点注意が必要なのは、このプランは個人のGoogleアカウントが対象であり、ビジネス・教育機関向けのGoogle Workspaceアカウントでは現在のところ利用できないという点です。

### 新人エンジニアへのメッセージ
Googleが提供する最新のAI環境が、ついに日本でも身近な価格で利用可能になりました。特に「Gemini 3 Pro」や「NotebookLM」の拡張は、日々のコーディングや技術キャッチアップの心強い味方になるはずです。最初の2カ月間は月額600円で利用できるキャンペーンも実施されているため、AIアシスタントを使いこなし、開発効率を一段上のレベルへ引き上げる絶好の機会といえるでしょう。

引用元: https://japan.cnet.com/article/35243269/


- [GitHub CopilotでClaude Code（とCodex CLI）が使えるようになるぞ！](https://zenn.dev/nuits_jp/articles/2026-01-28-claude-code-on-agent-hq)  


開発者の皆さんにとって、日々のコーディングを支える「GitHub Copilot」がさらに強力になる非常にワクワクするニュースが届きました。

2026年1月28日、GitHubが提供する「Agent HQ」というプラットフォームのInsiders（プレビュー版）環境において、Anthropic社が提供する強力なAIコーディングエージェント「Claude Code」が利用可能になりました。これにより、GitHub Copilotのプランを契約しているユーザーは、以下の3つのAIエージェントを使い分けられるようになります（※現在はプレビュー段階）。

1. **GitHub Copilot (& Copilot CLI)**: おなじみの標準的なコーディング支援ツール
2. **Codex CLI**: ターミナル操作を支援するエージェント
3. **Claude Code**: 高度な推論能力を持つClaudeベースのターミナル用AIエージェント

特に「Claude Code」は、ターミナル上で対話しながらファイル作成、コード編集、テストの実行などを自律的に行えるツールとして注目を集めています。これがGitHub Copilotの契約内で利用できるようになったことは、エンジニアの生産性を大きく引き上げる大きな一歩と言えます。

新人エンジニアの皆さんにとって注目すべきポイントは、複数の異なるAIモデルやエージェントが、一つのサブスクリプションでシームレスに統合され始めている点です。これまではツールごとに個別の契約が必要でしたが、今後はGitHubという開発基盤の上で、最適なAIを選択して開発を進めるスタイルが主流になっていくでしょう。

注意点として、現時点のGitHub Copilotのプランでは、Claude Codeをフル活用（大量のトークンを使用）する場合、一定規模を超えると従量課金が発生する可能性があるという課題があります。しかし、GitHubのCOOからは、ヘビーユーザー向けに「Maxプラン」の準備が進められていることも示唆されており、近いうちにコスト面を気にせず強力なAIエージェントを使い倒せる環境が整うことが期待されています。

AIエージェントを使いこなし、ターミナルから爆速で開発を進める未来がすぐそこまで来ています。今のうちからこれらのツールの進化をチェックしておくと、より効率的な開発ライフを送れるようになるはずです！

引用元: https://zenn.dev/nuits_jp/articles/2026-01-28-claude-code-on-agent-hq


- [株式会社アイホンのHPの“よくあるご質問”のところに『iPhoneの調子が悪いです』という項目があって草「今までのFAQの中で1番好き」](https://togetter.com/li/2657068)  


インターホン大手の株式会社アイホン公式サイトにある「iPhoneの調子が悪いです」というFAQが話題です。名前の類似からApple製品の相談が絶えないようですが、実は同社が日本での「iPhone」商標権を持ち、Appleにライセンス提供している背景があります。ユーモアを交えた丁寧な誘導は、新人エンジニアにとっても命名の重要性や商標、ユーザー体験の設計を考える上で学びのある事例です。

引用元: https://togetter.com/li/2657068



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
