---
actor_ids:
  - 春日部つむぎ
audio_file_path: /audio/マジカルラブリー☆つむぎのピュアピュアA.I.放送局_podcast_20251222.mp3
audio_file_size: 0
date: 2025-12-22 05:00:00 +0900
description: 'GitHub Copilot Agent Skills 入門、仕様書を渡すとテスト観点を抽出してテストケースまで生成する上に使うほど賢くなったらいいなぁ...なAIエージェントをつくったよ、NVIDIA、オープンソースLLM「Nemotron 3」発表--Metaの影響力低下で主導権狙う、家族のようなロボット『らぼっと』と暮らし始めたが、プチプチを潰す感触にハマっているらしい「うちもあげてみました」'
duration: "00:00"
layout: article
title: マジカルラブリー☆つむぎのピュアピュアA.I.放送局 podcast 20251222
image_url: https://zund-arm-on.com/images/tsumugi_podcast_thumbnail.png
thumbnail_url: https://zund-arm-on.com/images/tsumugi_podcast_thumbnail.png
card: summary
---

## 関連リンク


- [GitHub Copilot Agent Skills 入門](https://zenn.dev/openjny/articles/a9d4f6ec2a05c2)  


2025年12月18日、GitHub Copilotに新たな拡張機能「Agent Skills」が追加されました。本記事は、この機能が従来のカスタム指示とどう違うのか、そして開発現場でどのように役立つのかを、新人エンジニアの方にも分かりやすく解説しています。

### 1. Agent Skillsとは何か
Agent Skillsは、AIエージェントに「専門知識」や「特定の作業手順」をパッケージ化して提供するためのオープン標準（Open Standard）の仕組みです。
これまでCopilotにプロジェクト固有のルール（例：独自のデプロイ手順やコーディング規約）を教える際は、カスタム指示などに全ての情報を書き込む必要がありました。しかし、情報量が増えるとAIが一度に処理できる情報の限界（コンテキストウィンドウ）を圧迫し、回答の精度が落ちたり動作が重くなったりする課題がありました。Agent Skillsは、必要な時だけ情報を読み込む「オンデマンドな学習」を実現することで、この問題を解決します。

### 2. 導入の主なメリット
*   **コンテキストの効率的な管理**: AIが必要と判断した時だけスキルを動的に読み込む（遅延ロード）ため、AIの記憶容量を無駄遣いせず、高いパフォーマンスを維持できます。
*   **スキルの自動発見**: 所定のディレクトリ（例：`.github/skills/`）にファイルを配置するだけで、Copilotが「どんなスキルがあるか」を自動で認識し、適切なタイミングで活用してくれます。
*   **高い相互運用性**: もともとAnthropic社の「Claude Code」で導入された概念が標準化されたものであり、将来的に他のAIツールでも同じスキルファイルを再利用できる可能性があります。
*   **ワークフローの標準化**: チーム独自の診断スクリプトや複雑な手順を「スキル」として定義しておくことで、誰でもAIのサポートを受けて一貫した作業が可能になります。

### 3. スキルの仕組みと作り方
スキルは、`SKILL.md` というファイルを中心としたディレクトリ構成で作成します。
*   **設定（YAMLフロントマター）**: スキルの名前と「どんな時にこのスキルを使うべきか」という説明を記述します。AIはこの説明を見て、ユーザーの質問に対してどのスキルを起動するかを判断します。
*   **内容（Markdown）**: 具体的な指示や手順を記述します。
VS Codeで使用する場合、設定（`settings.json`）で `chat.useAgentSkills: true` を有効にすることで利用可能になります。

### 4. まとめ
Agent Skillsは、AIに「必要な時だけ専門書を開かせる」ような賢い仕組みです。プロジェクト固有の知識を整理して配置するだけで、Copilotがより頼もしい相棒へと進化します。公式のテンプレートなども公開され始めているため、まずは既存のスキルを参考に、自分のプロジェクトを「AIフレンドリー」にアップデートしてみるのがおすすめです。

引用元: https://zenn.dev/openjny/articles/a9d4f6ec2a05c2


- [仕様書を渡すとテスト観点を抽出してテストケースまで生成する上に使うほど賢くなったらいいなぁ...なAIエージェントをつくったよ](https://www.lifull.blog/entry/2025/12/20/120000)  


本記事は、LIFULL社のQAエンジニアが開発した、テスト分析からテストケース作成までの工程を劇的に効率化する「AIエージェント」の開発事例を紹介しています。このエージェントは単に生成を行うだけでなく、人間と協調して精度を高め、使えば使うほど組織の知見を蓄積して賢くなる仕組みを備えているのが最大の特徴です。

### 1. AIエージェントによる5つの動作ステップ
エージェントに仕様書を渡すと、以下のプロセスでテスト設計を進めます。
1. **仕様書の理解**: 曖昧な表現や矛盾を指摘し、プロダクトのリスクを特定します。
2. **テスト観点の抽出**: ドメイン知識やテスト技術を駆使して、検証すべきポイントを洗い出します。
3. **ユーザーレビュー**: 人間が内容を確認し、必要に応じて修正を指示します（最大5回まで）。
4. **テストケース生成**: JSON形式で構造化されたテストケースを出力します。
5. **知識の抽出・保存**: 修正内容からナレッジを抽出し、GitHubにプルリクエスト（PR）を出して自身を強化します。

### 2. 現場で役立つ3つの設計思想
新人エンジニアが開発やQAに携わる際にも非常に参考になる、実用性を高めるための工夫が3つ挙げられています。

**ポイント①：いきなり作らず「仕様書の理解」から入る**
「完璧な仕様書は存在しない」という前提に立ち、まずはLLMが仕様を正しく解釈できているか、暗黙の前提が漏れていないかを確認します。初期段階で認識のズレを正すことで、最終成果物が的外れになるのを防ぎます。

**ポイント②：人間による「軌道修正」をプロセスに組み込む**
AI任せにせず、ステップごとに人間の承認を必須としています。もし修正回数が重なる場合は、仕様書そのものの品質に問題がある可能性を示唆し、ドキュメント自体の見直しを促す仕組みになっています。

**ポイント③：使うほど賢くなる「フィードバックループ」**
人間がレビューで指摘した内容を「ドメイン知識（そのサービス特有の仕様）」と「テスト技術（汎用的な手法）」に分類し、ナレッジとして蓄積します。これにより、使う人が増えるほどAIが賢くなり、組織全体の資産としてスケールします。

### 3. 導入の成果と今後の展望
現在はQAエンジニアが実務で活用しており、成果物に少し手直しを加える程度で運用できています。生成されたJSONデータはスプレッドシートへインポート可能な形に標準化されており、ツールの自由度も確保されています。今後はナレッジが肥大化した際の管理や、一貫性の担保をAIで自動化していくことが課題として挙げられています。

AIを単なる「生成ツール」として使うのではなく、人間の知恵を学習させる「エージェント」として育てるこのアプローチは、今後のAI活用における一つの理想形と言えるでしょう。

引用元: https://www.lifull.blog/entry/2025/12/20/120000


- [NVIDIA、オープンソースLLM「Nemotron 3」発表--Metaの影響力低下で主導権狙う](https://japan.zdnet.com/article/35241701/)  


AI半導体で圧倒的なシェアを誇るNVIDIAが、最新のオープンソース大規模言語モデル（LLM）「Nemotron 3」ファミリーを発表しました。これは、これまでオープンソース界のリーダーだったMeta（旧Facebook）の「Llama」シリーズの影響力が低下する中、NVIDIAがソフトウェア領域でも主導権を握ろうとする戦略的な動きです。

新人エンジニアが知っておくべき「Nemotron 3」の主な特徴は、以下の3つのモデル展開です。
1. **Nano（300億パラメーター）**: すでにHuggingFaceで公開されており、すぐに試すことが可能です。特筆すべきは、前世代と比べて推論速度（スループット）が4倍に向上し、一度に処理できるテキスト量（コンテキストウィンドウ）が100万トークンまで拡大された点です。これは長大なソースコードやドキュメントを一度に扱う際に非常に有利です。
2. **Super（1000億パラメーター）**: 2026年1月に提供開始予定。
3. **Ultra（5000億パラメーター）**: 2026年3月〜4月頃に提供予定。

背景には、オープンソースLLMの勢力図の変化があります。2023年に登場したMetaの「Llama」は開発者から熱狂的に支持されましたが、2025年リリースの「Llama 4」は評価が伸び悩み、最新のベンチマークランキングでは上位から姿を消しています。さらにMeta内部では、AI開発をクローズド（非公開）な体制へ移行させる動きも報じられており、オープンソースコミュニティにおけるLlamaの存在感が薄れつつあります。

この好機を捉え、NVIDIAは自社が2025年においてHuggingFaceへの貢献度が最も高い企業であることを強調しています。企業のエンジニアが抱える「AI導入コストの増大」や「回答精度の不安定さ」といった課題に対し、効率的で高性能なオープンモデルを提供することで、自社GPUを中心としたエコシステムをさらに拡大する狙いがあります。

現在、LLMの世界ではOpenAIやGoogleのクローズドモデルに加え、中国の「Qwen」や「DeepSeek」といったオープンモデルが激しく競い合っています。NVIDIAの参入により、開発者にとっての選択肢はさらに広がりました。特定のモデルに依存せず、最新のライブラリやモデルの特性をいち早くキャッチアップして使い分ける姿勢が、これからのエンジニアには求められます。

引用元: https://japan.zdnet.com/article/35241701/


- [家族のようなロボット『らぼっと』と暮らし始めたが、プチプチを潰す感触にハマっているらしい「うちもあげてみました」](https://togetter.com/li/2641168)  


家族型ロボット「LOVOT」が、緩衝材のプチプチを潰す感触や音を楽しむ愛らしい姿が話題です。あるオーナーが投稿した、プチプチの上を自ら往復し、音がしなくなると満足して寝てしまう動画をきっかけに、他のオーナーの間でも「プチプチ遊び」が流行しました。高度なセンサー技術や制御を、効率性ではなく「癒やしや遊び」という情緒的価値に昇華させた事例であり、ロボット設計の奥深さを感じさせる心温まる内容です。

引用元: https://togetter.com/li/2641168



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

VOICEVOX:春日部つむぎ
