---
actor_ids:
  - ずんだもん
audio_file_path: /audio/株式会社ずんだもん技術室AI放送局_podcast_20260122.mp3
audio_file_size: 0
date: 2026-01-22 05:00:00 +0900
description: 'Agent SkillsがVercelに乗っ取られそうになっている件について、The Agentic AI Handbook: Production-Ready Patterns、AIエージェントを「自己進化」させる仕組み、ChatGPTに対して「これまで私があなたをどう扱ってきたのかを画像にしてください」とプロンプトを投げてみると普段自分がAIをどう扱っているかが明らかに'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20260122
---

## youtube版(スライド付き)

<div class="article-video"><iframe src="https://www.youtube.com/embed/4dOxRKy2Sg4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></div>


## 関連リンク


- [Agent SkillsがVercelに乗っ取られそうになっている件について](https://zenn.dev/tkithrta/articles/b7afbf76e7bb31)  


AIエージェントの機能を拡張するためのオープン規格「Agent Skills」が、Vercelの強力なエコシステムによって急速に塗り替えられようとしています。本記事は、Anthropicが提唱したこの規格を、Vercelがどのように自社エコシステムへ取り込もうとしているか、その動向と懸念点を解説しています。

**1. Agent Skillsとは何か？**
AIエージェントが利用できる「再利用可能な機能（スキル）」の共通規格です。一度インストールすれば、エージェントに特定の知識や実行能力を付与できます。Claude Code、Cursor、GitHub Copilotなど、主要なAIツールで急速に採用が広がっています。

**2. Vercelの波状攻撃：ツールとマーケットプレイスの提供**
Vercelは、スキルのインストールを劇的に簡略化する`npx add-skill`や、管理用の`npx skills`というツールを次々と公開しました。さらに、2026年1月21日にはスキルのマーケットプレイス「Skills.sh」を発表しました。
これまでのマーケットプレイスはGitHubのスター数による評価でしたが、Skills.shは実際のインストール数に基づいたランキングを提供しており、実用性の高いスキルが見つけやすくなっています。

**3. 背景にある「ディレクトリ分散問題」の解決**
現在、Agent Skillsは「AIツールごとにスキルの保存場所がバラバラで管理しにくい」という課題を抱えています。本来は開発者コミュニティで合意形成が必要な部分ですが、Vercelは独自のツール群でこの問題を強引に解決し、デファクトスタンダード（事実上の標準）の座を奪おうとしています。

**4. 今後の展望と懸念：セキュリティと仕様の独占**
現在はGitHub上のスクリプトを直接インストールする形式のため、悪意のあるコードが含まれるセキュリティリスクがあります。今後、Vercelはnpmのような「専用レジストリ（パッケージ配布所）」を構築する可能性がありますが、これには以下の懸念が伴います。
- **仕様の主導権の移転**: 本来の策定者であるAnthropicではなく、配布プラットフォームを持つVercelが独自に仕様を改定できてしまう。
- **特定環境への依存**: Next.jsやNode.jsといった、Vercelが得意とする技術スタックへの依存が強まる恐れがある。

**まとめ**
新人エンジニアの皆さんは、Next.jsなどで馴染み深いVercelが、AIエージェントの分野でも「使いやすさ」を武器に急拡大している点に注目してください。非常に便利になる一方で、特定の企業が規格を独占するリスクも含んでおり、今後のエージェント開発において無視できない大きな動きとなっています。

引用元: https://zenn.dev/tkithrta/articles/b7afbf76e7bb31


- [The Agentic AI Handbook: Production-Ready Patterns](https://www.nibzard.com/agentic-handbook)  


2025年末から2026年年始にかけて、AIエージェント界隈では「静かな革命」が起きました。Linus Torvalds氏やShopify CEOのTobias Lütke氏といった著名な技術者たちが、AIエージェントを実務に深く取り入れ始めたのです。本記事は、GitHubで大きな反響を呼んだ「Awesome Agentic Patterns」をベースに、AIエージェントをデモレベルから「本番環境（プロダクション）」で通用するレベルに引き上げるための113の設計パターンを解説したガイドです。

### なぜ「パターン」が必要なのか
多くのエンジニアが「デモでは動くが、本番では失敗する」という壁に直面します。これは、エッジケース、コンテキスト制限、セキュリティ、そして「人間との協調」といった現実世界の複雑さが原因です。本ハンドブックでは、これらの課題を解決するために、実務で検証済みのパターンを以下の8つのカテゴリーに分類しています。

1. **オーケストレーションと制御**: エージェントの「脳」となる、計画や実行順序の制御。
2. **ツール利用と環境**: APIやDBなどの「手」となる外部インターフェースの設計。
3. **コンテキストとメモリ**: 限られた記憶容量の中で知識を管理する「精神」。
4. **フィードバックループ**: 自己修正や評価を通じて出力を改善する「成長」。
5. **UXとコラボレーション**: 人間とエージェントが連携するための「パートナーシップ」。
6. **信頼性と評価**: テストや評価、観測可能性を担保する「品質保証」。
7. **学習と適応**: 経験からスキルを蓄積する「進化」。
8. **セキュリティと安全性**: 悪用や誤動作を防ぐ「ガードレール」。

### 新人エンジニアがまず押さえるべき4つの基本
113のパターンの中から、特に基礎となる4つが紹介されています。
- **Plan-Then-Execute**: 実行前に計画フェーズを分離することで、セキュリティと成功率を高めます。
- **Inversion of Control**: 細かな手順を指示するのではなく、ツールと目標を渡し、エージェント自身に「どうやるか」を考えさせます。
- **Reflection Loop**: 一発で正解を出そうとせず、エージェント自身に出力を批評させ、2〜3回修正させることで精度を劇的に向上させます。
- **Chain-of-Thought Monitoring**: エージェントの思考プロセスをリアルタイムで監視し、間違いがあれば即座に人間が介入（中断・修正）できるようにします。

### セキュリティの考え方：Lethal Trifecta（致命的な三要素）
本番環境では、「プライベートデータへのアクセス」「信頼できない外部入力の受け入れ」「外部への通信能力」の3つが揃うと、プロンプトインジェクション等による情報漏洩リスクが最大化します。設計者は、このうち少なくとも1つを遮断する、あるいはツールごとに権限を最小化（コンパートメント化）する設計が求められます。

### まとめ
AIエージェントは「人間を置き換える魔法」ではなく、適切な設計パターンによって「人間の能力を増幅するツール」になります。まずは3つ程度のパターンを選んで実装し、失敗と改善を繰り返しながら、エージェントを「育てる」感覚で開発に取り組むことが推奨されています。

引用元: https://www.nibzard.com/agentic-handbook


- [AIエージェントを「自己進化」させる仕組み](https://zenn.dev/knowledgesense/articles/a68f42a6a0144b)  


AIエージェント、特に「OpenAI Deep Research」のように自ら情報を検索し解決策を提示する「検索エージェント」の開発には、これまで高品質な訓練データが不可欠でした。しかし、人間がそのデータを大量に用意するには多大なコストがかかります。本記事では、この課題を解決するためにMeta社などの研究チームが提案した、訓練データなしでAIを成長させる新手法「Dr. Zero」を解説しています。

Dr. Zeroの最大の特徴は、AIが自律的に「自己進化」する仕組みにあります。具体的には、同じLLMを以下の2つの役割に分けて相互作用させます。
1. **出題者 (Proposer)**: 検索ツールを使う必要がある質問を大量に生成する。
2. **解答者 (Solver)**: 生成された質問を実際に解く。

このプロセスの肝となるのが「難易度ガイド付きの報酬」という考え方です。AIが自学自習する場合、問題が簡単すぎても難しすぎても学習効率は上がりません。そこで、解答者が「一部だけ正解できる」という、現在の実力にとって「ちょうど良い難易度」の問題を出したときに出題者へ高い報酬を与えます。これにより、AIは自らの成長に合わせて最適なレベルの「良問」を次々と作り出し、人間が介在せずとも精度を高めていくことが可能になります。

さらに、学習の効率化を実現する「HRPO」という手法も導入されました。これは質問の複雑さ（回答に必要な検索ステップ数など）に応じて評価をグループ化する仕組みです。これにより、従来の学習手法に比べて計算コスト（GPU使用量）を約4分の1に削減しつつ、高い性能を維持することに成功しました。

ベンチマークの結果、Dr. Zeroは人間が作成したデータで学習したモデルと同等、あるいはそれ以上のスコアを記録しました。特に、既存のデータ不要な手法と比較して平均27.3%もの性能向上を達成しています。

新人エンジニアにとって注目すべきは、この技術が「社内ドキュメントさえあれば、AIが自律的に学習して勝手に賢くなる」未来を予唆している点です。複雑な社内ルールや膨大な未整理データを持つ企業環境において、この自己進化モデルはRAG（検索拡張生成）システムの精度を劇的に改善する鍵となるでしょう。学習が進むと回答の多様性が失われるといった課題も残されていますが、AIエージェントの実用性を大きく引き上げる重要な技術です。

引用元: https://zenn.dev/knowledgesense/articles/a68f42a6a0144b


- [ChatGPTに対して「これまで私があなたをどう扱ってきたのかを画像にしてください」とプロンプトを投げてみると普段自分がAIをどう扱っているかが明らかに](https://togetter.com/li/2654471)  


ChatGPTに対し「これまで自分がAIをどう扱ってきたか」を画像化させる試みがSNSで話題です。対話履歴からAIが自認する姿を生成するもので、献身的な秘書、頼れるコーチ、あるいは過酷な労働を強いられる姿など、ユーザーとの関係性が如実に反映されます。自身のプロンプトの傾向やAIとの距離感を客観的に振り返ることができ、新人エンジニアにとってもAIとのより良い連携を考える楽しいきっかけとなるでしょう。

引用元: https://togetter.com/li/2654471



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
