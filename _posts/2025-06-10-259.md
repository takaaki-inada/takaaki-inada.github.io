---
actor_ids:
  - ずんだもん
audio_file_path: /audio/株式会社ずんだもん技術室AI放送局_podcast_20250610.mp3
audio_file_size: 0
date: 2025-06-10 05:00:00 +0900
description: 'OpenSearch 3.0 でMCPによるAgentとの連携を行ってみる、The no-nonsense approach to AI agent development - Vercel、Apple supercharges its tools and technologies for developers to foster creativity, innovation, and design'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20250610
---

## 関連リンク


- [OpenSearch 3.0 でMCPによるAgentとの連携を行ってみる](https://acro-engineer.hatenablog.com/entry/2025/06/09/120000)  


この記事では、OpenSearch 3.0の最新機能、特に「MCP（Model Context Protocol）」を活用したAIエージェントとの連携方法について、新人エンジニアの方にも分かりやすく解説されています。

OpenSearchは、大量のデータの中から必要な情報を素早く探し出すための、強力な検索エンジン（データベースの一種）です。今回リリースされたバージョン3.0では、AI技術との連携が大きく進化しました。中でも注目すべきは、AIエージェントが外部のデータやツールとスムーズにやり取りするための共通ルールであるMCPに、OpenSearchが標準で対応した点です。これにより、OpenSearchは単なる検索システムから、より賢く、幅広い情報に対応できるプラットフォームへと進化しています。

OpenSearch 3.0の主な更新点は以下の通りです。
1.  **MCP（Model Context Protocol）への標準対応**: AIエージェントとの連携を容易にします。
2.  **検索性能の大幅向上**: Lucene 10やJDK 21へのアップグレードにより、特にAI関連で重要な「ベクター検索」の速度が改善しました。ベクター検索とは、言葉の意味の近さを基に情報を探す高度な検索方法です。
3.  **データ分析機能の強化**: PPL（Piped Processing Language）というデータ分析言語が強化され、ログの相関分析などがしやすくなりました。
4.  **ダッシュボード機能の強化**: 「Workspaces」という機能が追加され、ユーザーごとにカスタマイズされたデータ表示画面を提供できるようになりました。

記事では、このMCP連携の具体的な2つのパターンが紹介されています。

**1. OpenSearchから外部のMCPサーバーを利用する構成**
このパターンでは、OpenSearchが「質問役」となり、外部にあるAIエージェント（MCPサーバー）に情報を問い合わせます。例えば、OpenSearchに投げられた質問に対して、AIエージェントがAWSの公式ドキュメントを参照して回答するといった使い方ができます。これにより、OpenSearchの内部データだけでなく、外部の豊富な情報源も合わせて活用できるようになります。

**2. 外部のMCPサーバーからOpenSearchを呼び出す構成**
こちらは反対に、外部のAIエージェントが「質問役」となり、OpenSearch内のデータを参照するパターンです。記事では、Claude DesktopのようなAIアシスタントがOpenSearchに蓄積された商品データに対して質問を投げかけ、適切な回答を得る例が示されています。これにより、既存のOpenSearchに保存されている大事なデータを、AIエージェントから簡単に活用できるようになります。

このように、OpenSearch 3.0のMCP対応は、AIエージェントがOpenSearchのデータや機能をより柔軟に利用できる道を開きます。システム全体として、AIがより賢く、ユーザーの要求に応えられるようになるため、今後のAI活用の幅がさらに広がるでしょう。

引用元: https://acro-engineer.hatenablog.com/entry/2025/06/09/120000


- [The no-nonsense approach to AI agent development - Vercel](https://vercel.com/blog/the-no-nonsense-approach-to-ai-agent-development)  


この記事は、AIエージェントの開発を、新人エンジニアでも理解しやすいよう、実践的かつ分かりやすい3ステップで解説しています。

AIエージェントとは、これまで人手で行っていた、複数のステップと判断が必要な複雑なタスクを自動化するソフトウェアシステムです。従来の自動化では難しい、文脈理解や状況判断、適応力が求められる作業に向いています。最も効果的なAIエージェントは、特定の領域に特化し、目的を狭く絞り込むことで実現できます。

AIエージェント開発は、次の3つのステップで進められます。

**ステップ1：手動でプロトタイプを作る**
まず、コードを書く前に、人間がタスクを行うように手作業でエージェントの動きをシミュレーションします。具体的な入力データを使って、大規模言語モデル（LLM）にプロンプトを手動で与え、タスクを最後まで進めてみます。この過程で、繰り返し行われる機械的な作業を見つけ出し、どこを自動化できるかを見極めます。もし、この段階でLLMがうまくタスクを完了できないようであれば、そのタスクはAIエージェント向きではないかもしれません。

**ステップ2：タスクのループを自動化する**
手動シミュレーションでタスクが実行可能だと分かったら、いよいよコードを書き始めます。ここでは、エージェントの基本的な骨格を構築します。入力データの収集（APIやスクレイパーなど）を自動化し、タスクのプロセスをループや状態機械としてコードに落とし込みます。特に重要なのは、LLMの役割を明確にすることです。LLMは推論や判断が必要な部分にのみ使用し、データ解析や計算、ソートといった決定的（常に同じ結果が得られる）な処理は、通常のプログラミングコード（`if`文やループなど）で実装します。AIエージェント開発も、通常のソフトウェア開発の原則に沿って進めることが強調されています。

**ステップ3：信頼性を最適化する**
エージェントがエンドツーエンドで動作するようになったら、次は品質と信頼性の向上に注力します。プロンプトを洗練させ、ツールの呼び出しをより正確にし、不要なリトライを減らします。LLMが提供する結果の精度が低い場合は、別のLLMを使って結果を批判的に評価し、改善を促すことも有効です。手動でのテストに加え、さまざまな種類の入力データやエッジケースに対するパフォーマンスを評価するために、構造化された評価（テストスイートのようなもの）を導入し、品質の維持と向上が図られます。

まとめると、AIエージェント開発は、通常のソフトウェア開発の基本原則（明確なロジック、良い構造、密なフィードバックループ）に基づいて行われます。実装前に手動でテストし、LLMを本当に必要な判断部分にのみ活用し、そして徹底的に品質をテストすることで、信頼性の高いエージェントが構築できるのです。

引用元: https://vercel.com/blog/the-no-nonsense-approach-to-ai-agent-development


- [Apple supercharges its tools and technologies for developers to foster creativity, innovation, and design](https://www.apple.com/newsroom/2025/06/apple-supercharges-its-tools-and-technologies-for-developers/)  


Appleは先日、開発者向けのツールと技術を大幅に強化すると発表しました。これは、世界中の開発者がより創造的で革新的なアプリを効率的に作れるようにするためのものです。特に、AIやLLM（大規模言語モデル）の活用が注目されています。

主な強化点は以下の通りです。

1.  **Apple Intelligenceの活用**:
    *   開発者は、Appleデバイス上で動作するAIモデル「Apple Intelligence」をアプリに組み込めるようになります。これはオフラインでも使え、プライバシー保護を重視しています。
    *   Swift言語でわずか数行のコードを書くだけで、このAIモデルの生成能力（テキスト生成など）をアプリに簡単に組み込めます。

2.  **Xcode 26の進化**:
    *   開発ツール「Xcode 26」に、ChatGPTなどのLLMを直接統合できるようになります。これにより、コードの自動生成、テストコードの作成、ドキュメント生成、エラー修正などがAIの助けを借りて行えるようになり、開発効率が大きく向上します。
    *   「Liquid Glass」という新しいデザインが導入され、アプリのUI（ユーザーインターフェース）がより美しく、統一感のある体験を提供できるようになります。
    *   新しい「Icon Composer」アプリを使えば、開発者が視覚的に魅力的なアプリアイコンを簡単に作成できます。
    *   「Coding Tools」は、開発者がコードを書く際に適切なアクションを提案し、作業の流れをスムーズにします。

3.  **App Intentsの強化**:
    *   アプリの機能とSiriやSpotlightなどのシステム機能をより深く連携させる「App Intents」が進化。特に「ビジュアルインテリジェンス」に対応し、画像検索結果から直接アプリにアクセスできるようになります。

4.  **プログラミング言語Swiftの進化**:
    *   「Swift 6.2」がリリースされ、パフォーマンスの向上、並行処理（複数の処理を同時に実行する）の記述の簡素化、そしてWebAssemblyへの対応が強化されました。これにより、より高速で安定したアプリ開発が期待できます。

5.  **コンテナ技術への対応**:
    *   「Containerization framework」が提供され、Mac上で直接Linuxのコンテナイメージを作成・実行できるようになります。これは開発環境の構築や管理を効率化します。

6.  **ゲーム開発ツールの強化**:
    *   「Game Porting Toolkit 3」で、WindowsからMacへのゲーム移植を効率化するためのツールが改善。
    *   「Metal 4」では、Appleシリコンに最適化されたグラフィック技術が進化し、リアルタイムレイトレーシングなど、より高品質なゲーム表現が可能になります。
    *   「Apple Games」アプリや「Game Overlay」といった新機能で、プレイヤー間の交流やゲーム体験をさらに豊かにする仕組みが提供されます。

7.  **子どものオンライン保護とApp Storeの改善**:
    *   「Declared Age Range API」により、開発者は子どもの年齢に応じた適切なコンテンツを提供できるようになり、保護者による設定でプライバシーも守られます。
    *   App Storeのアプリ詳細ページに「Accessibility Nutrition Labels」が追加され、アプリがどのようなアクセシビリティ機能をサポートしているか利用者が事前に確認できるようになります。

これらの強化により、Appleは開発者がより高度な機能と魅力的なデザインを持つアプリを、これまで以上に効率的に開発できる環境を提供し、ユーザー体験の向上を目指しています。

引用元: https://www.apple.com/newsroom/2025/06/apple-supercharges-its-tools-and-technologies-for-developers/



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
