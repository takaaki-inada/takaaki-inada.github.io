---
actor_ids:
  - ずんだもん
audio_file_path: /audio/株式会社ずんだもん技術室AI放送局_podcast_20250820.mp3
audio_file_size: 0
date: 2025-08-20 05:00:00 +0900
description: 'URL context tool for Gemini API now generally available、Generate Images with Claude and Hugging Face、ClaudeCodeで挑むコンテキストエンジニアリング実践、コールセンターはAIに代替されない？「コールセンターに電話してくる人の9割以上は自分の問題を言語化できてないから」→さまざまな意見集まる'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20250820
---

## 関連リンク


- [URL context tool for Gemini API now generally available](https://developers.googleblog.com/en/url-context-tool-for-gemini-api-now-generally-available/)  


Googleは、AI開発者向けの「Gemini API」で利用できる「URLコンテキストツール」を一般公開しました。このツールを使うと、AIモデルにウェブページの情報やドキュメントの内容を、より簡単かつ深く理解させられるようになります。

これまでのGeminiモデルは、インターネットに直接アクセスする機能が限定的でした。既存の「Grounding with Google Search」は、検索結果の短い断片しか扱えませんでしたが、今回のURLコンテキストツールは、指定したウェブページ全体のコンテンツをAIモデルが分析できるようになります。これにより、AIがより多くの文脈を理解し、複雑な情報を扱えるようになるのが大きな特徴です。

今回のリリースで、このツールは読み込めるコンテンツの種類が大幅に増えました。
*   **PDFファイル**: PDFのリンクを指定するだけで、AIがテキストだけでなく、表や文書の構造まで理解できるようになります。報告書やマニュアルの分析に便利です。
*   **画像ファイル**: PNGやJPEGなどの画像も処理できるようになり、グラフや図表といった視覚情報もAIが理解し、分析できるようになります。Geminiの画像認識能力が、ウェブ経由で活用できるようになったイメージです。
*   **その他**: 標準的なHTMLページはもちろん、JSONやCSVといった構造化データ、各種テキストファイルも引き続きサポートします。

このツールは、大規模な開発利用にも対応できるよう準備が整いました。利用するGeminiモデルに応じて処理能力（レート制限）が設定され、コストも明確になったため、安心して開発を進められます。

URLコンテキストツールは、開発者が新しいAIアプリケーションを作る可能性を広げます。例えば、以下のような用途が考えられます。
*   **顧客対応の高度化**: 顧客のウェブサイト情報をAIチャットエージェントに読み込ませることで、より的確なサポートを提供できます。
*   **ドキュメントの比較・要約**: 複数のレポートや記事、PDFをAIに分析させ、違いを見つけたり、内容をまとめたりできます。
*   **コンテンツ作成の支援**: 複数の情報源となるURLから情報を集約し、要約やブログ記事などを自動で生成できます。
*   **コード・技術文書の理解**: GitHubリポジトリや技術文書のURLを指定するだけで、コードの説明を生成させたり、技術的な質問に答えさせたりできます。

このツールはすでに、オープンソースのGemini CLIや顧客サービスプラットフォームのGladly.aiなどで活用されており、よりスマートなAI体験の実現に貢献しています。今回の一般公開により、多くの開発者がこの強力な機能を使いこなし、様々な課題を解決するAIアプリケーションを生み出すことが期待されます。

引用元: https://developers.googleblog.com/en/url-context-tool-for-gemini-api-now-generally-available/


- [Generate Images with Claude and Hugging Face](https://huggingface.co/blog/claude-and-mcp)  


この記事では、AnthropicのAIチャットボット「Claude」と、AIモデルやアプリケーションが公開されているプラットフォーム「Hugging Face Spaces」を連携させることで、高品質な画像を簡単に生成できるようになる方法が紹介されています。この連携により、最新のAI画像生成モデルを非常に手軽に利用できるようになるのが大きな特徴です。

この連携には主に3つのメリットがあります。
1.  **プロンプト作成支援**: AIが画像生成のための詳細な指示文（プロンプト）の作成を手伝ってくれるため、より質の高い画像を効率的に生成しやすくなります。
2.  **画像生成の反復改善**: 生成された画像をAI自身が確認し、デザインや表現方法を改善するためのアドバイスをしてくれるため、理想の結果にスムーズに近づけられます。
3.  **最新モデルの活用**: 状況や目的に合わせて、最新のAIモデルや最適なモデルを簡単に切り替えて使えるため、常に最先端の技術を試すことができます。

この機能を利用するには、まず無料のHugging Faceアカウントを作成し、Claudeのチャット入力画面にある「Search and tools」メニューからHugging Faceを接続するだけです。この連携の裏側では、Hugging Faceの「MCP Server」という技術が使われており、効率的にGPUを利用できる「ZeroGPU」という仕組みが、大規模なAIモデルの動作を支えています。Hugging Faceアカウントには、これらの強力なモデルを無料で利用するためのクレジットも付与されます。

記事では特に二つの先進的な画像生成モデルが紹介されています。
一つ目は「**FLUX.1 Krea [dev]**」です。このモデルは、AIが生成した画像によく見られる不自然さ（例えば、不自然に滑らかな肌や過度に鮮やかな色など）をなくし、まるでプロのカメラマンが撮影したかのような、自然でリアルな画像を作ることに特化しています。風景や人物など、写実的な表現が求められる場合に非常に役立ちます。

二つ目は「**Qwen-Image**」です。このモデルは、プロンプトの指示に忠実に画像を生成する能力と、画像内のテキスト（文字）を非常に正確にレンダリングする点に優れています。そのため、ポスターや看板、インフォグラフィック、マーケティング資料など、画像の中に正確な文字を入れたい場合に最適です。また、Qwen-Imageには、より良いプロンプトを作成するための「Prompt Enhancer」という支援機能も備わっています。

これらのモデルは、Hugging FaceのMCP設定ページから簡単に追加・有効化でき、Claudeに指示を出すだけで利用可能です。両方のモデルを同時に有効にして、同じプロンプトで生成された画像を比較するといった使い方も試せます。

ClaudeとHugging Face Spacesの連携は、最先端のAIモデルを使った画像生成を、専門知識がなくても手軽に、かつ高品質に行えるようにする画期的な進歩です。Hugging Face Spacesには画像生成以外にも、動画生成やWeb検索、画像編集など様々なAIアプリケーションが公開されており、新人エンジニアの方々もこれを活用して、様々なアイデアを形にするプロジェクトに挑戦できるでしょう。

引用元: https://huggingface.co/blog/claude-and-mcp


- [ClaudeCodeで挑むコンテキストエンジニアリング実践](https://zenn.dev/aki_think/articles/66f6fc7530467a)  


この記事は、LLM（大規模言語モデル）を使った開発で、従来の「プロンプトエンジニアリング」から「コンテキストエンジニアリング」へとアプローチが変化している背景と、ClaudeCodeの「サブエージェント」機能を活用した実践方法を、新人エンジニア向けに解説します。

初期のLLMは、漠然とした指示だと意図しない回答をすることがあり、プロンプト（指示文）の工夫が重要でした。しかし、LLMの推論能力が向上した今、重要なのは「どう指示するか」よりも「AIにどんな文脈（情報）を与えるか、与えないか」というコンテキストの設計です。これが「コンテキストエンジニアリング」と呼ばれる新しい考え方です。

コンテキストエンジニアリングが重要になったのは、LLMの「コンテキストウィンドウの限界」や「不要な情報による性能低下」という課題があるためです。LLMとのやり取りが長くなったり、関係ない情報が混じったりすると、AIの応答品質が悪くなる「コンテキスト汚染」が起こります。開発現場では、多くの情報（仕様書、既存コードなど）を参照する中で、意図せずこの汚染が発生しがちです。

このコンテキスト汚染を解決する強力な手段が、ClaudeCodeの「サブエージェント」機能です。サブエージェントは、メインの作業プロセスとは独立したコンテキストで動作します。例えるなら、プログラミングの「純粋関数」のように、入力に対して結果を返すだけで、メインのコンテキストを汚しません。これにより、AIが常にクリーンで関連性の高い情報だけを参照できるようになります。

具体的な活用例としては、以下が挙げられます。
*   **実装計画の立案**: 大量の情報調査が必要な計画作りをサブエージェントに任せ、メインには完成した計画だけを受け取る。
*   **不具合修正**: 過去の試行錯誤による情報に引きずられず、ゼロから問題に取り組ませる。
*   **コードレビュー**: 実装の詳細に捉われず、客観的な視点でのレビューを依頼する。

サブエージェントは、タスクの性質に応じてOpus（高度な思考）やSonnet（速度重視）といったモデルを使い分け可能です。作成も簡単で、「PRを作成するエージェントを作って」のように自然な言葉で指示するだけで、ClaudeCodeが自動生成してくれます。

LLMとの協働を効率的に進めるためのベストプラクティスとしては、タスクを細かく分解し、「過程は不要で結果だけ欲しい」独立したタスクはサブエージェントに任せること。また、長時間の作業でコンテキストが汚染されてきたと感じたら、重要な情報を保存し、一度セッションをリセットしてクリーンな状態から再開することも効果的です。

コンテキストエンジニアリングは、LLMとの開発効率と品質を高める上で不可欠な技術です。ClaudeCodeのサブエージェント機能を活用し、ぜひ自分なりの実践方法を見つけてみてください。まずは簡単なサブエージェントを一つ作ってみることから始めてみましょう。

引用元: https://zenn.dev/aki_think/articles/66f6fc7530467a


- [コールセンターはAIに代替されない？「コールセンターに電話してくる人の9割以上は自分の問題を言語化できてないから」→さまざまな意見集まる](https://togetter.com/li/2591419)  


コールセンター業務はAIに代替されにくいという意見があります。その理由として、電話してくる人の大半が自分の問題を明確に言葉にできない点が挙げられます。人間オペレーターは、顧客の言葉の裏を読み取る「エスパー能力」や経験による「パターン認識」で状況を把握し解決しています。AIはFAQ提示などで活用されますが、複雑な状況判断や刻々と変わるトレンドへの対応はまだ難しいとされています。AIと人間の適切な役割分担が、顧客対応の効率化と品質向上の鍵となりそうです。

引用元: https://togetter.com/li/2591419



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
