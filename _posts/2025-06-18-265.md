---
actor_ids:
  - ずんだもん
audio_file_path: https://storage.googleapis.com/podcast-zund-arm-on/audio/株式会社ずんだもん技術室AI放送局_podcast_20250618.mp3
audio_file_size: 0
date: 2025-06-18 05:00:00 +0900
description: 'Building Effective AI Agents、How to think about agent frameworks、We’re expanding our Gemini 2.5 family of models、四国めたんのプラモデルにミニフィギュア同梱版が登場！6月19日（木）10時より予約開始！PLUM WEB SHOP限定でミニフィギュアの単品販売も！  電撃ホビーウェブ'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20250618
---

## 関連リンク


- [Building Effective AI Agents](https://www.anthropic.com/engineering/building-effective-agents)  


Anthropicは、LLM（大規模言語モデル）エージェント構築の経験から、効果的なAIエージェントを作るためのヒントを共有しています。多くの成功事例では、複雑なフレームワークよりも、シンプルで組み合わせやすいパターンが使われていることが分かりました。

## エージェント的システムとは
「エージェント」には様々な定義がありますが、AnthropicではLLMとツールを組み合わせたシステム全体を「Agentic systems（エージェント的システム）」と呼んでいます。その中で、特に重要な2つのタイプを区別しています。

*   **Workflows（ワークフロー）**: 事前に決められた手順（コードパス）に沿ってLLMとツールを動かすシステムです。
*   **Agents（エージェント）**: LLM自身がタスクの進め方やツールの使い方を、状況に応じて動的に判断し、制御するシステムです。

## エージェントを使うべきケースとそうでないケース
LLMアプリケーションを作る際は、まず最もシンプルな方法から試し、本当に必要になった場合にだけ複雑なシステムを導入することが推奨されます。エージェント的システムは、より良いタスク性能を目指す一方で、処理が遅くなったり、コストがかさんだりするトレードオフがあるため、そのバランスを考える必要があります。

*   **ワークフロー**は、手順が明確で、予測可能で安定した動作が必要なタスクに適しています。
*   **エージェント**は、タスクが複雑で、柔軟性やLLM自身が判断を下す能力が大規模に求められる場合に有効です。

しかし、多くのケースでは、LLMへの一度の問い合わせを最適化するだけで十分な結果が得られることもあります。

## フレームワークの活用について
LangGraphやAmazon BedrockのAI Agentフレームワークなど、エージェントシステムの開発を助けるツールが多数存在します。これらは、LLMの呼び出しやツールの定義、処理の連携といった基本的な作業を簡単にしてくれます。

一方で、フレームワークを使うと、抽象化の層が増えることで、内部のプロンプトやLLMの応答が見えにくくなり、デバッグが難しくなることがあります。また、シンプルな方法で済む場合でも、不必要に複雑なシステムを作り上げてしまう誘惑に駆られることもあります。

Anthropicは、まずLLMのAPIを直接使ってみることを推奨しています。多くのパターンは簡単なコードで実現できます。もしフレームワークを使う場合は、その内部の仕組みをしっかりと理解しておくことが重要です。

## まとめと開発の原則
LLMを使った開発において最も大切なのは、凝ったシステムを作ることではなく、自分のニーズに「最適なシステム」を構築することです。まずはシンプルなプロンプトから始め、性能を評価しながら改善を進め、もしシンプルな解決策では対応できない場合にのみ、より複雑な多段階エージェントシステムを導入しましょう。

エージェントを開発する際には、以下の3つの重要な原則を意識することが推奨されています。

1.  **シンプルさ**: エージェントの設計は、できるだけ簡潔に保つことが成功の鍵です。
2.  **透明性**: エージェントが次に何をしようとしているか、その計画のプロセスを明確に示せるようにしましょう。
3.  **注意深いACI (Agent-Computer Interface) 設計**: エージェントが使うツールの使い方や役割を丁寧に文書化し、入念にテストすることで、エージェントとコンピューターの間の連携を最適化しましょう。

フレームワークは開発のスタートを加速させますが、システムを本番環境で運用する際には、抽象化を減らして、基本的なコンポーネントで構築することも検討してください。これらの原則に従うことで、強力であると同時に信頼性が高く、メンテナンスしやすいエージェントを作り出すことができるでしょう。

引用元: https://www.anthropic.com/engineering/building-effective-agents


- [How to think about agent frameworks](https://blog.langchain.com/how-to-think-about-agent-frameworks/)  


AIの進化により「AIエージェント」が注目されていますが、実用的なエージェントシステムを開発するのは簡単ではありません。この記事では、信頼性の高いエージェントを構築するための考え方と、フレームワークの選び方について解説しています。

**1. AIエージェントとワークフローの区別**
「AIエージェント」という言葉には様々な解釈がありますが、Anthropic社は「ワークフロー」と「エージェント」を区別しています。
*   **ワークフロー**: LLM（大規模言語モデル）とツールが、事前に決められた手順（コード）に沿って動くシステムです。動きが予測しやすく、安定しています。
*   **エージェント**: LLM自身が状況を判断し、動的にツールを選び、タスクを遂行するシステムです。より柔軟ですが、その分予測が難しいことがあります。
実際の多くのAIシステムは、これらの「ワークフロー」と「エージェント」を組み合わせて作られています。単純で予測可能なタスクにはワークフロー、複雑で柔軟な判断が必要なタスクにはエージェントというように、それぞれの特性を理解して使い分けることが重要です。

**2. 信頼性の高いエージェント構築の鍵**
プロトタイプは簡単に作れても、ビジネスで使える信頼性の高いエージェントを作るのは非常に難しいです。一番の課題は、「LLMに適切な『コンテキスト』（文脈や情報）を、各ステップで正しく与えること」です。LLMが意図しない動作をする主な原因は、必要な情報が不足していたり、情報の形式が悪かったりすることにあります。そのため、開発する際には、LLMに渡すコンテキストを細かく制御できるかどうかが極めて重要になります。

**3. エージェントフレームワークの役割とLangGraph**
多くのエージェントフレームワークは、開発を簡単に始めるための「エージェント抽象化」という機能を提供します。これは手軽な反面、内部の動作やLLMへのコンテキスト制御が見えにくくなるデメリットもあります。
LangGraphは、こうした課題を解決するために設計された「オーケストレーションフレームワーク」です。これは、システム全体の流れを管理・調整する役割を担います。
*   **柔軟な設計**: 宣言的なグラフ構造でシステムの流れを定義しつつ、各処理（ノード）の中身は通常のコードで書けるため、手軽さと高い制御性を両立しています。ワークフローとエージェントの両方のパターンに対応できます。
*   **豊富な機能**:
    *   **記憶機能**: 会話の履歴を保持する短期記憶や、長期的な学習を可能にする機能。
    *   **人間との協調**: エージェントの途中に人間の承認を挟んだり、実行後に動作を検証・修正したりする機能。
    *   **リアルタイム更新**: 処理の進捗をユーザーに即座に伝えるストリーミング機能。
    *   **デバッグ・監視**: LLMの入出力を詳細に確認し、問題を特定するためのツール（LangSmithなど）との連携。
    *   **耐障害性**: 途中でエラーが発生してもシステムが停止しないような仕組み。
これらの機能は、エージェントだけでなくワークフロー型のシステムでも大いに役立ち、開発者がより信頼性の高いアプリケーションを構築するのを助けます。

**4. まとめ**
今後のLLMの性能がさらに向上したとしても、LLMに与えるコンテキストを適切に制御する重要性は変わりません。実用的なAIシステムは、多くの場合、ワークフローとエージェントの最適な組み合わせから生まれます。LangGraphのようなフレームワークは、開発の初期段階だけでなく、長期的に見て信頼性、保守性、拡張性のあるAIシステムを構築するために不可欠なツールとなるでしょう。

引用元: https://blog.langchain.com/how-to-think-about-agent-frameworks/


- [We’re expanding our Gemini 2.5 family of models](https://deepmind.google/discover/blog/were-expanding-our-gemini-25-family-of-models/)  


Googleは、AIモデル「Gemini 2.5」ファミリーのラインナップをさらに強化し、開発者がより柔軟にAIを活用できるよう新しいモデルの提供を開始しました。

まず、これまでプレビュー版として提供されてきた「Gemini 2.5 Flash」と「Gemini 2.5 Pro」が、正式に「一般提供（GA: Generally Available）」となりました。これは、これらのモデルが安定し、実際のサービスや製品に組み込んで使うのに適したレベルになったことを意味します。すでにSplineやRooms、Snap、SmartBearといった企業がこれらのモデルを本番環境で利用しており、その信頼性が証明されています。新人エンジニアの皆さんも、これらのモデルを使って、より本格的なAIアプリケーション開発に安心して取り組めるようになります。

そして、新たに「Gemini 2.5 Flash-Lite」のプレビュー版が公開されました。このモデルは、Gemini 2.5ファミリーの中で「最もコスト効率が良く、最も高速」という特徴を持っています。AIモデルの利用にかかる費用を抑えつつ、素早い応答が必要なタスクに特に強みを発揮します。例えば、大量のテキストを翻訳したり、情報を分類したりするような処理で、これまで以上に効率的なAI活用が期待できます。

Flash-Liteは、これまでの2.0世代のモデルと比較しても、コーディング、数学、科学、推論、さらにはテキスト以外の情報（画像や音声など）を扱うマルチモーダルな能力においても、全体的に高い品質を実現しています。また、Gemini 2.5シリーズの大きな特徴である「100万トークン」という非常に長い文章や大量の情報を一度に処理できる能力や、Google検索やコード実行といった外部ツールと連携できる機能も、Flash-Liteでそのまま利用できます。これにより、より複雑で実用的なAIシステムを構築できるようになります。

これらの新しいモデルは、Google AI StudioやVertex AIといったGoogleのAI開発プラットフォームを通じてすぐに利用を開始できます。また、Gemini 2.5 FlashとProは、Geminiアプリからも利用可能です。さらに、Google検索の一部にもカスタムバージョンのFlash-LiteとFlashが導入されており、私たちの日常生活にもAIの恩恵が広がっています。

今回の発表は、AI開発の選択肢を広げ、さまざまな用途に応じた最適なモデルを選べるようになることを示しています。新人エンジニアの皆さんにとって、最先端のAI技術に触れ、新しい価値を創造する大きなチャンスとなるでしょう。

引用元: https://deepmind.google/discover/blog/were-expanding-our-gemini-25-family-of-models/


- [四国めたんのプラモデルにミニフィギュア同梱版が登場！6月19日（木）10時より予約開始！PLUM WEB SHOP限定でミニフィギュアの単品販売も！  電撃ホビーウェブ](https://hobby.dengeki.com/news/2633689/)  


人気キャラクター「四国めたん」の全身可動プラモデルに、新しく作られたミニフィギュアが同梱された特別版が登場します。2025年6月19日(木)午前10時から予約が始まります。このプラモデルは色々なポーズが取れるので、飾って楽しめますよ。ミニフィギュアはPLUM WEB SHOPで単品でも買えるそうです。ホビーに興味がある新人エンジニアの方は、ぜひチェックしてみてくださいね。

引用元: https://hobby.dengeki.com/news/2633689/



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
