---
actor_ids:
  - ずんだもん
audio_file_path: https://storage.googleapis.com/podcast-zund-arm-on-tech/audio/株式会社ずんだもん技術室AI放送局_podcast_20240918.mp3
audio_file_size: 0
date: 2024-09-18 05:00:00 +0900
description: 'AIやテクノロジーに関する記事を紹介  
Announcing Pixtral 12B、Synchron Announces First Use of Amazon’s Alexa with a Brain Computer Interface、Build RAG-based generative AI applications in AWS using Amazon FSx for NetApp ONTAP with Amazon Bedrock  Amazon Web Services、「ExcelのエラーをGoogleで調べる時代は終わりましたね」ChatGPTにスクショを送ってポンすれば、10秒ぐらいで返答するので、効率の良さが全然違う'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20240918
information: 
---

## 関連リンク


- [Announcing Pixtral 12B](https://mistral.ai/news/pixtral-12b/)  


Mistral AIは、画像とテキストの両方を理解するようにトレーニングされた、新しいオープンソースの多様な言語モデル「Pixtral 12B」を発表しました。

Pixtral 12Bは、Mistral Nemo 12Bをベースに、新たに4億パラメータのビジョンエンコーダを追加することで、多様なタスクにおいて優れた性能を実現しています。特に、図表や文書の理解、多様な推論、指示に従う能力に優れており、MMMU推論ベンチマークでは52.5%という高いスコアを達成しています。これは、他の多くのより大規模なモデルを上回る成果です。

Pixtral 12Bは、画像の解像度やアスペクト比を維持したまま処理できるため、ユーザーは画像処理に使用するトークンの数を柔軟に調整できます。また、最大128kトークンの長いコンテキストウィンドウ内に複数の画像を処理することも可能です。

**Pixtral 12Bの主な特徴**

*   画像とテキストの両方を理解
*   多様なタスクで優れた性能を発揮
*   テキストのみのベンチマークでも最先端の性能を維持
*   可変の画像サイズとアスペクト比に対応
*   最大128kトークンの長いコンテキストウィンドウ内で複数の画像を処理可能
*   Apache 2.0ライセンス


**Pixtral 12Bのアーキテクチャ**

Pixtral 12Bは、画像をトークン化するビジョンエンコーダと、テキストと画像のシーケンスから次のテキストトークンを予測する多様なトランスフォーマーデコーダの2つのコンポーネントで構成されています。このアーキテクチャにより、任意のサイズの画像を複数処理できます。

**Pixtral 12Bの活用方法**

Pixtral 12Bは、Mistral AIが提供するチャットインターフェース「Le Chat」やAPIを通じて利用できます。また、`mistral-inference`や`vLLM`などのライブラリを用いてローカル環境で実行することも可能です。


Pixtral 12Bは、オープンソースでありながら、多様な言語モデルの性能において新たな基準を打ち立てました。今後、様々なアプリケーションやワークフローに統合され、画像とテキストの処理において重要な役割を果たしていくことが期待されます。 


引用元: https://mistral.ai/news/pixtral-12b/


- [Synchron Announces First Use of Amazon’s Alexa with a Brain Computer Interface](https://www.businesswire.com/news/home/20240916709941/en/Synchron-Announces-First-Use-of-Amazon%E2%80%99s-Alexa-with-a-Brain-Computer-Interface**.)  


Synchron社は、脳コンピューターインターフェース（BCI）を用いて、ALS（筋萎縮性側索硬化症）患者がAmazon Alexaを操作することに世界で初めて成功したと発表しました。

このBCIシステムは、脳の運動皮質の表面にある血管に、経静脈的に埋め込まれます。患者の思考を検知し、ワイヤレスで送信することで、重度の麻痺を持つ人々が、手を動かさずにデジタルデバイスを操作することを可能にします。

今回の発表では、ALS患者であるMarkさんが、SynchronのBCIシステムを使って、Amazon FireタブレットのTap to Alexa機能を通じてスマートホームを制御することに成功しました。照明のオンオフ、ビデオ通話、音楽再生、スマート家電の操作など、音声や手を使わずに、思考だけで様々な操作が可能になりました。

Synchron社は、Alexaとの連携を通じて、BCI技術の可能性を広げ、自宅内外の環境制御を容易にすることを目指しています。これにより、重度の麻痺を持つ人々の自立性向上に貢献できると期待されています。

Synchron社のCEOであるTom Oxley氏は、「SynchronのBCIは、神経技術と消費者向け技術のギャップを埋めるものであり、麻痺を持つ人々が再び環境をコントロールできるようになる可能性を示しています。」と述べています。

今回の成果は、BCI技術が、重度の麻痺を持つ人々の生活の質を向上させるための大きな可能性を秘めていることを示すものです。今後の研究開発によって、さらに多くの機能が追加され、より多くの患者が恩恵を受けることが期待されます。




引用元: https://www.businesswire.com/news/home/20240916709941/en/Synchron-Announces-First-Use-of-Amazon%E2%80%99s-Alexa-with-a-Brain-Computer-Interface**.


- [Build RAG-based generative AI applications in AWS using Amazon FSx for NetApp ONTAP with Amazon Bedrock  Amazon Web Services](https://aws.amazon.com/blogs/machine-learning/build-rag-based-generative-ai-applications-in-aws-using-amazon-fsx-for-netapp-ontap-with-amazon-bedrock/)  



このブログ記事では、Amazon Web Services (AWS) 上で、Retrieval Augmented Generation (RAG) ベースの生成AIアプリケーションを構築する方法について解説しています。RAGは、大規模言語モデル（LLM）の出力に関連する情報を外部データソースから取得することで、より正確で関連性の高い応答を生成する技術です。

具体的には、Amazon Bedrock、Amazon FSx for NetApp ONTAP、およびその他のAWSサービスを組み合わせることで、大規模なドキュメントやデータセットを効率的に格納・管理し、LLMにこれらの情報を提供する仕組みを構築する方法が紹介されています。

**本記事のポイントは以下の通りです。**

* **RAGを用いた生成AIアプリケーションの構築**: LLMの能力を最大限に引き出し、より信頼性の高い応答を生成できます。
* **Amazon FSx for NetApp ONTAPによるデータ管理**: 大量のドキュメントやデータを効率的に保存・管理し、LLMへのアクセスを容易にします。
* **Amazon Bedrockを活用したLLMの利用**: 様々なLLMを簡単に利用し、RAGアプリケーションに組み込むことができます。

これらの技術を組み合わせることで、企業は自社のデータやドキュメントを活用した、より高度な生成AIアプリケーションを構築することが可能になります。例えば、顧客サポートの自動化、文書要約、質問応答システムなど、様々なユースケースに適用できます。

新人エンジニアの方にとっても、AWSのサービスを活用した生成AIアプリケーションの構築方法を理解する上で、参考になる内容となっています。




引用元: https://aws.amazon.com/blogs/machine-learning/build-rag-based-generative-ai-applications-in-aws-using-amazon-fsx-for-netapp-ontap-with-amazon-bedrock/


- [「ExcelのエラーをGoogleで調べる時代は終わりましたね」ChatGPTにスクショを送ってポンすれば、10秒ぐらいで返答するので、効率の良さが全然違う](https://togetter.com/li/2435748)  


近年、ChatGPTがExcelのエラー解決に役立つツールとして注目されています。

**ChatGPTの活用:** 
Excelのエラーメッセージを画像でChatGPTに送信すると、わずか10秒ほどで回答が得られるケースが増えています。これは、従来Google検索でエラー内容を調べ、適切な情報を探すのに要していた時間と比較して、大幅な時間短縮につながります。

**エンジニアやExcelユーザーの反応:**
Twitter上では、ChatGPTのこの機能に多くのユーザーが驚きの声を上げています。Excelの関数やエラーメッセージの解釈、さらには英語の誤り訂正など、画像から情報を理解し、的確な回答を返すChatGPTの能力に、驚嘆と期待の声が多数寄せられています。

**ChatGPTとGoogle検索の比較:**
ChatGPTは、画像認識と自然言語処理技術を活用することで、Excelのエラーや問題を効率的に解決できる可能性を秘めています。一方、Google検索は、キーワード検索と検索結果の精査が必要となるため、ChatGPTに比べて時間がかかる場合があります。

**ChatGPTの今後の可能性:**
ChatGPTは、Excelのエラー解決だけでなく、英文の修正や表データの抽出など、幅広い用途で活用できる可能性を秘めています。しかし、まだ開発段階であり、完璧な回答が得られない場合もある点には注意が必要です。

**新人エンジニアへのアドバイス:**
Excelの操作に慣れていない新人エンジニアにとって、ChatGPTは強力な学習ツールとなりえます。エラー解決だけでなく、Excelの機能や関数の使い方を学ぶ際にも、ChatGPTを活用することで、学習効率を向上させることが期待できます。ただし、ChatGPTの回答を鵜呑みにせず、自分で確認する習慣を身につけることが重要です。


ChatGPTは、Excelのエラー解決において、従来のGoogle検索に代わる新たな選択肢として注目されています。新人エンジニアの方々も、ぜひChatGPTを活用して、Excelのスキルアップを目指してみて下さい。 


引用元: https://togetter.com/li/2435748



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
