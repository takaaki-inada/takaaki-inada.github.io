---
actor_ids:
  - お嬢様ずんだもん
audio_file_path: https://storage.googleapis.com/podcast-zund-arm-on-tech/audio/私立ずんだもん女学園放送部_podcast_20250620.mp3
audio_file_size: 0
date: 2025-06-20 05:00:00 +0900
description: 'AI system development: LLM → RAG → AI Workflow → AI Agent  CodeLink、How Early Access to NVIDIA GB200 Systems Helped LMArena Build a Model to Evaluate LLMs、オープンソースのAI開発エージェント基盤にコマンドライン版「OpenHands CLI」が登場  gihyo.jp、【ずんだもん】新作ぬいぐるみ2種が登場。ぶるぶる震えたり大きかったり…両方ほしくなるのだ！'
duration: "00:00"
layout: article
title: 私立ずんだもん女学園放送部 podcast 20250620
image_url: https://zund-arm-on.com/images/ojousama_zundamon_square.jpg
thumbnail_url: https://zund-arm-on.com/images/ojousama_zundamon_thumbnail.jpg
---

## 関連リンク


- [AI system development: LLM → RAG → AI Workflow → AI Agent  CodeLink](https://www.codelink.io/blog/post/ai-system-development-llm-rag-ai-workflow-agent)  


この記事では、AIシステム開発が「LLM」から始まり、「RAG」「AI Workflow」を経て、最終的に「AI Agent」へと段階的に進化していく過程を、新人エンジニアにも分かりやすく解説しています。すべてのAIシステムに高度なAI Agentが必要なわけではなく、解決したい問題に合わせて適切な技術を選ぶことが重要だと述べられています。

まず、**Pure LLM（純粋なLLM）**は、インターネット上の膨大な情報を学習した知識の塊です。小説の要約や文章作成など、学習データ内の情報を使うタスクは得意ですが、リアルタイムの情報取得や外部ツールとの連携はできません。しかし、プロンプトの工夫（in-context learningなど）で、ある程度の問題解決が可能です。例えば、レジュメが職務要件に合うかを分類するような単純なタスクなら、LLM単体でも対応できます。

次に、**RAG (Retrieval Augmented Generation)**は、LLMに外部の関連情報を与えることで、より正確で最新の回答を生成させる手法です。これにより、LLMは企業の内部データや最新のリアルタイム情報も活用できるようになります。レジュメスクリーニングの例では、社内の技術マニュアルや過去のレジュメを参考にして、より適切な判断ができるようになります。この際、ベクトルデータベースやセマンティック検索といった技術が使われます。

さらに進んだ段階が、**Tool Use & AI Workflow（ツール利用とAIワークフロー）**です。これは、LLMが電卓やメールサービス、検索エンジンといった外部ツール（API）と連携し、定められた手順に沿ってビジネスプロセスを自動化する仕組みです。定型的なタスク、例えばレジュメの取得、内容評価、そして合否通知メールの送信といった一連の流れを自動化できます。LLMはデータベースやメールAPI、カレンダーAPIなどにアクセスして、プログラムされた手順を実行します。

そして、最も進化した形が**AI Agent（AIエージェント）**です。AIエージェントは、タスクを自律的に分解し、必要なツールを判断して使い、結果を評価し、次に何をすべきかを自分で決められるシステムです。AIワークフローが決められた手順をなぞるのに対し、AIエージェントは自分で計画を立て、状況に応じて動的に手順を決定・実行します。採用プロセス全体（CV解析、面接調整、スケジュール変更対応など）を、人間がほとんど介入せずに自動で管理するような複雑なタスクをこなすことができます。

この記事の重要なポイントは二つです。一つは、「**すべてのシステムにAIエージェントが必要なわけではない**」ということ。シンプルな構成から始め、必要に応じて複雑な機能を追加していくのが賢明です。もう一つは、「**機能よりも信頼性を重視すべき**」という点。LLMは非決定的な性質があるため、本番環境で安定稼働させるには、綿密なテストと安全対策（ガードレール）が不可欠です。新人エンジニアの皆さんも、この段階的な進化と重要ポイントを理解して、AIシステム開発に取り組んでいきましょう。

引用元: https://www.codelink.io/blog/post/ai-system-development-llm-rag-ai-workflow-agent


- [How Early Access to NVIDIA GB200 Systems Helped LMArena Build a Model to Evaluate LLMs](https://developer.nvidia.com/blog/how-early-access-to-nvidia-gb200-systems-helped-lmarena-build-a-model-to-evaluate-llms/)  


こんにちは、新人エンジニアの皆さん！
今回ご紹介する記事は、私たちが普段利用する大規模言語モデル（LLM）の「どれが、どんなタスクに一番得意なのか」を賢く評価する新しいシステムと、その裏側にある最新技術のお話です。

カリフォルニア大学バークレー校のLMArenaが開発した「P2L（Prompt-to-Leaderboard）」モデルは、LLMの得意分野を見極めるための画期的なツールです。これまでのLLM評価は総合スコアで示されることが多かったのですが、P2Lは「数学ならこのモデル、プログラミングならあのモデル」といったように、特定のタスク（例えば、数学、コーディング、創造的ライティングなど）ごとに、どのLLMが優れているかを人間の評価（投票）を基に判断します。これにより、単一のランキングでは見えにくいLLMごとの「個性」や「得意技」がはっきり分かるようになります。さらに、予算に応じて最適なモデルを自動で選ぶ「コストベースのルーティング」もできるので、利用コストを抑えながら最高のパフォーマンスを引き出すことも可能です。

このP2Lモデルの開発と、それを実際に動かすための大規模なシステム構築を強力に支えたのが、NVIDIAの最新AIスーパーコンピュータ「GB200 NVL72」の早期アクセスでした。LMArenaは、NVIDIA DGX CloudとNebius AI Cloudを通じてこの高性能システムを利用。GB200 NVL72は、多数の高性能CPUとGPUを高速で接続した、まさにAIのためのモンスターマシンです。このおかげで、P2Lモデルの複雑な学習プロセスをわずか4日間で完了させるなど、従来のシステムに比べて圧倒的なスピードアップを実現しました。

NVIDIAとNebiusは、P2Lの開発チームが本質的な開発に集中できるよう、手厚いサポートを提供しました。具体的には、GB200 NVL72上でPyTorchやHugging Face Transformersといった主要なオープンソースAIフレームワークが問題なく、そして最高のパフォーマンスで動作するように事前に検証・最適化してくれたのです。これにより、LMArenaのエンジニアは、インフラの構築やツールの互換性といった煩雑な作業に時間を取られることなく、P2Lの機能向上に全力を注ぐことができました。

このLMArena、NVIDIA、Nebiusの協力事例は、最新の高性能AIハードウェアと、それを最大限に活用するためのクラウド環境、そして革新的なAI評価モデルが一体となることで、AI開発がいかに加速するかを私たちに示しています。AIモデルの種類が爆発的に増え続ける現代において、どのAIを、どんなタスクに、どのくらいのコストで使うべきかを効率的に見極めるP2Lのようなシステムは、これからのAI開発を大きく前進させる鍵となるでしょう。皆さんが今後AIを扱う上で、モデルの選び方や評価の重要性を理解する上での良いヒントになるはずです。

引用元: https://developer.nvidia.com/blog/how-early-access-to-nvidia-gb200-systems-helped-lmarena-build-a-model-to-evaluate-llms/


- [オープンソースのAI開発エージェント基盤にコマンドライン版「OpenHands CLI」が登場  gihyo.jp](https://gihyo.jp/article/2025/06/openhands-cli)  


新人エンジニアの皆さん、こんにちは！プログラミングの世界に新しい風を吹き込む exciting なニュースです。「OpenHands」というオープンソースのAIソフトウェア開発エージェントに、コマンドライン版「OpenHands CLI」がリリースされました。これは、AIが皆さんのプログラミング作業をグッと楽にしてくれる可能性を秘めたツールなんです。

まず、「OpenHands」について簡単に説明しますね。これは、AIがまるで優秀なアシスタントのように、皆さんの指示（自然言語、つまり普段使う言葉）を理解して、プログラミングのコードを書いたり、プログラムのミス（バグ）を見つけて直したり、ファイルを操作したり、必要なコマンドを実行したり、さらにプログラム同士を連携させる「API」の呼び出し、テスト、コードの整理（リファクタリング）まで、さまざまな開発作業を自律的に行ってくれるプラットフォームです。オープンソースなので、誰でも自由に利用したり、その中身を見て改良したりできます。

今回リリースされた「OpenHands CLI」は、このOpenHandsを、普段エンジニアがよく使う「ターミナル」（黒い画面に文字を打ち込んで操作する場所）から直接利用できるようにしたものです。これまでのOpenHandsはGUI（グラフィカルな画面でマウス操作する方式）が中心でしたが、CLI版の登場にはいくつかの大きなメリットがあります。

一番のポイントは、ローカル環境にインストールする際に「Docker」という仮想環境を作るツールが不要になったことです。Dockerは便利なツールですが、導入に少し手間がかかる場合もあります。それが不要になることで、OpenHandsを試したいと思ったときに、もっと手軽に始められるようになりました。また、GUIが必要ないので、リモートのサーバーや皆さんが普段使っている「IDE」（統合開発環境、コードを書くための高機能なエディタのようなもの）など、慣れた開発環境で直接AIエージェントの力を借りて作業ができるようになります。

さらに、コマンドライン操作ならではの「軽快な動作」と「パフォーマンスの向上」も期待できます。キーボードだけでサクサク操作できる「スラッシュコマンド」なども用意されていて、普段からコマンドライン操作に慣れているエンジニアにとっては、非常に使いやすいツールになっているでしょう。

OpenHands CLIを使うためには、Python 3.12または3.13がインストールされていれば、`pip`コマンド一つで簡単に導入できます。利用するAIモデルについても柔軟で、特定のAIモデル（LLMプロバイダ）に依存せず、さまざまなクラウドベースやローカルで動くLLMを利用できます。記事によると、現時点ではClaude 4 sonnetがクラウドベースで最高のパフォーマンスを発揮しているとのことです。また、ローカルで動かすモデルとしては、ソフトウェア開発に特化した「Devstral」というモデルも推奨されています。

このようにOpenHands CLIは、AIを開発プロセスに組み込むことをより身近で効率的なものにしてくれます。新人エンジニアの皆さんも、ぜひこの新しいツールに触れてみて、AIがどのように開発を助けてくれるのかを体験してみてください。きっと、皆さんの開発効率を大きく向上させてくれるはずです。

引用元: https://gihyo.jp/article/2025/06/openhands-cli


- [【ずんだもん】新作ぬいぐるみ2種が登場。ぶるぶる震えたり大きかったり…両方ほしくなるのだ！](http://news.dengeki.com/article/202506/45265)  


人気のAIキャラクター「ずんだもん」から、新作のプライズぬいぐるみが2種類登場しました！一つは紐を引っ張るとぶるぶる震える「ぶるぶるぬいぐるみ」（全4種、約15cm高）で、もう一つは表情豊かな約30cmのビッグサイズ「デフォルメぬいぐるみ」（全2種）です。どちらもオンラインクレーンゲームなどで手に入ります。日々の開発の合間に、かわいいずんだもんに癒されてみてはいかがでしょうか？

引用元: http://news.dengeki.com/article/202506/45265



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

VOICEVOX:ずんだもん
