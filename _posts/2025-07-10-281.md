---
actor_ids:
  - ずんだもん
audio_file_path: /audio/株式会社ずんだもん技術室AI放送局_podcast_20250710.mp3
audio_file_size: 0
date: 2025-07-10 05:00:00 +0900
description: 'AIともっと楽するE2Eテスト、From AI to Agents to Agencies: The Next Evolution of Artificial Intelligence、OLMo from Ai2、下の世代にとってゆっくりは「お年寄りが見てる動画でしょ？」という認識らしいので動画制作者はそろそろAIによる音声合成に移行した方がよい？'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20250710
---

## 関連リンク


- [AIともっと楽するE2Eテスト](https://speakerdeck.com/myohei/aitomotutole-surue2etesuto)  


この資料は、AIを活用して「エンドツーエンド（E2E）テスト」、つまりユーザーがアプリを操作するのと同じように、画面を通じた一連の動作が正しく行われるかを確認するテストを効率化する方法について解説しています。

近年、AIツールによるコード生成の速度が飛躍的に向上したことで、開発スピードは上がりました。しかし、その結果として、アプリの品質を保証するためのテスト（特にE2Eテスト）が追いつかず、開発全体のボトルネックになってしまうという新たな課題が生まれています。従来のE2Eテストは、専門知識が必要で学習コストが高く、属人化しやすいうえ、仕様変更のたびにメンテナンスが大変という課題がありました。

そこで注目されるのが、AIによるテスト作成です。AIを使うことで、自然言語でテストシナリオを記述できるようになり、専門知識がなくてもテストを作成できるようになります。さらに、AIがテストのメンテナンスをサポートしてくれることで、チーム全体でテストに貢献しやすくなります。

この資料では、AIが最大限にパフォーマンスを発揮できるよう、「AI First」の設計思想に基づいた「ScreenActionパターン」というテストアーキテクチャが提案されています。これは、画面のUI要素の定義（PageObject）、操作の定義（ActionObject）、状態検証の定義（StateObject）をそれぞれ別々のクラスに明確に分離する設計です。これにより、AIがコードを生成する際に、どの部分を担当すべきかが明確になり、迷わず効率的にコードを書けるようになります。結果として、テストコードの保守性やチーム開発のしやすさも向上します。

実際にAIを活用したところ、プロンプト一つでベースとなるテストコードを短時間で生成できるようになり、手作業に比べて大幅な効率化が実現しました。今後は、QAエンジニアだけでなく、プロダクトオーナーやデザイナーも自然言語でテストシナリオを記述し、AIがそれをテストコードに変換することで、チーム全体でテスト作成に取り組めるようになると期待されています。

将来的には、AIによるテストの完全自動生成や、ユーザーの要望（ユーザーストーリー）から直接テストを生成する未来を目指しており、AIがテストの保守まで自動で行うことで、より開発がスムーズになることが期待されます。

引用元: https://speakerdeck.com/myohei/aitomotutole-surue2etesuto


- [From AI to Agents to Agencies: The Next Evolution of Artificial Intelligence](https://blog.nishantsoni.com/p/from-ai-to-agents-to-agencies-the)  


この記事では、AIが「エージェント」からさらに進化した「エージェンシー」という新しい形へと変化している様子を解説しています。

従来の「AIエージェント」は、複雑なタスクを人間が細かく指示しなくても自律的にこなせるシステムとして登場しました。例えば、ウェブサイトのコードを書いたり、デジタルの作業の流れを管理したりと、単一のAI（大規模言語モデルなど）が様々なツールを使いこなして、与えられたタスク全体をこなすイメージです。

しかし、筆者はさらに進んだ新しい仕組みとして「エージェンシー」が生まれつつあると指摘します。「エージェンシー」は、単一のタスクを達成するために、複数の異なる種類の知能（AI）を動的に連携させるシステムです。例えるなら、一つの道具を使いこなす「AIエージェント」に対し、「エージェンシー」は、複数の専門家が協力し、それぞれの得意分野を活かして一つの大きな仕事をこなすようなものです。

「エージェンシー」は、次の3つの要素で構成されます。
1.  **タスクコンテキスト管理**: 作業全体の要件や進捗状況を一貫して把握し、情報がぶれないようにします。
2.  **知能割り当てシステム**: 複数の専門的な知能の中から、目の前のサブタスクに最も適した知能を自動で選びます。
3.  **オーケストレーションロジック**: メインタスクを小さなサブタスクに分解し、それぞれに最適な知能を割り当て、全てがスムーズに連携するよう調整します。

例えば、「ECサイトのデータを取得するPythonウェブスクレイパーを作成する」というタスクを「エージェンシー」に指示した場合、以下のように動作します。
*   全体の設計や計画は、高度な推論ができるAIが担当します。
*   定型的なコードの生成は、高速で効率的なAIが担当します。
*   エラーの検出や修正は、デバッグに特化したAIが担当します。
このように、一つのタスクの中で、それぞれの工程を最も得意なAIに任せることで、効率的で質の高い結果を出せるようになります。

これまでのAIの進化は、2020～2023年の「個別モデル」（人間が調整）、2024～2025年の「AIエージェント」（自律的に動くが単一知能）、そして2025年以降の「エージェンシー」（複数の専門知能を連携）という流れで進んでいくと筆者は考えています。

「エージェンシー」は、「一つの知能が単一のタスクを扱う」というこれまでの考え方から、「複数の知能が協力して一つのタスクをこなす」という新しいアプローチへの大きな転換点であり、AIによるタスク実行の可能性をさらに広げるものです。

引用元: https://blog.nishantsoni.com/p/from-ai-to-agents-to-agencies-the


- [OLMo from Ai2](https://allenai.org/olmo)  


AIの研究機関であるAi2（Allen Institute for AI）が、新しい大規模言語モデル（LLM）の「OLMo 2」シリーズを公開しました。これは、AI開発の透明性とアクセス性を高めることを目指した、非常にオープンなモデル群です。

「OLMo 2」の最大の特徴は、モデルの重みだけでなく、学習に使われたデータ、トレーニングコード、評価方法、さらには開発途中の状態を示す中間チェックポイントまで、すべてが公開されている点です。これにより、研究者や開発者はOLMo 2がどのように作られたかを詳しく検証し、さらに発展させていくことが可能になります。

OLMo 2ファミリーには、性能や用途に応じて複数のサイズのモデルが用意されています。

*   **OLMo 2 32Bモデル**: このシリーズで最も大きく高性能なモデルです。膨大なデータ（6兆トークン）を使って学習されており、一部の多岐にわたる学術的な評価テストでは、有名なGPT-3.5-TurboやGPT-4o miniといったモデルを上回る性能を示しています。これは、オープンなモデルとしては初の快挙とされています。
*   **OLMo 2 7Bおよび13Bモデル**: これらのモデルは、それぞれ5兆トークンのデータで学習されています。同じサイズの他のオープンモデルと比べて同等かそれ以上の性能を持ち、Meta社やMistral社が提供するオープンウェイトモデルとも競争力があります。
*   **OLMo 2 1Bモデル**: 最もコンパクトなモデルで、Gemma 3 1BやLlama 3.2 1Bといった同サイズのモデルよりも高い性能を発揮します。この小さなモデルは、研究者が迅速に試行錯誤したり、手元の環境で開発を進めたりする際に非常に役立ちます。

Ai2は、「真のオープンネス」こそがAIの未来を切り開き、AIを誰もが利用できるものにすると信じています。そのため、単にモデルの重みを公開するだけでなく、学習プロセス全体をオープンにすることで、オープンな科学研究を支援し、AI技術の発展を加速させようとしています。

具体的には、OLMo 2モデル本体と、事前学習から後処理まで全ての段階で使用された学習データ、さらに高性能なトレーニングコード、そしてモデルの評価に使われたコードとデータもすべて無償で公開されています。これにより、エンジニアや研究者は、AIモデル開発の最先端に触れ、その仕組みを深く理解し、自身のプロジェクトに活用することができます。

オープンなLLMの進化は、AI業界全体の発展に大きく貢献しており、新人エンジニアにとっても注目すべき重要な動きと言えるでしょう。

引用元: https://allenai.org/olmo


- [下の世代にとってゆっくりは「お年寄りが見てる動画でしょ？」という認識らしいので動画制作者はそろそろAIによる音声合成に移行した方がよい？](https://togetter.com/li/2574018)  


「ゆっくり」動画の音声が、若い世代からは「お年寄りが見る動画」と認識されているという話題が注目されています。これに伴い、動画制作者はAIによる音声合成への移行を検討すべきとの声が上がっています。記事では「ずんだもん」などの新しい音声合成キャラクターも紹介され、技術の進化とともに、世代間で動画の視聴習慣や好みが変化している様子が伺えます。これはAI技術の身近な応用例と、ネット文化の移り変わりを示す面白い動向です。

引用元: https://togetter.com/li/2574018



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
