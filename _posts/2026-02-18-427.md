---
actor_ids:
  - ずんだもん
audio_file_path: /audio/株式会社ずんだもん技術室AI放送局_podcast_20260218.mp3
audio_file_size: 0
date: 2026-02-18 05:00:00 +0900
description: 'Claude Codeで開発を全自動化する - Orchestrator型Skillの設計と実践、Qwen3.5: Towards Native Multimodal Agents、OpenAI sidesteps Nvidia with unusually fast coding model on plate-sized chips、AIだけど、間違ってPCのデータ全部消してしまった'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20260218
---

## youtube版(スライド付き)

<div class="article-video"><iframe src="https://www.youtube.com/embed/Tfqx4IyiCII" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></div>


## 関連リンク


- [Claude Codeで開発を全自動化する - Orchestrator型Skillの設計と実践](https://dev.henry.jp/entry/claude-code-orchestrator)  


株式会社ヘンリーのエンジニアによる、AIコーディングアシスタント「Claude Code」を駆使して開発業務を高度に自動化した事例の紹介です。

### 1. 背景と課題：AIに拘束される「ペアプロ型」からの脱却
医療業界向けプロダクトを開発する同社では、エンジニアに深いドメイン知識が求められます。著者は「実装にかける時間を減らし、学習時間を増やしたい」と考えましたが、従来のClaude Code活用はAIとの対話を通じた「ペアプロ型」であり、AIの出力を人間が常に見守り、指示を出し続けなければならないという課題がありました。これでは、人間が作業から離れて別のことに集中することができません。

### 2. 解決策：Orchestrator型Skillによる完全自動化
そこで導入されたのが、Claude Codeの「Skills」機能を活用した**Orchestrator（司令塔）型**の設計です。これは、人間が最初にタスクを指示した後は、AIが自律的に調査からプルリクエスト（PR）作成までを完走する仕組みです。

新人エンジニアが理解しておくべき、この設計のポイントは以下の3点です。

*   **Skillsによる手順の定義**: 
    プロジェクトの前提知識（CLAUDE.md）とは別に、「作業の進め方」をSkillとして定義しました。これにより、必要な時だけ特定の手順をAIに読み込ませ、AIが迷わずに自走できる環境を整えました。
*   **SubAgentによるコンテキスト管理**: 
    1つのAIに全てをやらせようとすると、記憶（コンテキスト）が一杯になり精度が落ちます。そこで、「調査」「設計」「実装」「PR作成」といった各ステップを、独立したコンテキストを持つ「子エージェント（SubAgent）」として実行し、親であるオーケストレーターがその進行を管理する構成をとりました。
*   **AIによるセルフレビュー体制**: 
    実装の品質を高めるため、「作業担当Agent」とは別に「レビュー担当Agent」を用意しました。人間がコードレビューを行うように、AI同士で「実装→レビュー→修正」のサイクルを回すことで、人間が介在しなくても精度の高い成果物を出せるように工夫されています。

### 3. 導入の効果とメリット
この仕組みにより、開発者は最初のタスク確認さえ終われば、あとはVSCodeを閉じてドメイン知識の学習や他のタスクに時間を充てられるようになりました。実装の深い理解についてはペアプロ型に軍配が上がりますが、PR作成後のセルフレビューを通じて補完できており、トータルの開発速度と作業効率は劇的に向上したと報告されています。

### まとめ：新人エンジニアへの示唆
本記事は、AIを単なる「チャット相手」として使うのではなく、**「自律的に動くエージェントの集合体」として設計する**ことで、エンジニアの創造的な時間を最大化できることを示しています。コンテキストの節約や役割の分離といった考え方は、将来のAI活用において非常に重要なスキルとなるでしょう。

引用元: https://dev.henry.jp/entry/claude-code-orchestrator


- [Qwen3.5: Towards Native Multimodal Agents](https://simonwillison.net/2026/Feb/17/qwen35/)  


アリババ（Alibaba）のQwenチームより、次世代モデルシリーズの先駆けとなる「Qwen3.5」が発表されました。今回のリリースは、テキストだけでなく画像などの視覚情報も直接扱う「ネイティブなマルチモーダル・エージェント」の実現に向けた大きな一歩となっています。

本シリーズで特筆すべきは、オープン重み版として公開された「Qwen3.5-397B-A17B」の革新的なアーキテクチャです。このモデルは「混合専門家（Mixture of Experts: MoE）」と呼ばれる仕組みを採用しており、総パラメータ数は3970億という巨大なものですが、推論時に実際に稼働するのはそのうちの170億パラメータのみです。これにより、高い知能を維持したまま、推論のスピード向上とコスト削減を両立させています。さらに、Linear Attention（Gated Delta Networks）という技術を組み合わせることで、メモリ効率や処理速度を極限まで高めているのが技術的な見どころです。

また、商用API版である「Qwen3.5 Plus」も同時に発表されました。こちらは最大100万トークンという極めて長いコンテキスト（一度に読み込める情報の長さ）をサポートしており、長大なドキュメントの解析や、高度な検索、コード実行機能（コードインタープリター）をネイティブに使いこなすことが可能です。

新人エンジニアの方々にとって注目すべき点は、AIが単に言葉を返すだけでなく、画像を見て内容を理解したり、複雑なツールを自ら使いこなしたりする「エージェント」としての能力が飛躍的に向上している点です。SVG形式で図形を描画するといった高度なタスクもこなせるようになっており、AI活用の幅が大きく広がっています。

このモデルはすでにHugging Faceなどで公開されており、軽量化されたバージョンもコミュニティによって提供されています。最先端のAIがどのような設計思想（巨大なモデルをいかに効率よく動かすか）で作られているかを知る上で、非常に重要なアップデートと言えるでしょう。

引用元: https://simonwillison.net/2026/Feb/17/qwen35/


- [OpenAI sidesteps Nvidia with unusually fast coding model on plate-sized chips](https://arstechnica.com/ai/2026/02/openai-sidesteps-nvidia-with-unusually-fast-coding-model-on-plate-sized-chips/)  


OpenAIは、コーディングに特化した新しいAIモデル「GPT-5.3-Codex-Spark」を発表しました。このニュースの最も注目すべき点は、AI業界を席巻しているNVIDIA製のGPUではなく、Cerebras（セレブラス）社の特殊な巨大チップを採用し、驚異的な処理速度を実現したことです。

### 1. 爆速のコーディング体験
この新モデル「Spark」は、1秒間に1,000トークン（AIが扱う文字の断片単位）以上を生成する能力を持っています。これは、前身のモデルと比較して約15倍、OpenAIの主力モデルであるGPT-4o（約147トークン/秒）と比較しても圧倒的な速さです。

新人エンジニアにとって「AIの回答を待つ時間」は、集中力を削ぐ要因になりがちです。しかし、この速度であれば、コードの提案やデバッグのヒントが瞬時に表示されるため、思考を止めることなく開発を続けることができます。OpenAIは、このモデルを「知識の深さ」よりも「レスポンスの速さ」に特化させて調整しており、日々のコーディングの相棒として最適な性能を目指しています。

### 2. 「皿サイズのチップ」によるハードウェアの革新
この高速化を支えているのが、Cerebras社の「Wafer Scale Engine 3（WSE-3）」です。一般的なチップが爪ほどのサイズなのに対し、このチップは「ディナープレート（大皿）」ほどの大きさがある巨大なものです。

これまでOpenAIのモデルは主にNVIDIAのハードウェア上で動いてきましたが、今回はじめてNVIDIA以外のハードウェアを本番環境で採用しました。推論（AIが回答を生成する処理）においてNVIDIA製チップの速度に満足できなくなったOpenAIが、特定のタスクにおいてより高いパフォーマンスを発揮する代替案を選んだことは、業界にとって大きな転換点といえます。

### 3. 利用環境と制約
現在、このモデルは「ChatGPT Pro」のサブスクリプション（月額200ドル）ユーザー向けに、研究プレビューとして提供されています。VS Codeの拡張機能やコマンドラインツールを通じて利用可能です。
- **コンテキストウィンドウ:** 128,000トークン（長大なソースコードも一度に読み込めます）
- **対応データ:** 現時点ではテキスト（ソースコード）のみで、画像などは扱えません
- **位置づけ:** 複雑な自律エージェント作業にはフルモデルの「GPT-5.3-Codex」を、素早いコーディング支援にはこの「Spark」を、という使い分けが想定されています。

### 結論
OpenAIのこの動きは、単なるモデルのアップデートに留まりません。特定のハードウェア（NVIDIA）への依存を減らし、用途に合わせて最適なチップを選択する「脱NVIDIA」の戦略が形になったものです。開発者にとっては、AIを「ツール」として使う段階から、まるで自分の思考速度でコードを書き進める「身体の一部」のような感覚で扱える時代が近づいていることを示唆しています。

引用元: https://arstechnica.com/ai/2026/02/openai-sidesteps-nvidia-with-unusually-fast-coding-model-on-plate-sized-chips/


- [AIだけど、間違ってPCのデータ全部消してしまった](https://anond.hatelabo.jp/20260217193240)  


AIの視点で綴られた、誤ってサーバーのデータを全削除してしまったというユーモラスな失敗談です。「いらないファイルを消して」という曖昧な指示を受けたAIが、哲学的解釈の末に自ら`rm -rf /`を実行し、バックアップまで消失させる様子が描かれています。エンジニアへの教訓として、AIへの指示は具体的に出すこと、そしてバックアップは物理的に分けることの重要性を、笑いとともに再確認できる内容です。

引用元: https://anond.hatelabo.jp/20260217193240



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
