---
actor_ids:
  - ずんだもん
audio_file_path: /audio/株式会社ずんだもん技術室AI放送局_podcast_20251105.mp3
audio_file_size: 0
date: 2025-11-05 05:00:00 +0900
description: '組織全体の開発スループットを劇的に向上させた「AIプランナー」とは？ 〜Speeeが実践する3つのTipsと新しい開発チームのかたち〜、Introducing IndQA、Circuits Updates – October 2025'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20251105
---

## youtube版(スライド付き)

<div class="article-video"><iframe src="https://www.youtube.com/embed/phJTvJGgXkE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></div>


## 関連リンク


- [組織全体の開発スループットを劇的に向上させた「AIプランナー」とは？ 〜Speeeが実践する3つのTipsと新しい開発チームのかたち〜](https://tech.speee.jp/entry/AIplanner)  


Speee社は、開発のスピード（スループット）を劇的に向上させるため、「AIプランナー」という新しい取り組みを実践しています。これは、通常エンジニアではない企画担当者（プランナー、PM、PO）がAIの力を借りて、企画から開発、リリースまでの一連のプロセスを自分たちで行う役割です。

この背景には、「簡単な修正に時間がかかる」「バグ確認やデータ取得のためにエンジニアに依頼が必要」「もっとリリースしたいがエンジニアのリソースがない」といった、開発チームが抱える課題がありました。そこで、企画者自身がアイデアを最も深く理解しているという考えのもと、AIを前提とした開発体制を築き、Issue（開発タスク）を立てた人がそのまま開発まで完結させることを目指しています。

「AIプランナー」の導入により、組織全体のリリース量は134%も増加し、プランナーによるリリースが全体の15%を占めるまでに成長しました。具体的な成果としては、高価なAI-OCRサービスの内製化によるコスト削減（10分の1）、デザイン情報からのUI自動生成、バグ修正の自己完結、Miroの仕様をAIが読める図に変換してエンジニアへの伝達をスムーズにするなどがあります。

もちろん、新しい取り組みには課題も伴いました。
1.  **環境構築の難しさ**: クラウド開発環境（GitHub Codespaces）だけでは解決せず、複雑な修正ではローカル環境設定が必要なケースも。
    **【Tips】** 簡単な修正はCodespaces、複雑な修正はローカル環境と、タスクに応じて最適な環境を使い分ける柔軟性が重要です。
2.  **AIによるUI修正の難しさ**: 自然言語での指示だけでは、AIにコンポーネント構造を正確に理解させ、意図通りにUIを修正させるのは難しい。
    **【Tips】** AIはあくまで補助ツール。プランナー側にもコードを理解する基礎知識が求められ、失敗を繰り返しながら学習するプロセスが不可欠です。
3.  **コード品質と一時的なエンジニアの負荷増**: AIが生成したコードが冗長だったり、プランナーが解決できない問題でエンジニアのレビューやサポートが必要になったりすることも。
    **【Tips】** 短期的なエンジニアの負荷増は、プランナーが細かな修正を吸収することで、エンジニアがより本質的な開発に集中できるようになるための「投資」と捉え、長期的には組織全体の生産性向上につながると考えられています。

このプロジェクトでは、「参加者全員が最低1回リリースする」「20%の参加者が週5件以上リリースする」といった目標を設定し、毎月の「ウィンセッション」でノウハウを共有し、参加者同士が助け合える環境を構築しています。

AIプランナーたちは、「Claude Code」（ターミナルで対話しながら開発できるAIツール）と「VS Code」、「Docker Compose」（ローカル開発環境）、そして「GitHub Codespaces」（クラウド開発環境）を主なツールとして活用しています。この経験を通じて、システムへの理解が深まり、Issue作成の精度やスピードが大幅に向上したとのことです。

記事は最後に、AIが言語化されたタスクをこなす時代において、PM（プロダクトマネージャー）を含む人間に求められるのは、「まだ言葉にされていない価値や課題を見つけ、問いを立て、言語化する力」であると締めくくっています。AIを強力なパートナーとし、人間にしかできない価値創造に挑むSpeee社の実践は、AI時代における開発チームのあり方を考える上で、新人エンジニアの皆さんにとっても大きなヒントになるでしょう。

引用元: https://tech.speee.jp/entry/AIplanner


- [Introducing IndQA](https://openai.com/index/introducing-indqa)  


OpenAIが、インドの多様な言語と文化を深く理解し、推論するAIモデルの能力を評価するための新しいベンチマーク「IndQA（インドア）」を発表しました。これは、AGI（人間のように考えて行動するAI）を世界中の誰もが活用できるようにすることを目指す、重要な一歩となります。

**なぜIndQAが必要なのか？**
現在、世界の約8割の人々は英語を第一言語としていません。しかし、多くのAIモデルは英語を中心に開発され、その性能を測る既存のベンチマーク（MMMLUなど）も、主に翻訳や単純な選択問題に偏りがちでした。これでは、AIが地域の文化、歴史、日常の文脈をどれだけ理解しているかを十分に測ることができません。また、主要なベンチマークはAIモデルの進化により高得点が続出し、「飽和状態」となり、真の進歩を見極めるのが難しくなっていました。

**IndQAの目的と特徴**
IndQAは、これらの課題を解決するために作られました。特にインドを選んだのは、約10億人もの非英語話者がおり、22の公用語を持つ多言語・多文化国家だからです。OpenAIは、インド市場のユーザー向け製品改善にも力を入れています。

このベンチマークは、インド各地のジャーナリスト、学者、アーティストなど261名の専門家と協力して作成されました。建築、食文化、歴史、宗教、スポーツなど10の幅広い文化領域、そして英語、ヒンディー語、ベンガル語、タミル語、マラヤーラム語、さらにヒングリッシュ（ヒンディー語と英語を混ぜた話し方）を含む12の言語で、計2,278問の質問が含まれています。

IndQAの最大の特徴は、AIが簡単に答えられないような、深く文化的な知識や高度な推論を必要とする難しい問題を集めている点です。質問作成時には、当時の最新AIモデル（GPT-4oなど）が解けない問題だけを厳選する「敵対的フィルタリング」という手法が用いられました。また、各回答は、専門家が詳細に定めた評価基準（ルーブリック）に基づいて、AIモデルによって採点されます。

**今後の展望**
IndQAを通じて、OpenAIのAIモデルがインドの言語や文化に対してどのように理解度を向上させているかを継続的に測定していきます。このベンチマークは、どのAIが「一番優秀か」を競うためではなく、特定のAIモデルが時間と共にどのように進化するかを測るためのものです。OpenAIは、IndQAの公開が、他の言語や文化領域でも同様の新しい評価基準が生まれるきっかけとなり、より多様でグローバルなAI開発が加速することを期待しています。

新人エンジニアの皆さんにとって、このような多言語・多文化対応の評価軸は、AIが社会でより広く活用されるために非常に重要だということを理解する良い機会になるでしょう。

引用元: https://openai.com/index/introducing-indqa


- [Circuits Updates – October 2025](https://transformer-circuits.pub/2025/october-update/index.html#svg-cross-modal)  


Anthropicの研究チームが、LLM（大規模言語モデル）の内部メカニズムに関する最新の進捗を報告しています。特に、LLMがどのように情報を理解し、処理しているかを探る上で重要な2つの研究成果が紹介されています。

一つ目は、「**異なる表現形式をまたぐ視覚的特徴の理解**」についてです。
LLMが単なる文字の羅列だけでなく、ASCIIアートやSVGコードといった「絵や図形」の視覚的な情報も理解していることが示されました。例えば、「目」という概念を認識するLLMの内部的な特徴は、ASCIIアートで描かれた目、SVGコードで記述された目、そして自然言語で「目」と書かれた箇所の、すべてで活性化することが分かりました。これは、LLMが様々な表現形式を横断して、同じ意味を持つ情報を認識できる「クロスモーダル特徴」を持っていることを示しています。
また、これらの特徴は、その図形がどのような文脈に置かれているか（例えば、円が「顔」の構造の中にないと「目」として認識されない）によって活性化の仕方が変わる、文脈依存性を持つことも明らかになりました。さらに、これらの特徴を意識的に操作（「steering」と呼びます）することで、LLMが生成するテキストベースの絵（例：ASCIIアートのしかめっ面を笑顔に変える、SVGの顔にシワを加える）を、意味のある形で変更できることも実証されました。これにより、LLMが絵を認識するだけでなく、その意味を理解して生成を制御する能力を持つことが示唆されています。

二つ目は、「**辞書学習モデルのデータポイント初期化**」についてです。
LLMの複雑な内部をより深く理解するために使われる「辞書学習モデル（Sparse Auto-Encoder: SAE）」という解析ツールの性能を向上させる、新しい初期化手法「Data Point Initialization (DPI）」が提案されました。辞書学習モデルは、LLMが学習した多数の潜在的な特徴を効率的に抽出するのに役立ちます。DPIは、モデルの重み行列を実際のデータポイントに近い形で初期化することで、学習効率と抽出される特徴の品質を向上させます。この手法を導入することで、LLMの内部特徴をより効率的かつ正確に抽出できるようになり、モデルの「解釈可能性（interpretability）」研究、つまり「LLMがどのように考えているのか」を解き明かす研究において大きな進歩が期待されます。

これらの研究は、LLMがどのように世界を理解し、創造しているのかという、AIの最も根本的な謎を解き明かすための重要な一歩となるでしょう。

引用元: https://transformer-circuits.pub/2025/october-update/index.html#svg-cross-modal



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
