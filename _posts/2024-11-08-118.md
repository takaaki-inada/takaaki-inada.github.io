---
actor_ids:
  - ずんだもん
audio_file_path: /audio/株式会社ずんだもん技術室AI放送局_podcast_20241108.mp3
audio_file_size: 0
date: 2024-11-08 05:00:00 +0900
description: 'AIやテクノロジーに関する記事を紹介  
SCIPE - Systematic Chain Improvement and Problem Evaluation、Supercharging AI Coding Assistants with Gemini Models Context、Unleashing Stability AI’s most advanced text-to-image models for media, marketing and advertising: Revolutionizing creative workflows  Amazon Web Services'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20241108
information: 
---

## 関連リンク


- [SCIPE - Systematic Chain Improvement and Problem Evaluation](https://blog.langchain.dev/scipe-systematic-chain-improvement-and-problem-evaluation/)  



SCIPEは、複数のLLM（大規模言語モデル）呼び出しを含む複雑なLLMチェーンにおける問題箇所特定を支援するツールです。LLMアプリケーション開発において、最終出力だけでなく中間出力の評価も重要ですが、リソース制約から見過ごされがちです。LLMチェーンの1つのノードの不具合が、全体に悪影響を及ぼすため、デバッグが困難になります。

SCIPEは、LLMチェーンの各ノードの入力と出力を分析し、修正によって最終出力の精度を最も向上させるノードを特定します。これは、正解データ（ground truth）を必要とせず、LLM自身を評価者として利用することで実現しています。

SCIPEはノードの故障確率を2種類に分類します。

1. **独立故障**: ノード自体、またはそれを処理するLLMに起因する故障。
2. **従属故障**: 上流のノードの故障が原因で発生する故障。

LLM評価者(LLM Judge)を用いて各ノードの出力を評価し、パス/フェイルスコアを生成します。この結果から、条件付き故障確率（上流ノードも故障している場合のノード故障率）と独立故障確率を計算し、問題ノードを特定します。

最も下流のノードから開始し、条件付き故障確率に基づいて上流ノードを辿り、独立故障確率が最も高いノードを根本原因として特定します。これは、再帰的なアルゴリズムで実装されています。

SCIPEを使用するには、Langgraphから生成されたアプリケーショングラフ、各ノードの入出力データ（DataFrame形式）、そして設定ファイルが必要です。設定ファイルには、LLM評価者のモデル名、検証結果の保存先などが含まれます。

`LLMEvaluator`クラスを用いて、LLM評価を実行し、`find_problematic_node()`メソッドで問題ノードを特定します。結果は、根本原因ノード、デバッグパス、各ノードの故障確率を含む`EvaluationResult`オブジェクトとして出力されます。

SCIPEは、LLMチェーンにおける問題ノードの特定と修正を支援することで、LLMアプリケーションの信頼性と性能向上に貢献します。  GitHubリポジトリには、具体的な使用方法や詳細な技術情報は記載されていますが、本要約では省略しています。


引用元: https://blog.langchain.dev/scipe-systematic-chain-improvement-and-problem-evaluation/


- [Supercharging AI Coding Assistants with Gemini Models Context](https://developers.googleblog.com/en/supercharging-ai-coding-assistants-with-massive-context/)  



GoogleとSourcegraph社による共同研究で、Gemini 1.5 ProとFlashモデルを用いた大規模コンテキストウィンドウ（最大100万トークン）が、AIコーディングアシスタントの精度向上に大きく貢献することが示されました。

従来のAIモデルは、大規模なコードベースにおける複雑な関係性や依存関係の理解に課題がありましたが、この研究では、大規模コンテキストウィンドウによってコード理解と生成の精度が向上することを実証しています。

Sourcegraph社が開発したコーディングアシスタント「Cody」を用いた実験では、100万トークンのコンテキストウィンドウを使用することで、以下の3つの指標で大幅な改善が見られました。

* **Essential Recall（必須情報の再現率）:** 回答に含まれる重要な事実の割合が大幅に増加しました。
* **Essential Concision（必須情報の簡潔さ）:** 回答の長さに対する必須情報の割合が向上し、より簡潔で関連性の高い回答が得られるようになりました。
* **Helpfulness（有用性）:** 回答の長さに対する有用性のスコアが大幅に向上し、よりユーザーフレンドリーな体験が実現しました。

さらに、幻覚率（事実と異なる情報の生成）も18.97%から10.48%に減少しました。これは、AIによるコード生成の信頼性を高める上で重要な成果です。

ただし、大規模コンテキストウィンドウを使用する際には、処理時間増加というトレードオフが存在します。Sourcegraph社は、プリフェッチ機構と階層型コンテキストモデルアーキテクチャによるモデル実行状態キャッシングを実装することで、1MBのコンテキストにおける最初のトークン生成時間を30～40秒から約5秒に短縮することに成功しました。

この研究成果は、大規模コンテキストモデルがコード理解と生成を革新的に変える可能性を示唆しており、今後のAIコーディングアシスタントの発展に大きな影響を与えるものと期待されます。  詳細な評価方法やベンチマーク、分析については、Sourcegraph社のブログ記事を参照ください。


引用元: https://developers.googleblog.com/en/supercharging-ai-coding-assistants-with-massive-context/


- [Unleashing Stability AI’s most advanced text-to-image models for media, marketing and advertising: Revolutionizing creative workflows  Amazon Web Services](https://aws.amazon.com/blogs/machine-learning/unleashing-stability-ais-most-advanced-text-to-image-models-for-media-marketing-and-advertising-revolutionizing-creative-workflows/)  



Amazon Bedrock上で利用可能になったStability AIの最新テキスト・トゥ・イメージモデル（Stable Image Ultra、Stable Diffusion 3 Large、Stable Image Core）は、メディア、広告、エンターテインメント業界のワークフローを革新します。これらのモデルは、従来のStable Diffusion XLよりも大幅に改良されており、特にテキストの品質、複雑なシーンの描写、写実性の向上に優れています。

**主な改善点**は、より正確なプロンプトへの対応、テキストの正確なレンダリング、複雑なシーンの描写力向上、写真のような写実性、多様な入力への対応、スケーラビリティの向上、そして高度なDiffusion Transformerアーキテクチャの採用です。  Stable Image CoreはSDXLの後継として高速かつ低価格な選択肢を提供し、Stable Diffusion 3 LargeとStable Image Ultraは、より高度なアーキテクチャにより、高品質な画像と優れたタイポグラフィを実現します。パラメータ数は、Stable Image Coreが26億、Stable Diffusion 3 LargeとStable Image Ultraが80億です。

これらのモデルは、**コンセプトアート、ストーリーボード、広告素材、ソーシャルメディアコンテンツ**など、幅広い用途に活用できます。例えば、広告代理店は、ブランドアイデンティティに合わせた視覚素材を迅速に生成し、マーケティングキャンペーンを効率化できます。映画制作では、セットデザインの視覚化や仮想制作に役立ち、時間とコストを削減できます。

さらに、提供されているJupyter Notebookのサンプル(詳細は割愛)では、大規模言語モデル(LLM)とStable Diffusion 3 Largeを組み合わせた、広告キャンペーンのエンドツーエンド生成プロセスが示されています。これは、LLMによるアイデア生成と画像生成モデルによるビジュアル作成を統合することで、高品質な広告素材を迅速に作成できることを実証しています。

これらのモデルは、従来の手法では困難だった、抽象的な概念や複雑なスタイルの表現を可能にし、クリエイティブな表現の幅を大きく広げます。新人エンジニアにとっても、これらのモデルは、高度な画像生成技術を容易に利用できる強力なツールとなるでしょう。  ただし、各モデルの特性(パラメータ数、入力形式、出力品質など)を理解し、目的に最適なモデルを選択することが重要です。


引用元: https://aws.amazon.com/blogs/machine-learning/unleashing-stability-ais-most-advanced-text-to-image-models-for-media-marketing-and-advertising-revolutionizing-creative-workflows/



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
