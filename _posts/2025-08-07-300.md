---
actor_ids:
  - ずんだもん
audio_file_path: /audio/株式会社ずんだもん技術室AI放送局_podcast_20250807.mp3
audio_file_size: 0
date: 2025-08-07 05:00:00 +0900
description: 'Introducing Open SWE: An Open-Source Asynchronous Coding Agent、強化学習で効率の良い検索を実現するRAGの手法、ACL2025＠ウィーンに現地参加しました、最近病院で”自分の症状をAIに要約させて持参する人”が増えたんだけど正直すごく助かってる→「要約させて問診票に書いたら医療関係者じゃないかと警戒された」'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20250807
---

## 関連リンク


- [Introducing Open SWE: An Open-Source Asynchronous Coding Agent](https://blog.langchain.com/introducing-open-swe-an-open-source-asynchronous-coding-agent/)  


ソフトウェア開発におけるAIの利用は、数年の間に大きく進化しました。最初はコードの自動補完から始まり、やがてIDE（開発環境）でコード作成を支援するCopilotのような存在へ。そして今、クラウド上で非同期に動き、より自律的にソフトウェア開発のタスク全体をこなす「AIエージェント」へと進化しています。

今回発表された「Open SWE」は、この次世代AIエージェントの先駆けとなるオープンソースプロジェクトです。これは、まるでチームの新しいメンバーのように働く非同期型のコーディングエージェントで、主に以下のような特徴を持っています。

Open SWEは、GitHubリポジトリと直接連携し、GitHubのIssueからタスクを受け取ることができます。コードベースの調査、詳細な実行計画の立案、コードの記述、テストの実行、自己レビュー、そして最終的にプルリクエスト（PR）の作成まで、一連の開発プロセスを自動で実行します。

特に新人エンジニアにとっても嬉しいポイントは、AI任せにしない「人間参加型」の仕組みです。Open SWEが計画を立てた際に、その計画をレビューして承認したり、途中で指示を変更したり、新しい要望を追加したりすることが可能です。これにより、AIが勝手に進めてしまうことへの不安がなく、AIと協力しながら開発を進められます。

また、Open SWEはGitHubの既存ワークフローに深く統合されます。例えば、GitHubのIssueに特定のラベルを付けるだけで、Open SWEがタスクを開始し、完了時には自動でPRを作成してくれます。さらに、各タスクは隔離された安全な環境（サンドボックス）で実行されるため、セキュリティ面も安心です。クラウド上で非同期に動作するため、あなたのローカルPCのリソースを消費することなく、複数のタスクを並行して処理させることが可能です。

Open SWEの内部では、計画役（Planner）とレビュー役（Reviewer）といった専門のエージェントが連携して動いています。これにより、いきなりコードを書き始めるのではなく、まずはしっかり計画を立て、コードを書いた後も自己レビューとテストを行うため、高品質で動作するコードを生成しやすいのが強みです。

現時点では、複雑で時間のかかる開発タスクに向いていますが、今後は簡単なバグ修正やスタイル調整にも対応できるバージョンが開発される予定です。Open SWEはオープンソースとして公開されており、開発者が自由に拡張・カスタマイズできるため、AIと人間が協調する未来のソフトウェア開発の基盤となることが期待されています。

引用元: https://blog.langchain.com/introducing-open-swe-an-open-source-asynchronous-coding-agent/


- [強化学習で効率の良い検索を実現するRAGの手法](https://zenn.dev/knowledgesense/articles/05de2f39d5f420)  


この記事では、AIが賢く情報を探すための新しい技術「GraphRAG-R1」について解説しています。

皆さんご存知の通り、ChatGPTのようなLLM（大規模言語モデル）は、質問に答える能力が非常に高いです。しかし、LLMは学習した時点までの情報しか持っていないため、最新の情報や特定の専門知識については苦手な場合があります。そこで活躍するのが、RAG（Retrieval Augmented Generation）という技術です。RAGは、LLMが外部のデータベースなどから必要な情報を検索して「参照」しながら、より正確で詳細な回答を生成する仕組みです。

最近のRAGの主流は、一度に全ての情報を探すのではなく、質問の内容に応じて必要な情報が見つかるまで、何度も検索を繰り返す「繰り返し検索」という方法です。この方法には、「必要な情報を見つけきれない（検索不足）」ことや、「もう十分なのに探し続けてしまう（検索過多）」といった課題がありました。これらの課題は、LLMが適切な「コンテキスト」（回答に必要な情報）を得ることを妨げていました。

今回紹介されている「GraphRAG-R1」は、この「繰り返し検索」の精度を大幅に高めるための画期的な手法です。強化学習という、コンピューターが試行錯誤しながら最適な行動を学ぶ技術（例えば、ゲームのAIがプレイを重ねるうちに上手くなるようなイメージです）をRAGに適用しています。これにより、RAGは「どんな情報を、どのタイミングで、どれくらい探すべきか」を非常に賢く判断できるようになります。

GraphRAG-R1の大きな特長は、既存のRAGシステムに後から追加して、その能力を引き出せる汎用性の高さです。強化学習では、「正解の文章を見つけること」と「回答の品質と検索にかかるコストのバランス」という2つの「ご褒美（報酬）」を設定することで、AIは無駄なく、かつ必要な情報を効率的に集める方法を学びます。

実際の評価では、GraphRAG-R1を導入したRAGは、従来のRAGと比べて最大で80%以上も性能が向上したという驚くべき結果が出ています。これは、LLMがより正確で質の高い回答を出せるようになったことを意味します。

GraphRAG-R1は、RAGが「より適切な検索クエリを生成する能力」と「検索を続けるべきか、止めるべきかという最適な判断能力」を劇的に向上させる、非常に優れた技術と言えるでしょう。これからLLMを活用したシステム開発に携わる新人エンジニアの皆さんにとって、このような最新の検索技術は、今後のスキルアップに欠かせない知識となるはずです。ぜひ、この技術の可能性に注目してみてください。

引用元: https://zenn.dev/knowledgesense/articles/05de2f39d5f420


- [ACL2025＠ウィーンに現地参加しました](https://acro-engineer.hatenablog.com/entry/2025/08/06/120000)  


この記事は、自然言語処理分野で最も権威ある国際学会の一つ「ACL2025」に筆者が現地参加した際の報告です。新人エンジニアの皆さんにも分かりやすく、最新のトレンドと注目された研究内容を紹介します。

**ACLとは？**
ACL（Association for Computational Linguistics）は、自然言語処理（NLP）という、コンピュータが人間の言葉を理解し、処理する技術を扱う大規模な国際学会です。近年、大規模言語モデル（LLM）の発展が目覚ましく、それに伴いACLへの論文投稿数も昨年から大幅に増え、今年は8360本もの論文が集まりました。これは、LLMが世界的に大きな注目を集めている証拠と言えます。

**学会の様子とトレンド**
今年のACLはオーストリアのウィーンで開催され、キーノート講演、技術セッション、ポスター発表、そして参加者同士の交流会など、様々なイベントがありました。筆者が特に感じたトレンドは、LLMにこれまでよりもっと複雑なタスクを実行させるための「ベンチマーク」を作る研究が多かったことです。例えば、計画を立てる能力や、構造化されたデータを理解する能力を測るための新しい評価方法が提案されていました。これは、私たちが普段LLMを使う中で、「もっとこんなことができたら」と感じるような、より高度な活用に繋がる研究が多いということです。

**特に注目されたセッションや論文**
*   **「LLMの不確実性（Uncertainty）を測る」**: LLMの回答がどれくらい「確実」なのかを評価する研究です。例えば、重要な意思決定に関わる場面でLLMを使う場合など、回答の信頼性が高いか低いかを知ることは非常に重要になります。
*   **「構造化データ生成の高速化」**: LLMがJSONなどの決まった形式でデータを出力する際に、その処理をより速く、効率的に行うための新しいアルゴリズムが提案されました。LLMにシステム連携用のデータなどを生成させる際に、この技術が役立ちます。
*   **「プロンプト最適化による評価の改善」**: LLMの性能を比較する際、同じプロンプト（指示文）で評価するだけでなく、モデルごとに最適なプロンプトを使うことで、より正確な能力が測れるという研究です。プロンプトエンジニアリングの重要性を示しています。
*   **「長文RAGの効率化」**: RAG（検索拡張生成）という、長い文章から必要な情報を探してLLMに回答させる技術について、回答の精度を保ちながら、LLMが処理する情報量を10分の1に減らす新しい方法が提案されました。これにより、LLMを使う際のコスト削減や処理速度の向上が期待できます。

**まとめ**
今回のACL2025を通じて、LLMの研究は、単なる文章生成から、より複雑なタスクや実世界での応用へと進化していることが感じられました。LLMが私たちの仕事や生活にもっと役立つように、その技術が日々進化していることが分かりますね。

引用元: https://acro-engineer.hatenablog.com/entry/2025/08/06/120000


- [最近病院で”自分の症状をAIに要約させて持参する人”が増えたんだけど正直すごく助かってる→「要約させて問診票に書いたら医療関係者じゃないかと警戒された」](https://togetter.com/li/2585794)  


最近、病院でAIを使って自分の症状を要約し、医師に見せる人が増えています。この方法は医師にとっても症状が分かりやすくなるため、診察がスムーズに進み大変喜ばれています。AIの日本語要約能力は高く、自分の症状をうまく伝えられない場合でも、AIを使うことで正確に伝えることが可能になります。これは、AIが日常生活のコミュニケーションを円滑にする強力なツールとして役立つ具体的な例であり、身近な問題解決にAIを活用するヒントになります。

引用元: https://togetter.com/li/2585794



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
