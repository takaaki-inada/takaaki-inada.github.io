---
actor_ids:
  - ずんだもん
audio_file_path: /audio/株式会社ずんだもん技術室AI放送局_podcast_20251015.mp3
audio_file_size: 0
date: 2025-10-15 05:00:00 +0900
description: 'Make agents a reality with Amazon Bedrock AgentCore: Now generally available  Amazon Web Services、Securing your agents with authentication and authorization、StreamingVLM: Real-Time Understanding for Infinite Video Streams、イラストレーターさん「あなたの愛猫を描きます！」企画に寄せられた猫の開き画像が豪快すぎて笑顔になる'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20251015
---

## youtube版(スライド付き)

<div class="article-video"><iframe src="https://www.youtube.com/embed/5tR4-M4AumU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></div>


## 関連リンク


- [Make agents a reality with Amazon Bedrock AgentCore: Now generally available  Amazon Web Services](https://aws.amazon.com/blogs/machine-learning/amazon-bedrock-agentcore-is-now-generally-available/)  


AWSから、AIエージェントを開発し、実際のビジネスで活用するための新しいプラットフォーム「Amazon Bedrock AgentCore」が一般提供開始されました。これは、これまで試作段階にとどまりがちだったAIエージェントを、安全性、信頼性、スケーラビリティを確保しながら、本格的なサービスとして運用するための基盤となるものです。

AIエージェントとは、まるで人間のアシスタントのように、自律的に考え、タスクを遂行するプログラムのことです。例えば、ユーザーの質問に答えたり、情報を収集したり、複数のシステムを連携させて複雑な業務を自動化したりできます。しかし、これを企業レベルで安全かつ効率的に運用するには、多くの技術的な課題がありました。AgentCoreは、そうした課題を解決し、開発者がエージェントを素早く本番環境に導入できるように設計されています。

AgentCoreの主な特徴は以下の通りです。

*   **柔軟な開発**: 開発者は、Amazon Bedrockで提供されるAIモデルだけでなく、OpenAIやGoogle Geminiなど外部のモデル、そしてLangChainやCrewAIといったお好みの開発フレームワークを使って、自由にエージェントを構築できます。
*   **豊富なツール連携**: エージェントがコードを安全に実行できる「Code Interpreter」や、ウェブサイトを操作できる「Browser」機能が組み込まれています。また、既存の社内システムやAPIをエージェントから簡単に呼び出せるようにする「Gateway」機能もあり、エージェントはより多くのタスクを実行できるようになります。
*   **賢い記憶力**: 過去の会話や操作履歴を覚え、文脈を理解しながら対応する「インテリジェントメモリ」機能により、エージェントはより賢く、パーソナルな体験を提供できます。
*   **運用と監視**: エージェントの動作を詳細に監視し、問題が発生した場合に素早く原因を特定できる機能（Observability）が提供されます。また、予測不能な負荷にも自動で対応し、長時間のタスクでも安定して稼働できる信頼性の高い実行環境（Runtime）も備わっています。
*   **高いセキュリティ**: 高度なセキュリティ機能が組み込まれており、機密データを安全に扱いながら、企業システムにアクセスできます。

すでに、Amazon社内の製造プロセス自動化、医療分野での承認審査効率化、通信大手エリクソンやソニーグループでのAI活用など、様々な業界でAgentCoreが活用され、大きな成果を上げています。

AgentCoreは東京リージョンを含む世界9つのAWSリージョンで利用可能なので、日本のエンジニアの皆さんも、これらの強力な機能を使って、アイデアを素早く形にし、AIエージェントの可能性をビジネスに活かしていくことができます。

引用元: https://aws.amazon.com/blogs/machine-learning/amazon-bedrock-agentcore-is-now-generally-available/


- [Securing your agents with authentication and authorization](https://blog.langchain.com/agent-authorization-explainer/)  


AIエージェントは、チャットだけでなく、ファイル操作やメッセージ送信、外部ツールの利用といった「行動」ができる点が大きな特徴です。そのため、従来のAIアプリケーションよりもセキュリティ対策が重要になります。特に「認証（Authentication）」と「認可（Authorization）」は、エージェントを安全に運用するために欠かせない要素です。

**認証（AuthN）と認可（AuthZ）の基本**
認証とは「あなたが誰であるか」を確認するプロセスです。例として、システムにログインする際にユーザー名とパスワードで本人確認をするのが認証です。一方、認可とは「認証されたあなたが何ができるか」を判断し、アクセス権限を制御するプロセスです。この二つは合わせて「認証認可（Auth）」と呼ばれ、あらゆるアプリケーションで重要ですが、AIエージェントには特有の課題があります。

**AIエージェントが従来のアプリケーションと違う点**
1.  **多くのサービスへのアクセス:** エージェントは、従来のアプリケーションよりもはるかに多くの異なるサービスやツール（例：メール、カレンダー、データベースなど）にアクセスする必要があります。
2.  **動的に変化するアクセス要件:** エージェントの行動は、その時々の状況によって必要な権限が大きく変わるため、柔軟なアクセス制御が必要です。
3.  **監査の複雑さ:** 多くのサービスをまたいで行動するため、エージェントが行った操作の記録（監査ログ）があちこちに分散し、全体の動きを追跡・確認するのが難しくなります。

これらの課題に対応するため、将来的にはエージェントの認証認可を一元的に管理する新しいシステムが必要になると考えられています。しかし、現在の技術でもエージェントのセキュリティは確保できます。

**現在のAIエージェントの認証認可**
エージェントも基本的にはリソースにアクセスするソフトウェアであるため、既存の認証認可技術である「OAuth 2.0」や「OIDC」といった業界標準のフレームワークを効果的に利用できます。エージェントのアクセスパターンは大きく二つに分けられます。

1.  **委任アクセス (Delegated Access):** エージェントがユーザーの「代理」としてリソースにアクセスする場合です。例えば、メールアシスタントがユーザーの許可を得てメールボックスにアクセスし、メールを処理するようなケースです。
    *   この場合、「Auth Code Flow」と「OBO (On-Behalf-Of) Token Flow」といったOAuth 2.0のフローが主に使われます。
2.  **直接アクセス (Direct Access):** エージェントが人間の関与なしに、自律的にリソースにアクセスする場合です。例えば、セキュリティエージェントが自動でシステムログを監視し、異常を検知するようなケースです。
    *   この場合、「Client Credentials Flow」というOAuth 2.0のフローが主に使われます。

**まとめ**
AIエージェントの能力が高まり、自律性が増すにつれて、認証認可の重要性はますます高まります。OAuth 2.0などの既存の標準技術を理解し、適切に活用することが、安全なエージェントを開発するための第一歩です。特に「Auth Code Flow」「OBO Token Flow」「Client Credentials Flow」の3つのフローは、多くのエージェントにおけるアクセス制御で役立つでしょう。

引用元: https://blog.langchain.com/agent-authorization-explainer/


- [StreamingVLM: Real-Time Understanding for Infinite Video Streams](https://arxiv.org/abs/2510.09608)  


最近注目されている「画像とテキストを同時に理解するAIモデル（VLM）」は、私たちが普段使っているAIアシスタントや、自動運転のような自律的に動くシステムにおいて、動画をリアルタイムで理解するための鍵となります。しかし、現在のVLMには大きな課題がありました。それは、終わりなく続く長い動画ストリームを処理する際に、システムが遅くなったり、メモリを使いすぎたりすることです。

従来のやり方では、動画全体を一度に処理しようとすると、動画が長くなるほど計算量が爆発的に増え（動画の長さの2乗に比例！）、現実的ではありませんでした。また、動画を区切って少しずつ処理する「スライディングウィンドウ方式」という方法もありますが、これだと動画全体の文脈が途切れてしまったり、同じ部分を何度も計算し直すために無駄な処理が多く発生し、結局遅延につながっていました。

このような課題を解決するため、この論文では「StreamingVLM」という新しいモデルを提案しています。StreamingVLMは、無限に続く視覚情報（動画）を、リアルタイムかつ安定して理解できるように設計されています。

彼らのアプローチのポイントはいくつかあります。
まず、AIモデルの学習方法と、実際に動かす推論方法を統一した枠組みで考えることで、より効率的な処理を実現しています。
推論時には、AIが過去の情報を記憶しておくための「KVキャッシュ」という領域をコンパクトに保つ工夫がされています。具体的には、重要な情報（アテンションシンク）を再利用したり、直近の短い動画フレームの情報と、直近の長いテキストの情報をうまく組み合わせたりして、必要な情報だけを効率的に保持します。

このリアルタイム処理能力は、シンプルな「教師ありファインチューニング（SFT）」という学習方法によって実現されています。これは、全体を一度に見るのではなく、短いながらも少しずつ重なる動画の塊（チャンク）を使って学習させることで、非常に長い動画を処理するための特殊な学習をせずとも、実際の推論時と同じようなアテンションの動きをモデルに覚えさせることができます。

StreamingVLMの性能を評価するために、研究チームは平均2時間以上という超長時間の動画を含む、新しい評価基準「Inf-Streams-Eval」を作成しました。このベンチマークで、StreamingVLMは競合する「GPT-4O mini」に対して66.18%の勝率を達成し、NVIDIA H100という高性能なGPU一枚で、1秒間に最大8フレームという安定したリアルタイム処理を実現しています。さらに、このSFT学習戦略は、特定の画像質問応答（VQA）タスク向けのチューニングなしに、一般的なVQA能力も向上させ、他の主要なベンチマークでも優れた結果を出しています。

このStreamingVLMは、将来のAIアシスタントや自律エージェントが、長く続く動画をスムーズに理解し、より賢く、より役立つ存在になるための重要な一歩と言えるでしょう。コードも公開されており、さらなる発展が期待されます。

引用元: https://arxiv.org/abs/2510.09608


- [イラストレーターさん「あなたの愛猫を描きます！」企画に寄せられた猫の開き画像が豪快すぎて笑顔になる](https://togetter.com/li/2615511)  


イラストレーター「はいらずんば@猫スケッチ」さんの「あなたのうちの子描きます」企画が注目を集めました。応募された写真の中でも、大胆に寝そべる猫の「豪快な開き」ポーズが特に話題に。「お股パッカーン」や「お手てのむん！」といった可愛らしい姿が多くの人の笑顔を誘い、SNS上で大きな反響を呼んでいます。猫の愛らしい一面が心を和ませる、楽しいニュースです。

引用元: https://togetter.com/li/2615511



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
