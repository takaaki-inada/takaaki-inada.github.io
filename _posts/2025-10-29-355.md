---
actor_ids:
  - ずんだもん
audio_file_path: /audio/株式会社ずんだもん技術室AI放送局_podcast_20251029.mp3
audio_file_size: 0
date: 2025-10-29 05:00:00 +0900
description: 'Develop Specialized AI Agents with New NVIDIA Nemotron Vision, RAG, and Guardrail Models、ClaudeCodeを使ったら手作りAWSが3日でTerraform化できた話、Doubling down on DeepAgents、車に乗ってたら同乗者が目視人力でQRコードを読みとり始め、答え合わせしたら正解しててドン引きした「人かどうかも怪しいな」'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20251029
---

## youtube版(スライド付き)

<div class="article-video"><iframe src="https://www.youtube.com/embed/br-SnlSHdcc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></div>


## 関連リンク


- [Develop Specialized AI Agents with New NVIDIA Nemotron Vision, RAG, and Guardrail Models](https://developer.nvidia.com/blog/develop-specialized-ai-agents-with-new-nvidia-nemotron-vision-rag-and-guardrail-models/)  

**タイトル**: Develop Specialized AI Agents with New NVIDIA Nemotron Vision, RAG, and Guardrail Models

**要約**:
NVIDIAは、AIエージェントの開発を加速するための新しいNemotronモデル群を発表しました。AIエージェントとは、自分で考えて計画を立て、状況に応じて行動できる自律的なAIのことです。今回の発表は、特定の業務に特化したAIエージェントを、より効率的かつ安全に構築できるようにすることを目指しています。

発表された主なモデルと、それぞれがAIエージェント開発にどう役立つかを簡単にご紹介します。

*   **Nemotron Nano 3**: これは、AIエージェントがもっと賢く、効率的に「思考」するためのモデルです。例えば、複雑な科学的な問題を解いたり、プログラミングをしたり、数学的な計算をしたり、他のツールをAIが使う際の精度を高める役割をします。MoE（Mixture-of-Experts）という特別な技術を使うことで、処理速度を速くしつつ、開発コストも抑えることができます。

*   **Nemotron Nano 2 VL**: 文書、画像、動画といったさまざまな種類の情報を理解できる「マルチモーダル」なAIエージェントを作るためのモデルです。これはAIエージェントに「目と耳」の役割を与えるようなもので、データ分析、文書の自動処理、動画の内容理解など、視覚情報とテキスト情報を組み合わせて判断するAIアシスタントの開発に役立ちます。

*   **Nemotron Parse 1.1**: 主に文書から必要な情報（テキストや表など）を正確に抽出することに特化した、コンパクトなモデルです。例えば、スキャンした書類から特定のデータを自動で抜き出すような場面で活躍し、その後の情報検索の精度向上や、AIの学習データを質の高いものにするのに役立ちます。

*   **Nemotron RAG**: AIエージェントが、最新の情報や企業内の独自のデータソースから知識を引き出して、より正確で信頼性の高い回答を生成するためのRAG（Retrieval-Augmented Generation）パイプラインを構築するのに使うモデル群です。社内マニュアルを参照して質問に答えるAIや、リアルタイムのビジネス分析を行うAIエージェントの基盤となります。

*   **Llama 3.1 Nemotron Safety Guard**: AIエージェントが意図せず不適切または有害な内容を出力しないように監視し、安全性を確保するためのモデルです。特に、多言語に対応しており、文化的な違いも考慮しながら、危険なプロンプト（指示）や応答を検出する能力を持っています。

これらのモデルに加え、NVIDIAはAIモデルの性能を評価するための「NeMo Evaluator SDK」や、AIエージェントの最適な設定を自動で見つける「NeMo Agent Toolkit」も提供し、開発者がより信頼性の高いAIエージェントを効率的かつ安全に作れるようサポートしています。

引用元: https://developer.nvidia.com/blog/develop-specialized-ai-agents-with-new-nvidia-nemotron-vision-rag-and-guardrail-models/


- [ClaudeCodeを使ったら手作りAWSが3日でTerraform化できた話](https://tech-blog.rakus.co.jp/entry/20251028/ai-terraforming)  


SREのgumamonさんが、AI Agentの一種である「ClaudeCode」を使って、既存のAWS環境をわずか3日でTerraform化できたという、実践的な事例を紹介する記事です。新人エンジニアの皆さんも、これからのインフラ管理でAIがどう役立つのか、その可能性と注意点を知る良い機会になるでしょう。

まず、**Terraform（テラフォーム）**とは、AWSのようなクラウドサービスのインフラ構成を「コード」として定義・管理できるようにするツールです。これにより、手作業に比べてミスの削減や繰り返し作業の効率化が期待できます。この記事では、これまで手作業で作られてきたAWS環境をTerraformのコードで管理できるように変更する「Terraform化」にClaudeCodeを活用しました。

AI Agentをインフラ管理に使う際、筆者は「**AIは怒れるインターン生**」という比喩を使い、その限界と注意点を指摘しています。AIは指示通りに動きますが、長い指示を覚えきれず、時には「やってはいけないこと」を提案することもあります。そのため、AIにインフラの変更を直接許可するのではなく、**サンドボックス環境**という隔離された場所で作業させ、権限を制限する「ガードレール」の設置が必須であると強調しています。具体的には、AWSへのアクセスは読み取り専用（ReadOnly）に限定し、Terraformの状態を管理するS3やDynamoDBへの最小限の書き込み権限のみ与えるといった工夫をしています。

実際の3日間のTerraform化プロセスでは、以下のステップを踏みました。
*   **Day1**: ClaudeCodeの導入と、プロジェクトの目的や構成をAIが理解しやすいようにプロンプト（指示文）を整備。この過程で、自分自身の既存AWS構成への理解が深まったそうです。
*   **Day2**: 既存のAWSリソースからTerraformコードを生成させ、`terraform import`を使ってリソースをTerraformの管理下に置きました。AIとの「ペアプログラミング」のように試行錯誤しながら、プロンプトを改善していきました。
*   **Day3**: 生成されたコードのリファクタリング（より良い形に整理すること）を行いました。AIにレビューさせて命名規則のばらつきなどを指摘してもらい、修正を進めました。プロンプトを分割することで、AIがより効率的に作業できるように改善した点もポイントです。

この取り組みを通じて、筆者は以下の大きな効果を実感しました。
1.  **圧倒的なスピード**: 自力で1ヶ月かかるような作業が、試行錯誤を含めてたった3日で完了。
2.  **高い応用力**: 通常のツールでは対応が難しいAWSリソースについても、ClaudeCodeはコードを生成できた。
3.  **大胆な意思決定**: AIの力を借りることで、手作業では諦めていた大規模なリファクタリングにも挑戦できた。
4.  **思考の整理**: AIに明確な指示を出すためにプロンプトを考える過程で、自身のインフラ構成への理解が深まった。

このように、AI Agentはインフラ管理の生産性を大きく向上させる可能性を秘めていますが、その特性を理解し、適切な権限管理や監視体制のもとで活用することが非常に重要です。AIをただ使うだけでなく、AIが働きやすい環境を人間が整えることで、より効果的な協働が生まれることを示唆する良い事例です。

引用元: https://tech-blog.rakus.co.jp/entry/20251028/ai-terraforming


- [Doubling down on DeepAgents](https://blog.langchain.com/doubling-down-on-deepagents/)  


LangChainチームは、複雑で長期間にわたるタスクを自律的に実行できるAIエージェント「DeepAgents」のバージョン0.2リリースを発表しました。これは、AIエージェントが単発のタスクを超え、より広範な問題解決に貢献することを目指すものです。

DeepAgentsの核となるのは、計画ツール、ファイルシステムへのアクセス、サブエージェント、詳細なプロンプトという4つの要素です。これらの機能をパッケージ化した`deepagents`ライブラリにより、開発者は独自のツールやプロンプトを組み合わせるだけで、高度なエージェントを効率的に構築できます。

今回の0.2リリース最大の目玉は、「Pluggable Backends（プラグ可能なバックエンド）」です。これまでのDeepAgentsは、エージェントが一時的に情報を保存する「仮想ファイルシステム」のみに限定されていました。しかし0.2からは、エージェントのファイルシステムとして、永続的なデータ保存が可能な「LangGraphストア」や「ローカルファイルシステム」など、様々な種類のストレージを自由に選べるようになりました。

この機能は、エージェントに長期記憶を持たせる上で非常に重要です。例えば、特定のディレクトリへのファイル操作をAmazon S3のようなクラウドストレージにマッピングすることで、エージェントは過去の経験や学習結果を永続的に保持し、将来のタスクに活かせるようになります。また、独自のデータベースと連携するカスタムバックエンドを作成したり、ファイル書き込みにルール（ガードレール）を設定したりする柔軟性も提供されます。

その他、0.2ではエージェントの運用効率を高める改善も複数追加されました。具体的には、大規模なツール実行結果の自動ファイル保存、会話履歴が長くなった場合の自動要約によるトークン最適化、ツール呼び出し中断時の履歴自動修正などが挙げられます。

LangChainチームは、LangChain、LangGraph、DeepAgentsという3つのオープンソースライブラリを提供しており、それぞれ異なる役割を持っています。LangGraphはワークフローとエージェントを組み合わせる「エージェントランタイム」、LangChainはエージェントのコアロジックを柔軟に構築する「エージェントフレームワーク」です。そしてDeepAgentsは、計画ツールやファイルシステムといった組み込み機能を活用し、より自律的で長期間稼働するエージェントを構築するための「エージェントハーネス」として位置づけられています。これら3つのライブラリは階層的に連携し、DeepAgentsはLangChainの上に、LangChainはLangGraphの上に構築されています。

新人エンジニアの皆さんにとって、DeepAgentsの進化は、AIエージェントがより複雑なタスクをこなし、実世界で役立つ存在になるための重要な一歩を示しています。ぜひ、これらのライブラリに触れ、未来のAIエージェント開発に挑戦してみてください。

引用元: https://blog.langchain.com/doubling-down-on-deepagents/


- [車に乗ってたら同乗者が目視人力でQRコードを読みとり始め、答え合わせしたら正解しててドン引きした「人かどうかも怪しいな」](https://togetter.com/li/2621269)  


走行中の車内で、同乗者が前の車のQRコードを「目視」で解読し、そのURLを手入力するという驚きの出来事がありました。後でカメラで確認したところ、手入力したURLが正確に一致していたことが判明。通常は機械が読み取るQRコードを、補助ツールなしで人間が完璧に読み解くという、信じられないような超人的な能力が話題を呼んでいます。このエピソードは、デジタル化された情報と人間の知覚力の可能性について、思わず考えさせられる内容です。

引用元: https://togetter.com/li/2621269



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
