---
actor_ids:
  - ずんだもん
audio_file_path: /audio/株式会社ずんだもん技術室AI放送局_podcast_20250821.mp3
audio_file_size: 0
date: 2025-08-21 05:00:00 +0900
description: 'OpenAI、AIコーディングエージェントをガイドするための「AGENTS.md」サイトを公開  gihyo.jp、Gemma3:270Mをファインチューニングして使ってみた、RAGでLLMの内部パラメータを活用する方法、「ねんどろいど ずんだもん」に使える限定の表情パーツ6種が「ねんどろいどフェイスメーカー」でセット販売中！  電撃ホビーウェブ'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20250821
---

## 関連リンク


- [OpenAI、AIコーディングエージェントをガイドするための「AGENTS.md」サイトを公開  gihyo.jp](https://gihyo.jp/article/2025/08/agents-md-site)  


OpenAIが、AIコーディングエージェントがより効率的に開発作業を行うための新しいガイドライン「AGENTS.md」を発表しました。これは、AIがプロジェクトのコードを理解し、より適切にサポートするための「説明書」のようなものです。

これまでのAIコーディングアシスタントは、コードの自動生成や修正を部分的にサポートしていましたが、プロジェクト全体の構造、独自の開発ルール、あるいは特定のテスト手順といった「文脈」を自動で理解するのは難しい側面がありました。そこで「AGENTS.md」は、こうしたAIエージェントが直面する課題を解決し、人間と同じようにプロジェクトの背景を深く理解して作業できるようにすることを目的としています。

「AGENTS.md」は、ソフトウェア開発でよく使われる「README.md」ファイルのように、プロジェクトのルートディレクトリに配置されます。このファイルには、AIエージェントがそのプロジェクトで作業する際に知っておくべき重要な情報が、標準的なMarkdown形式でまとめられます。具体的には、プロジェクトの概要や目的、コードのビルド方法、テストの実行手順、守るべきコーディング規約（例：インデントのスタイル、変数名の付け方）、依存ライブラリ、セキュリティに関する注意点などが含まれます。

これにより、AIエージェントは、ただ与えられたコードを補完するだけでなく、プロジェクト特有のルールや文脈を理解し、例えば「この機能は、既存のAコンポーネントと統合する際に、Bという規約に従うべきだ」といった、より高品質で整合性の取れたコードを提案したり、バグを見つけたりすることが期待されます。複数のサブプロジェクトがあるような大きなリポジトリ（モノレポ）の場合でも、それぞれのサブプロジェクトごとに「AGENTS.md」を置くことができ、AIは作業中のファイルに最も近いガイドラインを優先して参照します。もちろん、開発者が直接AIに指示を出す（プロンプトする）ことで、このガイドラインを一時的に上書きすることも可能です。

この取り組みは、OpenAIだけでなく、OpenAI Codex、Amp、GoogleのJules、Cursor、Factory、Roo Codeといった様々なAIコーディングツール開発チームと協力して進められています。AIがますます開発現場で活躍するようになる中で、「AGENTS.md」のような共通のガイドラインは、AIと人間のエンジニアがスムーズに協力し、開発効率とコード品質の両方を高めるための重要な一歩となるでしょう。新人エンジニアの皆さんも、今後AIと一緒に開発を進める際には、こうした「AIに仕事を任せるための説明書」の重要性を意識しておくと、AIをより効果的に活用できるはずです。

引用元: https://gihyo.jp/article/2025/08/agents-md-site


- [Gemma3:270Mをファインチューニングして使ってみた](https://zenn.dev/mixi/articles/1a6a7c1856c206)  


この記事では、Googleが新しく発表した軽量なAIモデル「Gemma 3 270M」を、実際にカスタマイズ（ファインチューニング）してみた体験が紹介されています。

**Gemma 3 270MってどんなAI？**
このモデルは、たった2億7千万パラメータという小さなサイズながら、とても効率的に動作するのが特徴です。一番のポイントは、開発者が自分の目的に合わせて簡単にカスタマイズできるように作られていること。すでに指示を理解したり、文章を整理したりする能力が備わっているので、基本的な訓練をせずともすぐに実用的な場面で活用できます。つまり、「軽くて速いのに、必要な基本機能は揃っていて、しかも自分好みにカスタマイズしやすいAIモデル」なんです。

**実際にファインチューニングに挑戦！**
筆者はこのGemma 3 270Mを「関西弁を話すAI」にカスタマイズすることに挑戦しました。
1.  **データセットの準備:** まず、AIに学習させるための関西弁の会話データを用意しました。
2.  **フルチューニング:** 用意したデータを使って、モデル全体を再学習させる「フルチューニング」を行いました。プログラムはAIアシスタントのClaudeの力を借りて作成。わずか数分で、質問に対して関西弁で返答するモデルが完成したそうです。

**もっと効率的なカスタマイズ：LoRA**
次に、より少ない計算資源で効率的にAIをカスタマイズできる「LoRA（Low-Rank Adaptation）」という手法も試されました。LoRAは、AIモデルの全パラメータを学習し直す代わりに、ごく一部の新しいパラメータだけを学習させることで、メモリ使用量を大幅に減らしつつ、高い性能を維持できるのが特長です。
LoRAを使っても、同様に関西弁モデルの作成に成功し、フルチューニングの場合よりも自然な回答が得られたと報告されています。

**まとめ**
Gemma 3 270Mは、その軽さから必要とするコンピュータの性能が低く、高速に動くことが確認されました。そして、記事の通り、本当に簡単にカスタマイズできるモデルだと感じたそうです。新人エンジニアの皆さんも、このモデルを使えば、普段の業務やちょっとした個人的なタスクを、自分だけのAIで効率化できるかもしれませんね。

**利用上の注意点**
外部のデータセットを利用する際は、不適切な内容が含まれていないか、事前にしっかり確認することが大切です。今回紹介されたプログラムは、学習・検証目的での利用が想定されています。

引用元: https://zenn.dev/mixi/articles/1a6a7c1856c206


- [RAGでLLMの内部パラメータを活用する方法](https://zenn.dev/knowledgesense/articles/0712abdd04a4f6)  


LLM（大規模言語モデル）を使ったシステムで、外部の情報を参照して回答を生成するRAG（Retrieval-Augmented Generation）という技術が注目されています。RAGでは、LLMが答えた情報が「どの情報源から来たのか」を示す「出典（しゅってん）」を明記することがとても大事です。なぜなら、LLMがたまに間違った情報を生成する「ハルシネーション」を防ぎ、回答の信頼性を高めるためです。

しかし、これまでのRAGの出典特定方法には課題がありました。多くの場合、LLMが文章をすべて出力し終えてから、その文章がどの情報源と関連するかを後から判断していました。この方法だと、LLMが文章を作りながら内部で考えている情報（潜在意識のようなもの）を活かせず、正確な出典特定が難しいという問題がありました。

この課題を解決するのが、今回紹介されている新しい手法「LoDIT（ロディット）」です。LoDITは、LLMが文章を生成している「途中」の情報を活用して、どの情報源を参照しているかをリアルタイムに判断します。

具体的には、LLMが次にどの単語（「トークン」と呼びます）を出すかを確率で予測している、その「トークンの出力確率」という内部情報を使います。LLMは例えば「私の名前」の次に「は」を出す確率が60%、「で」を出す確率が20%…といったように、次のトークンごとに確率を計算しています。

LoDITでは、各情報源（例えば資料A、資料Bなど）にそれぞれ「AA」や「BB」といった、普段使われない短いトークンを割り当てておきます。LLMが文章を生成する際、一つ一つのトークンが出力されるたびに、これらの割り当てられたトークン「AA」や「BB」が出力される確率も同時に記録します。そして、生成された文章全体で、どの情報源のトークン（「AA」や「BB」など）の出力確率が高かったかを総合的に判断することで、「この文章は情報源Aを参照したな」というように、LLMが実際に参照していた情報源を特定します。

このLoDITを用いることで、既存の手法と比較して、LLMがどの情報源を元に回答したかをより正確に特定できるようになります。論文の評価では、既存手法よりも最大で約1割も精度が向上したことが報告されています。特に、トークンが元々持つ出力の偏りを取り除く「debiasing」という仕組みが、精度向上に大きく貢献しているとのことです。

LoDITは、LLMの「次に何を話すか」を予測する際の内部的な情報をうまく活用することで、RAGの信頼性を高める画期的なアプローチです。このように、LLMの潜在的な情報から「+α」の価値を引き出す技術は、今後のAI開発においてますます重要になるでしょう。RAGの出力の信頼性を高めたい場面で、ぜひ活用を検討してみてください。

引用元: https://zenn.dev/knowledgesense/articles/0712abdd04a4f6


- [「ねんどろいど ずんだもん」に使える限定の表情パーツ6種が「ねんどろいどフェイスメーカー」でセット販売中！  電撃ホビーウェブ](https://hobby.dengeki.com/news/2711194/)  


電撃ホビーウェブによると、「ねんどろいど ずんだもん」に使える限定の表情パーツ6種が「ねんどろいどフェイスメーカー」でセット販売中です。これは「ずんだ餅の日」に合わせた特別コラボで、2025年8月19日から10月30日までの期間限定。すでに予約中の「ねんどろいど ずんだもん」をさらに楽しむためのアイテムで、カスタマイズ済みのセットを2個から注文できます。本体は別売りなので注意が必要ですが、ずんだもんファンには嬉しいニュースですね。

引用元: https://hobby.dengeki.com/news/2711194/



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
