---
actor_ids:
  - お嬢様ずんだもん
audio_file_path: https://storage.googleapis.com/podcast-zund-arm-on-tech/audio/私立ずんだもん女学園放送部_podcast_20250530.mp3
audio_file_size: 0
date: 2025-05-30 05:00:00 +0900
description: 'AIエージェントで並列実装なら必須技術！ Git Worktree を理解する、Coding Agentをこれから導入するならClaude Code Actionが個人的におすすめ、RAG(検索拡張生成)を用いるLLMアプリにおける、セキュリティ視点での実装ガイドライン、NTTからサイバー攻撃に対するセミナーの案内がきたが、自分がいま取り組んでるのは、「アライグマから光ファイバーをどう守るか？」 物理攻撃には、めっぽう弱いのIT化社会'
duration: "00:00"
layout: article
title: 私立ずんだもん女学園放送部 podcast 20250530
image_url: https://zund-arm-on.com/images/ojousama_zundamon_square.jpg
thumbnail_url: https://zund-arm-on.com/images/ojousama_zundamon_thumbnail.jpg
---

## 関連リンク


- [AIエージェントで並列実装なら必須技術！ Git Worktree を理解する](https://zenn.dev/siu_issiki/articles/git_worktree)  


最近はClaude CodeやGitHub CopilotなどのAIツールを使って開発する機会が増えてきましたね。これらのAIは複数の作業を同時に進めるのが得意ですが、私たちエンジニアが使うGitのやり方には、少し困ったところがあります。

従来のGitでは、別の作業（例えば、新しい機能開発中に緊急のバグ修正が入るなど）を始めるたびに、今やっている作業を一時的に保存して、ブランチという作業場所を切り替える必要がありました。これが結構面倒で、作業が中断されたり、開発環境を再準備する必要があったりします。特にAIエージェントに長時間作業を任せている場合、ブランチを切り替えるとAIが混乱してしまうこともあります。

そこで注目されているのが「Git Worktree」という機能です。これは、同じプロジェクトの様々なブランチを、**まるで別のプロジェクトのように**、異なるフォルダーで同時に開いて作業できるようにする機能です。例えるなら、一つの本棚（Gitリポジトリ）にある複数の本（ブランチ）を、いくつかコピーして別々の机（Worktree）に置いて、同時に読み進められるようなイメージです。

Git Worktreeを使えば、例えば一つのフォルダーでAIに大きなリファクタリング作業を任せている間に、別のフォルダーで自分自身が別のバグ修正を進める、といった並列作業がスムーズにできます。それぞれの作業場所は完全に分離されているので、AIの作業と自分の作業が干渉する心配もありません。

記事では、Claude Codeの公式ドキュメントでもWorktreeを使った並列作業が推奨されていることや、VS Codeという開発ツールでWorktreeの管理を簡単にする拡張機能「Git Worktree Manager」が紹介されています。

Git Worktreeは、AIエージェントを活用した並列開発を進める上で、とても便利な技術です。これまでのGitのやり方では難しかったマルチタスク開発が、Worktreeを使うことで効率的に行えるようになるでしょう。ぜひ試してみてください。

引用元: https://zenn.dev/siu_issiki/articles/git_worktree


- [Coding Agentをこれから導入するならClaude Code Actionが個人的におすすめ](https://zenn.dev/aeonpeople/articles/1ec37f3ae91995)  


この記事は、イオンネクストで技術戦略を担当されている筆者が、GitHub上で動くAIコーディングアシスタント「Claude Code Action（Vertex AI版）」を使ってみた感想や導入方法のポイント、他のAIツールとの比較を紹介しています。

なぜエンタープライズ（企業での利用）でGoogle Cloud (Vertex AI) がおすすめかというと、既存のクラウド環境にAIツールの費用を混ぜ込めるため、新しいツール導入の手間やハードルが下がるからです。アカウント管理も既存の仕組みに乗れるので楽だとしています。Vertex AIでは、GeminiやClaudeだけでなく、NotebookLM Enterpriseなど評判の良いAIツールを導入しやすい点もメリットに挙げています。

Claude Code Actionは、GitHubワークフローに組み込むことで、自動コードレビューやPR（プルリクエスト）管理、課題分類などがAIでできるようになる機能です。Anthropicが提供しており、AIモデルとしてAWS BedrockやGoogle Cloud Vertex AIを利用できます。

Vertex AIでClaude Code Actionを使うための設定手順は、基本的に公式ドキュメント通りでOKですが、いくつかの修正点があったそうです。例えば、GitHub ActionsのYamlファイルで参照するアクションのパスや、AIモデルの指定方法などに変更が必要だった点を共有しています。

他のCoding Agentとして、GitHub Copilot Coding AgentやDevinと比較したところ、それぞれ違いが見られました。
GitHub Copilot Coding Agentは、すぐにDraft PRを作成し、実行計画もPRの説明として詳細に示され、コードも正常に動作したそうです。READMEやヘルパースクリプトも自動で追加されるなど、気が利いている印象だったとのこと。
一方、Claude Code Actionは、Issueへのコメントを起点に実行計画を立て、ユーザーがPRを作成する流れでした。試した際のコードはAPIエラーで動きませんでした。
Devinは、PRは作成しましたが、基本的な機能テストを実施済みと記載されているものの実際はテストしておらず、作成されたコードも引数に問題があり動きませんでした。ただし、普段のDevinの品質は良い印象とのことです。

PRレビューツールとしては、Copilot Code ReviewとClaude Code Action（レビュー用にプロンプト調整）を比較しました。
Copilot Code Reviewは、通常のPRレビューのように該当行へのコメントやSuggested change（修正案）を出してくれる点で使いやすいと感じたそうです。
Claude Code Actionは、プロンプト次第ですが、どのコードへの指摘か視覚的に分かりづらい場合があったものの、指摘内容自体はCopilotと同様の箇所を捉えていました。

まとめとして、Claude Code Actionは他のツールと比較しても実用的な品質であり、プロンプトの調整やナレッジの蓄積でさらに精度が向上する可能性を述べています。エージェント型AIの導入コストにハードルを感じる企業は、まずはClaude Code ActionとVertex AI/Bedrockの組み合わせで試してみるのが良い選択肢となり得ると提案しています。ただし、Vertex AIは従量課金のため、コスト管理は必要です。

引用元: https://zenn.dev/aeonpeople/articles/1ec37f3ae91995


- [RAG(検索拡張生成)を用いるLLMアプリにおける、セキュリティ視点での実装ガイドライン](https://blog.flatt.tech/entry/rag_security)  


LLM（大規模言語モデル）は進化していますが、最新情報や固有の知識には弱点があります。この課題を解決する技術が**RAG（検索拡張生成）**です。RAGは、あらかじめ用意した資料（知識ベース）の中から、ユーザーの質問に関連する部分を検索し、その情報をLLMに与えることで、より適切で正確な回答を引き出します。

RAGアプリを開発する際、その便利さからセキュリティが後回しになりがちですが、いくつかの重要なリスクが存在します。この記事では、特にRAG特有のリスクと対策に焦点を当てて解説しています。

RAGアプリのセキュリティリスクはいくつかありますが、特に気をつけたいのは以下の点です。
1.  **データ汚染:** 知識ベースに攻撃者が悪意のある情報を混ぜ込むリスクです。これにより、LLMが間違った情報や有害な情報を回答してしまう可能性があります。これは「Data Poisoning」とも呼ばれ、多くのユーザーに影響するため深刻です。
2.  **機密情報の漏洩:** 知識ベースに会社の非公開情報などがある場合、アクセス権限が正しく設定されていないと、本来その情報を見られないはずのユーザーが見てしまうリスクです。特に複数の会社やユーザーで共有するシステム（マルチテナント）では、他のユーザーのデータが見えないようにする「認可制御」が非常に重要になります。
3.  **過剰な課金:** LLMの利用料金は、処理するテキスト量（トークン数）によって決まることが多いです。攻撃者が大量のリクエストを送るなどして、意図的に料金を増やしてしまうリスクがあります。RAGは知識ベースの情報もLLMに渡すため、通常よりもトークン数が多くなりやすく、このリスクに注意が必要です。

これらのリスクのうち、特にRAGで重要な役割を果たす**Vector store**（知識ベースをベクトル形式で保存・検索するデータベース）に関連するデータ汚染とデータ漏洩について詳しく解説されています。

Vector storeの「データ汚染」を防ぐには、知識ベースに入れるデータの信頼性を確認することが基本です。外部からデータを取り込む場合は、信頼できる情報源かを確認したり、データの種類でフィルタリングしたりといった対策が有効です。

Vector storeからの「データ漏洩」を防ぐには、先ほどの「認可制御」が鍵となります。マルチテナント環境では、ユーザーごとにアクセスできるデータを厳密に分ける必要があります。この認可制御の実装方法は、利用するVector storeのライブラリによって異なります。ライブラリによっては、マルチテナントに対応した機能が備わっているものや、データを区別するための情報を付けて検索時に絞り込む方法（metadata filtering）で対応できるものがあります。metadata filteringを使う際は、悪意のある入力を防ぐための対策（サニタイズなど）をしっかり行う必要があります。独自の認可制御を実装するとミスが発生しやすいため、可能な限りライブラリの機能を利用するか、専門家のレビューを受けることが推奨されます。

RAGアプリ開発では、その機能性だけでなく、データ汚染や情報漏洩といったセキュリティリスクを理解し、適切な対策を講じることが、安全なシステムを構築するために不可欠です。

引用元: https://blog.flatt.tech/entry/rag_security


- [NTTからサイバー攻撃に対するセミナーの案内がきたが、自分がいま取り組んでるのは、「アライグマから光ファイバーをどう守るか？」 物理攻撃には、めっぽう弱いのIT化社会](https://togetter.com/li/2556533)  


NTTからサイバー攻撃セミナーの案内が来たものの、現場では「アライグマから光ファイバーケーブルを守る」という物理的な課題に取り組んでいるツイートが話題に。ITインフラはサイバー攻撃だけでなく、動物による物理的な被害対策も意外と重要であることをユーモラスに伝えています。過去にはセミやリスの対策もあり、システムの安定稼働には様々な視点が必要だと分かりますね。

引用元: https://togetter.com/li/2556533



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

VOICEVOX:ずんだもん
