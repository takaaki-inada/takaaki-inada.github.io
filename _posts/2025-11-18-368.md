---
actor_ids:
  - ずんだもん
audio_file_path: /audio/株式会社ずんだもん技術室AI放送局_podcast_20251118.mp3
audio_file_size: 0
date: 2025-11-18 05:00:00 +0900
description: 'Agents 2.0: From Shallow Loops to Deep Agents、Claude Code on the Web を超える!? Codex Cloud の実践テク5選、自宅のRTX3060で小さなLLMを自作してみた、「得点が無限1UPみたいに増えてゆくんですけれども」高専ロボコンで優勝した旭川高専のとった戦法が話題に「合理的すぎて好き」「こういう発想大好き」'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20251118
---

## youtube版(スライド付き)

<div class="article-video"><iframe src="https://www.youtube.com/embed/nJxH9-XvW38" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></div>


## 関連リンク


- [Agents 2.0: From Shallow Loops to Deep Agents](https://www.philschmid.de/agents-2.0-deep-agents)  


AIエージェントは、近年非常に注目されている技術です。これまで主流だった「Agent 1.0（シャローエージェント）」は、AIモデルがユーザーの指示を受けてツールを使い、結果を返すというシンプルな仕組みで動いていました。例えば、「東京の天気は？」といった簡単な質問には素早く答えられます。

しかし、「10社の競合を調査して、比較表を作り、戦略レポートをまとめる」といった、何十ものステップが必要で数日かかるような複雑なタスクになると、Agent 1.0には限界がありました。AIモデルの一時的な記憶（コンテキストウィンドウ）がすぐにいっぱいになり、これまでの会話履歴や指示が消えてしまったり、本来の目標を見失ったり、間違った方向に進んで戻れなくなったりすることが多々ありました。まるで、一度にたくさんのことを覚えられない新人さんのように、情報過多で混乱してしまっていたのです。

この課題を解決するために登場したのが、「Deep Agents（Agent 2.0）」という新しい考え方です。Deep Agentsは、単に反応するだけでなく、より能動的に問題を解決するためのアーキテクチャを持っています。その鍵となるのが、以下の4つの柱です。

1.  **明示的な計画 (Explicit Planning)**: AIエージェントが漠然と考えるのではなく、まるでToDoリストを作るように具体的な計画を立て、実行します。途中で何かに失敗しても、計画を見直して修正することで、タスク全体を見失わずに進められます。
2.  **階層的な役割分担（サブエージェント） (Hierarchical Delegation)**: 複雑なタスクを、一つのエージェントが全てこなすのではなく、「司令塔」となるエージェントが、「調査担当」や「プログラミング担当」といった専門の「サブエージェント」に仕事を割り振ります。各サブエージェントは自分の専門分野に集中し、その結果だけを司令塔に報告することで、効率よく役割分担ができます。
3.  **永続的な記憶 (Persistent Memory)**: AIモデルの一時的な記憶だけに頼らず、ファイルやデータベースといった外部の記憶装置に中間結果や重要な情報を保存します。これにより、必要な情報をいつでも取り出せるようになり、記憶の限界を突破します。
4.  **詳細な指示（コンテキストエンジニアリング） (Extreme Context Engineering)**: AIモデルが賢くなったからといって、簡単な指示だけで動くわけではありません。「いつ計画を立てるか」「どんな時にサブエージェントに仕事を任せるか」「ツールの使い方」など、非常に具体的で詳細な指示をAIモデルに与えることで、複雑な行動を精密にコントロールします。

Deep Agentsは、これらの工夫を通じて、AIエージェントが数秒で終わるタスクだけでなく、数時間や数日かかるような、より大規模で複雑な問題にも挑戦できるようになることを目指しています。これは、AIモデル自体の性能向上だけでなく、そのモデルをいかに効果的に設計し、活用するかの「エンジニアリング」の重要性を示唆しています。AIエージェントは、ただの「反応するプログラム」から「能動的に問題を解決するパートナー」へと進化していると言えるでしょう。

引用元: https://www.philschmid.de/agents-2.0-deep-agents


- [Claude Code on the Web を超える!? Codex Cloud の実践テク5選](https://zenn.dev/sunagaku/articles/codex-cloud-5-tips)  


Web上で動くAIエージェントは、自分のパソコン環境（ローカル環境）と完全に分かれているため、とても便利ですが、使う上での制約もあります。例えば、「どうやって開発を進めるかの計画が立てにくい」「AIが作った設計書の確認が難しい」「ローカル環境との連携がスムーズにいかない」といった悩みを持つエンジニアもいるかもしれません。

この記事では、OpenAIが開発したクラウドベースのAIコーディングエージェント「Codex Cloud」を使うことで、これらの悩みを解決し、効率的に開発を進める実践的な方法が紹介されています。高機能なWeb上のAIエージェント「Devin」は月額500ドルかかる場合がありますが、Codex CloudはChatGPTの有料プランがあれば利用できるため、手軽に始められるのが大きな魅力です。

Codex Cloudは、インターネット上の安全な隔離された環境で動作し、開発を始める前に「実装計画書」を作成してくれる「Planモード」があります。デフォルトでは大まかな計画ですが、後述のテクニックで精度を高められます。

ここからは、Codex Cloudをさらに使いこなすための5つの実践テクニックを紹介します。新人エンジニアの方も、ぜひ活用してみてください。

1.  **カスタム指示を設定する**: デフォルトでは英語出力になったり、計画書が簡素だったりする問題を、カスタム指示（AIへの具体的な指示）を設定することで解消できます。日本語で回答させたり、計画書の精度を上げたりと、自分好みにカスタマイズすることで、開発体験が格段に向上します。
2.  **同時並行モードを活用する**: このモードを使うと、同じタスクに対して複数のAIを並行して動かし、異なるアプローチや解決策を同時に生成・比較できます。例えば、最初の段階で4つの異なる大まかな方向性を検討し、その中から最適なものを選んで、さらに詳細な実装パターンを並行して検討するといった使い方ができます。ただし、多くの情報処理（Token消費）が必要になるため、使い過ぎには注意が必要です。
3.  **Local上で変更差分をすぐに取り入れる**: Codex Cloudで作成・変更されたファイルを、素早く自分のローカル環境に取り込む機能があります。「git apply をコピーする」ボタンを使えば、プルリクエスト（PR）を作成する手間なく、変更を適用できるため、開発の連携がスムーズになります。
4.  **Plan作成と実装を分ける**: Planモードで作成された実装計画を、すぐに「タスクを開始」ボタンで実行するのは、場合によっては避けた方が良いとされています。特に複数のタスクがある場合、それぞれが個別の変更として扱われ、一つのPRにまとめにくくなるためです。計画をしっかり立ててから、新しいスレッドでまとめて実装を依頼する方が、変更管理がしやすくなります。
5.  **機能要件を整理した上で、並行開発を行う**: AIに良いアウトプットを出してもらうためには、事前に「何を作りたいのか」という機能要件を明確に整理することが非常に重要です。要件が曖昧なまま並行開発を行っても、質の低い結果しか得られません。まず一つのスレッドで必要な要件をしっかり整理し、その上で新しいスレッドで並行開発を行うことで、各実装の精度が高まり、比較検討もしやすくなります。

これらの実践テクニックを活用することで、Codex CloudはWeb上での開発をより効率的かつ高精度に進める強力なツールになります。ぜひ、これらの方法を試して、日々の開発に役立ててみてください。

引用元: https://zenn.dev/sunagaku/articles/codex-cloud-5-tips


- [自宅のRTX3060で小さなLLMを自作してみた](https://zenn.dev/nwn/articles/8f1d2521284738)  


この記事では、個人所有のPC（NVIDIA GeForce RTX3060）を使って、独自の小規模な大規模言語モデル（LLM）を開発し、事前学習を行った事例が紹介されています。新人エンジニアの方でも「自分のPCでどこまでできるんだろう？」という疑問へのヒントになるでしょう。

まず、LLMの学習データとして、前処理済みの「青空文庫」データセットから、現代の日本語に当たる「新字新仮名」に絞り込んだ約1万件の作品が利用されました。これにより、日本語の古典的な表現ではなく、より身近な現代日本語のテキストを学習させることが目的です。

次に、このデータセットに特化した「トークナイザー」を自作しています。トークナイザーは、文章をLLMが理解できる「トークン」という単位に分割する役割を担います。一般的なトークナイザーではなく、青空文庫の日本語表現に最適化するため、「SentencePiece」を使って32,000語彙のunigramモデルを構築。日本語特有の語尾などを細かく分割できるよう工夫し、「となって」「集まっている」といった表現が適切にトークン化できることを確認しています。

モデルのアーキテクチャは、GPT-2をベースに、RTX3060のVRAM（12GB）に収まるよう、パラメータ数を42.1M（4210万）に抑えた小型版を設計しました。具体的には、モデルの層数や埋め込み次元を調整し、学習効率とVRAM消費のバランスを取っています。少ないリソースで学習を安定させるため、バッチサイズを小さくしつつ「勾配蓄積」の技術を使ったり、混合精度学習（fp16）を導入したりと、様々な工夫が凝らされました。

結果として、約1時間45分の学習で、LLMは「人生とは」「愛とは」「神とは」といった抽象的な問いに対し、青空文庫で学習した内容に基づいた、それらしい文章を生成できるようになりました。参加したイベントでは、他の大規模モデルと比較して小型ながら、その出力の面白さが評価されたとのことです。

記事の最後に、今回自作されたトークナイザーとモデルがHugging Faceに公開されており、Google Colabを使って実際に試せる環境が提供されています。自宅のPCでLLMを開発し、その成果を公開するまでの具体的なステップが示されており、LLM開発に興味のあるエンジニアにとって、大変参考になる事例と言えるでしょう。

引用元: https://zenn.dev/nwn/articles/8f1d2521284738


- [「得点が無限1UPみたいに増えてゆくんですけれども」高専ロボコンで優勝した旭川高専のとった戦法が話題に「合理的すぎて好き」「こういう発想大好き」](https://togetter.com/li/2628947)  


高専ロボコンで旭川高専が、ユニークな戦略で優勝し話題になっています。彼らは、ゲートを高く積む従来の戦法に加え、同じゲートを何度も通過すると得られるボーナス点に着目。これを繰り返し稼ぐ「無限1UP」のような戦法で、大量得点を実現しました。ルールを深く読み解く発想力と、それを正確に実行する技術力の両方が評価されており、多くのエンジニアの心を掴んでいます。

引用元: https://togetter.com/li/2628947



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
