---
actor_ids:
  - お嬢様ずんだもん
audio_file_path: /audio/私立ずんだもん女学園放送部_podcast_20251128.mp3
audio_file_size: 0
date: 2025-11-28 05:00:00 +0900
description: 'GitHub Copilot カスタムエージェントのための agents.md 作成ベストプラクティス、Programmatic Tool Calling(PTC)の何が新しいのか？、vLLM+Structured Outputを使ったテキストのラベリング高速化  Wantedly Engineer Blog、生成AIが発達してくる未来で俺が危惧してること「ドラレコの映像、証拠にならなくなるのでは…？」'
duration: "00:00"
layout: article
title: 私立ずんだもん女学園放送部 podcast 20251128
image_url: https://zund-arm-on.com/images/ojousama_zundamon_square.jpg
thumbnail_url: https://zund-arm-on.com/images/ojousama_zundamon_thumbnail.jpg
---

## youtube版(スライド付き)

<div class="article-video"><iframe src="https://www.youtube.com/embed/36sb25QhsxY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></div>


## 関連リンク


- [GitHub Copilot カスタムエージェントのための agents.md 作成ベストプラクティス](https://zenn.dev/studypocket/articles/github-copilot-agents-md-best-practices)  


GitHub Copilotの新しい「カスタムエージェント」機能をご存じでしょうか？これは、AIアシスタントに特定の役割や専門知識を与え、開発を効率化するものです。本記事は、このカスタムエージェントの設定ファイル「`agents.md`」の効果的な作り方を、新人エンジニアにも分かりやすく解説します。GitHubが2,500以上のリポジトリを分析して得た知見が基になっています。

`agents.md`ファイルは、リポジトリの`.github/agents/`に配置し、エージェントの役割、使用ツール（`read`, `edit`, `shell`など）、プロジェクト構造、コードスタイルなどを定義します。これにより、バックエンド専門やフロントエンド専門といった、特化したエージェントチームを構築できます。

効果的な`agents.md`には、以下の6つの要素が重要です。

1.  **コマンド**: エージェントが実行する具体的なコマンドを明確に書きます。
2.  **テスト**: 使用するテストフレームワークやテストの実行方法を具体的に指定します。
3.  **プロジェクト構造**: ディレクトリ構成とその役割を記述し、エージェントがファイルを理解しやすくします。
4.  **コードスタイル**: 推奨されるコードの書き方と避けるべき書き方を、具体的な例で示します。
5.  **Gitワークフロー**: ブランチ命名規則やコミットメッセージのフォーマットなど、開発プロセスを定義します。
6.  **境界線**: エージェントが「必ずやること」「確認が必要なこと」「絶対にやってはいけないこと」を明確にし、意図しない挙動を防ぎます。

曖昧な指示や複雑すぎる設計は、エージェントのパフォーマンスを低下させます。最初は完璧を目指さず、「最小限の設定から始め、問題があればルールを追加していく」という段階的なアプローチが推奨されます。

カスタムエージェントの大きな利点は、複数の開発タスク（Issue）に適切なエージェントをアサインし、並行して効率的に作業を進められることです。エージェントが正しく作業するためには、Issueに必要な情報（背景、要件、受け入れ条件など）がしっかり記載されていることが不可欠です。Issue作成自体もエージェントに任せることで、必要な情報が漏れなくそろい、開発の精度と効率がさらに向上するでしょう。

AIオーケストレーションを上手に活用し、皆さんの開発ライフをより豊かなものにしてください。

引用元: https://zenn.dev/studypocket/articles/github-copilot-agents-md-best-practices


- [Programmatic Tool Calling(PTC)の何が新しいのか？](https://blog.lai.so/programmatic-tool-calling/)  


Anthropicが、対話型AI「Claude」の新しいAPI機能として「Programmatic Tool Calling」（PTC）を公開しました。これは、Claudeが外部のツールを使う方法を大きく進化させる技術です。新人エンジニアの皆さんも、これからのAIエージェント開発で役立つポイントなので、ぜひ知っておきましょう。

これまでのTool Use（ツール利用）では、Claudeがツールを一つ使うたびに「次はこれをやろう」と判断し、その結果を会話の履歴（これを「コンテキスト」と呼びます）に全て記録していました。ツールをたくさん使う複雑なタスクでは、このコンテキストがどんどん長くなり、「コンテキスト肥大化」という問題が起きていました。コンテキストが長くなると、情報処理のコストが増えるだけでなく、Claudeが重要な情報を見落としたり、判断を誤ったりする「context rot（コンテキスト腐敗）」と呼ばれる精度低下の問題も発生しやすかったのです。

PTCでは、この課題を根本的に解決します。Claudeは、複数のツールを呼び出す一連の処理をまとめたPythonコードを一度に生成します。このコードは、Anthropicが用意した特別な実行環境（「サンドボックス」と呼びます）の中で動きます。重要なのは、ツールが実行されたときの中間的なデータ（例えば、大量のデータ分析結果など）は、このサンドボックスの中にだけ保持され、Claudeのコンテキストには直接戻されない点です。Claudeが受け取るのは、サンドボックスでの処理が終わった後の「最終的な結果」だけになるため、コンテキストが肥大化するのを防げます。

実際に検証した結果、従来のTool Use方式と比較して、PTCを使うことで、Claudeに与える入力情報量（トークン）を約74%も削減できました。さらに、全体の処理時間も約24%短縮される効果が確認されています。これにより、より長く、より複雑なタスクでも、Claudeが効率的かつ正確にツールを使いこなせるようになります。

このPTCは、直接APIを使ってAIエージェントを開発するエンジニアにとっては、コンテキスト管理という核心的な問題を解決するための強力な技術となります。皆さんが将来、より賢く、より効率的に動くAIエージェントを開発する上で、このPTCのような技術は不可欠な要素となるでしょう。

引用元: https://blog.lai.so/programmatic-tool-calling/


- [vLLM+Structured Outputを使ったテキストのラベリング高速化  Wantedly Engineer Blog](https://www.wantedly.com/companies/wantedly/post_articles/1021372)  


本記事は、自然な文章で書かれた大量のテキストデータに、AI（大規模言語モデル、LLM）を使って効率的に「タグ付け（ラベリング）」を行う方法と、その処理を高速化する技術について解説しています。

私たちの周りにはたくさんのテキストデータがありますが、そのままでは扱いにくいことが多いです。そこで、文章の内容を意味ごとに整理し、適切なラベルを付ける「テキストラベリング」が重要になります。しかし、この作業は人間が手作業で行うと非常に大変ですし、自動化しようにも言葉の揺れなどで難しい側面がありました。

最近ではChatGPTのようなLLMが登場したおかげで、比較的簡単にテキストラベリングができるようになりました。LLMを使うと、どのような基準でラベルを付けるかを「プロンプト（指示文）」で伝えるだけで、柔軟にラベリング作業をコントロールできます。
さらに、自分のコンピュータ環境でLLMを動かす「ローカルLLM」を利用すれば、機密データを外部に出すことなくAIを活用できたり、APIの利用回数制限を気にせずに大量のデータを処理できたりするメリットがあります。

しかし、たくさんのテキストを一度にラベリングしようとすると、処理に時間がかかってしまうのが課題です。そこで、この記事では「vLLM」というライブラリを使って、ローカルLLMが答えを出す処理（推論）を大幅に速める方法を紹介しています。

また、ラベル付けでは、単に「AかBか」だけでなく、「有害かどうか」「もし有害なら、どんな種類の有害性か」といった、より複雑で「構造化されたラベル」が必要になることがあります。このニーズに応えるのが「Structured Output（構造化出力）」という機能です。これは、`outlines`や`vLLM`といったライブラリを使うことで実現でき、事前に定義した形式（例えば、Pydanticというライブラリで作成するデータ型）に合わせてLLMが出力してくれるため、結果がとてもきれいに整理されます。

実際に実験として、日本語の有害テキストをラベリングするタスクで、vLLMとStructured Outputの機能を組み合わせて使用しました。その結果、従来のStructured Outputのみで推論するよりも、約6.5倍も高速にラベリングできることが分かりました。

まとめると、クラウドのLLMサービスが使えない状況でも、ローカルLLMに「vLLM」を導入し、「Structured Output」を組み合わせることで、複雑な構造を持つラベルを非常に速く生成できる、という具体的な技術応用事例です。新人エンジニアの皆さんにとって、LLMを実際のサービスに組み込む際のパフォーマンス向上や、精度を高めるためのヒントになること間違いなしです。

引用元: https://www.wantedly.com/companies/wantedly/post_articles/1021372


- [生成AIが発達してくる未来で俺が危惧してること「ドラレコの映像、証拠にならなくなるのでは…？」](https://togetter.com/li/2632693)  


生成AIの進化で、ドラレコ映像が改ざんされ事故の証拠にならなくなるのでは、という懸念が議論されています。過去の映像改ざん事例やデジタルデータの信憑性の問題が指摘される一方で、複数のカメラでの検証、時刻認証技術、改ざん防止機能付きドラレコ、GPSデータ記録など、信頼性を保つための技術や対策も挙がっています。AIが進化する中で、デジタルデータの証拠能力をどう担保していくか、今後の社会で考えるべき大切な課題です。

引用元: https://togetter.com/li/2632693



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

VOICEVOX:ずんだもん
