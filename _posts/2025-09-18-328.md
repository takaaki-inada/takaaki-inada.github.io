---
actor_ids:
  - ずんだもん
audio_file_path: /audio/株式会社ずんだもん技術室AI放送局_podcast_20250918.mp3
audio_file_size: 0
date: 2025-09-18 05:00:00 +0900
description: 'An Introduction to Speculative Decoding for Reducing Latency in AI Inference、Making LLMs more accurate by using all of their layers、Gemini achieves gold-level performance at the International Collegiate Programming Contest World Finals、パソコンケース内に「踊るずんだもん」を住まわせてみた！ 空きスペースに回転LEDを組み込んで盆踊りするずんだもんを投影'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20250918
information: 告知が遅くなってしまったけど、9月19日までyoutube版の放送を試験配信中なのだ！音声読み上げだけだとなかなか頭に入ってこないから、テキストも表示しながら聞くとより頭に入ってくるのだ！番組ホームページにリンクがあるので、興味のある人は見てほしいのだ。感想きかせてくれると嬉しいのだ。
---

## youtube版(スライド付き)

<iframe width="560" height="315" src="https://www.youtube.com/embed/NLX7DSZe7Gs?si=Cyoo-2co5DOzJ06p" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

※youtube版は9/19まで試験配信中

## 関連リンク


- [An Introduction to Speculative Decoding for Reducing Latency in AI Inference](https://developer.nvidia.com/blog/an-introduction-to-speculative-decoding-for-reducing-latency-in-ai-inference/)  


LLM（大規模言語モデル）が文章を生成する際、現状では「単語や文字の最小単位であるトークンを一つずつ順に生成する」という方法がとられています。この「逐次生成」の仕組みが、AIの応答速度（レイテンシ）を遅くしたり、高性能なGPUの計算能力を十分に活用できなかったりする原因となっていました。

この課題を解決するために登場したのが、「投機的デコーディング（Speculative Decoding）」という技術です。これは、大規模で高精度な「ターゲットモデル（主任科学者）」と、小さくて高速な「ドラフト機構（有能なアシスタント）」が協力して作業を進めるイメージです。アシスタントが次のトークン候補を素早く複数予測し、主任科学者はそれらの候補をまとめて一度に検証します。これにより、従来の「一つずつ生成・検証」のプロセスを大幅に短縮し、一度の処理で複数のトークンを生成できるようになります。結果として、AIの応答速度が向上し、GPUの利用効率も高まります。そして最も重要なのは、生成される文章の品質は、ターゲットモデルが単独で生成した場合と全く同じであることが保証される点です。

投機的デコーディングには主に二つのアプローチがあります。
一つは「ドラフト・ターゲットアプローチ」です。これは、メインとなる大規模なターゲットモデルと、小型で高速なドラフトモデルの二つのAIモデルを使用します。ドラフトモデルが次のトークンの候補を素早く生成し、ターゲットモデルがそれらをまとめて検証します。ターゲットモデルが正しいと判断した候補は採用し、予測が外れた部分についてはターゲットモデル自身が正しいトークンを生成し直すことで、生成物の精度を保ちます。

もう一つは、NVIDIAが推進する「EAGLE（Extrapolation Algorithm for Greater Language-Model Efficiency）」アプローチです。この方法では、別途ドラフトモデルを用意する代わりに、ターゲットモデル自身の内部情報（隠れた特徴量）を利用し、軽量な「EAGLEヘッド」という部品が次のトークン候補を予測します。特に最新の「EAGLE-3」では、ターゲットモデルの複数の層から情報を活用し、「予測の木」のように様々な候補を同時に試し、効率的に検証することで、さらに高速化を図ります。このアプローチの利点は、余分なドラフトモデルを動かす手間が省けることです。

この技術は、LLMの応答速度に劇的な改善をもたらします。従来のLLMが「一言ずつ」文章を生成するのを待つ必要があったのに対し、投機的デコーディングを使うと「まとまった言葉の塊」が一瞬で表示されるようになります。チャットボットのような対話型アプリケーションでは、この応答速度の向上により、よりスムーズで自然な会話体験が得られます。

NVIDIAのTensorRT-Model Optimizer APIのようなツールを使えば、これらの投機的デコーディング技術を既存のLLMに簡単に組み込むことができます。投機的デコーディングは、LLMをより高速かつ効率的に動かすための重要な技術であり、今後のAI開発においてその中心的な役割はますます大きくなるでしょう。

引用元: https://developer.nvidia.com/blog/an-introduction-to-speculative-decoding-for-reducing-latency-in-ai-inference/


- [Making LLMs more accurate by using all of their layers](https://research.google/blog/making-llms-more-accurate-by-using-all-of-their-layers/)  


大規模言語モデル（LLM）は目覚ましい発展を遂げていますが、時には事実に基づかない情報を自信満々に生成する「ハルシネーション（幻覚）」という問題に直面します。これは、LLMの実用性を大きく損ねる要因です。これまでの対策として、外部データを参照するRAG（Retrieval Augmented Generation）などがありますが、システムが複雑になる上に、完全にハルシネーションを防ぐことは難しいのが現状です。

このような課題に対し、Googleの研究チームは、NeurIPS 2024で「Self Logits Evolution Decoding (SLED)」という新しいデコーディング手法を発表しました。SLEDは、外部の知識ベースや追加のファインチューニング（追加学習）を必要とせず、LLMのハルシネーションを減らし、事実認識精度を向上させることを目指しています。

SLEDの核となる仕組みは、LLMがテキストを生成する際の「全ての層」からの情報を活用することです。LLMは文章を「トークン」（単語や記号の最小単位）に分解し、次のトークンを一つずつ予測しながら文章を生成します。通常、この予測にはLLMの最も深い（最後の）層が出力する情報だけが使われます。しかし、SLEDは途中の層（中間層）で得られる予測情報も重要視します。例えるなら、最終的な意思決定だけでなく、そこに至るまでの様々な段階での意見も総合的に判断するようなイメージです。SLEDは、これらの全ての層から得られる予測を賢く組み合わせることで、より正確な次のトークンを選び出し、LLMの出力を事実と合致させるように調整します。

例えば、「ブリティッシュコロンビアの首都は？」という質問で、LLMが一般的に知られている「バンクーバー」と間違えやすい場合でも、SLEDは全ての層の情報を考慮することで、正しい「ビクトリア」という答えをより高い確率で予測できます。このように、SLEDはLLMが「確信を持って間違える」ことを防ぎ、より信頼性の高い出力を実現します。

実験の結果、SLEDはGPT-OSS、Mistral、Gemmaといった様々なオープンソースLLMに適用可能であり、多肢選択問題や自由回答形式の質問など、幅広いタスクで事実認識精度を向上させることが確認されました。従来の強力なデコーディング手法と比較しても、SLEDは最大16%もの精度向上を達成しています。この性能向上の代償として、テキスト生成にかかる時間（推論時間）がわずか約4%増加しますが、これは事実認識精度の大きな改善を考慮すれば十分に許容できる範囲です。

SLEDは、外部の知識に頼らず、モデル自身の内部情報だけでLLMのハルシネーション問題を効果的に解決できる有望な技術です。他のデコーディング手法と組み合わせることも可能で、将来的には視覚応答やコード生成といった他のLLMタスクへの応用も期待されています。新人エンジニアの皆さんにとって、この技術はLLMがどのようにして「間違い」を修正し、「より賢く」なっていくのかを理解する上で、興味深い知見となるでしょう。

引用元: https://research.google/blog/making-llms-more-accurate-by-using-all-of-their-layers/


- [Gemini achieves gold-level performance at the International Collegiate Programming Contest World Finals](https://deepmind.google/discover/blog/gemini-achieves-gold-level-performance-at-the-international-collegiate-programming-contest-world-finals/)  


皆さん、AIの進化が止まりません！Google DeepMindが開発するAIモデル「Gemini 2.5 Deep Think」が、世界で最も権威ある大学レベルのプログラミング大会「国際大学対抗プログラミングコンテスト（ICPC）世界大会2025」で、なんと金メダルレベルの成績を達成しました。

ICPCは、世界中の約3000大学から参加者が集まる、非常に難易度の高いアルゴリズムプログラミング競技です。5時間という制限時間内に、複雑なアルゴリズム問題をチームで協力して解き、正確性と速さを競います。完璧な解決策だけが得点となり、人間の参加者でもトップレベルの思考力とコーディングスキルが求められます。

今回の大会で、Gemini 2.5 Deep Thinkは、人間と同じルールでリモート参加し、12問中10問を見事正解。これは、実際に参加した大学チームと比較しても全体で2位に相当する素晴らしい結果です。特筆すべきは、人間のどのチームも解決できなかった難問「Problem C」を、Geminiがわずか30分で効率的に解き切ったことです。この問題は、無限ともいえるパイプの構成の中から、水槽を最速で満たす最適な方法を見つけるという、非常に高度な抽象的推論が求められるものでした。Geminiは、優先度値と動的計画法、そして数学的なミニマックス定理を組み合わせることで、この難題を攻略したのです。

この快挙は、Gemini 2.5 Deep Thinkがわずか2ヶ月前に国際数学オリンピック（IMO）でも金メダルを獲得したことに続くもので、AIの抽象的な問題解決能力が著しく向上していることを示しています。これは、将来の汎用人工知能（AGI）実現に向けた大きな一歩と考えられています。

今回の成果は、AIが単なる情報処理ツールではなく、プログラマーの強力な「協力者」となれる可能性を強く示唆しています。Geminiが提示した独自の解決策を人間の知識と組み合わせれば、大会の全問題を完璧に解くことさえ可能だったとされています。今後は、ソフトウェア開発だけでなく、創薬やマイクロチップ設計、さらには科学研究といった幅広い分野で、AIがこれまで不可能とされてきた問題解決に貢献してくれるかもしれません。すでにGoogle AI Ultraのサブスクリプションユーザーは、Geminiアプリで軽量版のDeep Thinkを体験できます。これからのAIと人間の協業に、大いに期待しましょう！

引用元: https://deepmind.google/discover/blog/gemini-achieves-gold-level-performance-at-the-international-collegiate-programming-contest-world-finals/


- [パソコンケース内に「踊るずんだもん」を住まわせてみた！ 空きスペースに回転LEDを組み込んで盆踊りするずんだもんを投影](https://news.nifty.com/article/item/neta/12237-4501700/)  


自作PCケースの空きスペースに、高速回転LED（バーサライタ）を組み込んで「踊るずんだもん」を投影するユニークな動画が話題です。投稿者はBlenderやAdobe Mixamoを駆使し、3Dモデルのずんだもんに盆踊り風のアニメーションを付け、PC内で愉快に踊らせることに成功しました。この作品は、技術的な工夫と遊び心が融合した素晴らしい事例で、視聴者からも「このPC売れそう」と大好評。ITエンジニアが持つクリエイティビティの可能性を感じさせます。

引用元: https://news.nifty.com/article/item/neta/12237-4501700/



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
