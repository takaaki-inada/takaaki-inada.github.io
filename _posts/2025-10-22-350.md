---
actor_ids:
  - ずんだもん
audio_file_path: /audio/株式会社ずんだもん技術室AI放送局_podcast_20251022.mp3
audio_file_size: 0
date: 2025-10-22 05:00:00 +0900
description: 'やさしいClaude Skills入門、LangChain raises $125M to build the platform for agent engineering、LLMs Can Get Brain Rot、「ひかれるという感情が薄い」→北海道の車道で目撃……車をまったく気にしない野生動物　釧路では「まれによくある」光景に5.2万“いいね”'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20251022
---

## youtube版(スライド付き)

<div class="article-video"><iframe src="https://www.youtube.com/embed/kfqitxL2VLM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></div>


## 関連リンク


- [やさしいClaude Skills入門](https://www.docswell.com/s/harinezumi/5M683X-2025-10-21-003933)  


Anthropic社のAI「Claude」に、新たに「Claude Skills」という強力な機能が加わりました。これは、Claudeが特定のタスクを高品質かつ効率的に実行するための「ベストプラクティス集」のようなもので、指示やスクリプト、必要なリソースなどを一まとめにしたものです。技術的には「Agent Skills」とも呼ばれ、最近エンジニア界隈で大きな注目を集めています。

Claude Skillsの導入で嬉しいのは、AIにタスクを依頼する際の試行錯誤が減り、まるで経験豊富な先輩が手本を示すように、Claudeが最適な手順で作業を進められるようになる点です。これにより、私たちはAIの能力を最大限に引き出し、より少ない労力で高い成果を期待できるようになります。

その仕組みは、主に「SKILL.md」ファイルに記述されたスキルの概要情報（メタデータ）と、Claudeがファイルを読み込むための「Readツール」で動きます。Claudeは必要なSkillsのファイルだけを動的に読み込むため、AIが一度に扱える情報量（コンテキストウィンドウ）を無駄に消費せず、効率的な処理を実現します。これは、常にプロジェクト全体の指示を保持する「CLAUDE.md」や、ツール接続のプロトコルである「MCP」とは異なり、特定のタスクに特化した「便利機能パック」として、より具体的な作業効率化を目指しています。

Claude Skillsは、Claude Desktop、Claude API、Claude Codeなど様々な環境で利用可能です。Desktop版では設定から簡単に有効化でき、自作のSkillsもアップロードできます。API経由の場合は事前に登録が必要です。また、公式から提供されている「skill creator」というSkillsを使えば、独自のSkillsを効率的に作成できます。

効果的なSkillsを作るための「ベストプラクティス」（良いやり方）も紹介されています。特に、SKILL.mdのメタデータは常に読み込まれるため、簡潔にまとめることが重要です。また、SKILL.md自体の内容は500行以下に抑え、詳細な情報は別ファイルに分割するのが推奨されています。

具体的な活用事例としては、ウェブサービス「キミガタリ」の月間アップデートレポートを自動作成する取り組みが紹介されています。これまでは手動で行っていた定型レポート作成作業が、Claude Skillsを使うことで、現在時刻の確認から、Qiita投稿やGitコミット履歴の取得・分析、既存フォーマットへの沿った記事作成までを自動化。数秒で「まるで自分が書いたような記事」が完成するようになり、大幅な効率化が実現しました。

Claude Skillsは、ベテランエンジニアの知識やノウハウをAIに学習させ、組織における「属人化」（特定の個人にしかできない仕事）を解消する可能性を秘めています。質の高いSkillsが販売されるエコシステムの発展も期待されており、新人エンジニアの皆さんにとって、AIの活用範囲を広げる強力なツールとなるでしょう。

引用元: https://www.docswell.com/s/harinezumi/5M683X-2025-10-21-003933


- [LangChain raises $125M to build the platform for agent engineering](https://blog.langchain.com/series-b/)  


AIエージェント開発をリードするLangChainが、1.25億ドル（約180億円）の資金調達と、企業価値12.5億ドル（約1800億円）への評価を発表しました。この資金は、AIエージェントをより信頼性高く開発するための「エージェントエンジニアリング」プラットフォームの構築に充てられます。

LLM（大規模言語モデル）の登場で様々なアプリケーションが可能になりましたが、データやAPIと連携して自律的に動く「AIエージェント」こそがその真の力を引き出します。しかし、AIエージェントは試作は容易でも、本番環境で安定稼働させるのは非常に難しいという課題があります。「エージェントエンジニアリング」とは、この課題を解決し、非決定論的なLLMシステムを信頼性の高い体験へと磨き上げていく反復的なプロセスです。

LangChainはこの「エージェントエンジニアリング」のための包括的なプラットフォームを提供しています。主な発表内容は以下の通りです。

*   **LangChainとLangGraphの1.0リリース**: AIエージェントを迅速に構築できるオープンソースフレームワークが安定版となり、一般的なエージェントパターン向けのアーキテクチャが強化されました。LangGraphを使えば、エージェントの動作をより細かく制御できます。
*   **LangSmithの機能強化**: エージェントの挙動を可視化する「Observability」、生産データでテスト・評価する「Evaluation」、ワンクリックでデプロイできる「Deployment」、そしてノーコードでエージェントを構築できる「Agent Builder」（プライベートプレビュー中）が提供され、開発から運用までをトータルでサポートします。
*   **Insights Agentの導入**: LangSmithの機能として、エージェントの動作パターンを自動で分類する「Insights Agent」が追加されました。

LangChainのツール群は、AIエージェント開発のハードルを下げ、開発者が信頼性の高いエージェントをより効率的に生み出すことを支援します。AIエージェントが次の大きな波となる中で、LangChainの動向は今後も注目されそうです。

引用元: https://blog.langchain.com/series-b/


- [LLMs Can Get Brain Rot](https://llm-brain-rot.github.io/)  


この研究では、大規模言語モデル（LLM）も人間のように、低品質な情報に触れ続けることで能力が低下する「LLMブレインロット（脳の腐敗）仮説」を提唱し、その実証実験を行いました。「ブレインロット」とは、インターネット上の「つまらないけれど目を引くコンテンツ」ばかりを見ていると、人間の集中力や記憶力、判断力が鈍るという俗語から着想を得た言葉です。

研究チームは、LLMが継続的に「ジャンクデータ」に触れると、モデルの認知能力が長期的に低下するという仮説を立てました。これを検証するため、実際のTwitter/Xの投稿を基に、以下の2種類の基準で「ジャンクデータ」と「コントロールデータ（通常の高品質なデータ）」を作成しました。
1.  **M1 (エンゲージメント度)**：人気があって短い、いわゆる「バズった」投稿をジャンクデータとしました。これは、注意を引くが内容の浅い情報が、人間がSNSを延々と見てしまう現象に似ているためです。
2.  **M2 (意味的品質)**：「すごい！」「今日だけ！」のような扇情的な言葉や誇張された表現を含む投稿をジャンクデータとしました。

これらのジャンクデータをLLMに継続的に学習させたところ、驚くべき結果が明らかになりました。ジャンクデータに触れ続けたLLMは、そうでないモデルと比べて、推論能力、長文の理解力、安全性（不適切な指示への対応）が著しく低下することが判明しました。例えば、推論タスクのスコアが大幅に落ち込んだり、サイコパシーや自己愛といった「ダークな特性」を示す傾向が強まったりしました。また、ジャンクデータの割合が増えるほど、能力の低下がより顕著になるという「用量反応性」も確認されました。

エラーの原因を詳しく調べた結果、LLMが思考プロセスを途中で省略してしまう「思考スキップ」が、能力低下の主要な要因であることが分かりました。さらに懸念されるのは、一度ジャンクデータに汚染されて能力が低下したLLMは、その後、高品質なデータを使った追加学習やファインチューニングを行っても、元の能力レベルまで完全に回復することは難しいという点です。これは、モデル内部の表現に根本的な変化が生じてしまうことを示唆しています。

この研究は、LLMの学習データとしてインターネット上の情報を用いる際、そのデータ品質の重要性を改めて浮き彫りにしました。私たちがAIの信頼性や性能を維持していくためには、継続的な学習におけるデータの選定と品質管理が極めて重要であり、まるで人間の健康診断のように、展開されているLLMに対しても定期的な「認知的健康診断」が必要であると結論付けています。

引用元: https://llm-brain-rot.github.io/


- [「ひかれるという感情が薄い」→北海道の車道で目撃……車をまったく気にしない野生動物　釧路では「まれによくある」光景に5.2万“いいね”](https://hint-pot.jp/archives/281691/3/)  


北海道釧路で、車道をまったく気にせず堂々と歩く野生動物の姿がSNSで5.2万いいねを集め話題になっています。この地域では動物たちが車に「ひかれる」という感情が薄く、このような光景は「まれによくある」とのこと。私たちエンジニアも、時にはコードから離れて、自然の中での面白い出来事に目を向け、クスッと笑ってリフレッシュするのも良いかもしれませんね。

引用元: https://hint-pot.jp/archives/281691/3/



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
