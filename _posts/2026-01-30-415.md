---
actor_ids:
  - お嬢様ずんだもん
audio_file_path: /audio/私立ずんだもん女学園放送部_podcast_20260130.mp3
audio_file_size: 0
date: 2026-01-30 05:00:00 +0900
description: 'Introducing Moltworker: a self-hosted personal AI agent, minus the minis、AGENTS.md outperforms skills in our agent evals - Vercel、Context Management for Deep Agents、池袋からイタリアへ“ファーストクラスの旅”に行ってみた！ 豪華な座席と機内食を味わう体験へ「すごい臨場感」「普通に騙されたわw」の声'
duration: "00:00"
layout: article
title: 私立ずんだもん女学園放送部 podcast 20260130
image_url: https://zund-arm-on.com/images/ojousama_zundamon_square.jpg
thumbnail_url: https://zund-arm-on.com/images/ojousama_zundamon_thumbnail.jpg
---

## youtube版(スライド付き)

<div class="article-video"><iframe src="https://www.youtube.com/embed/jTqlvgJ9H-M" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></div>


## 関連リンク


- [Introducing Moltworker: a self-hosted personal AI agent, minus the minis](https://blog.cloudflare.com/moltworker-self-hosted-ai-agent/)  


Cloudflareは、セルフホスト型のパーソナルAIエージェント「Moltbot（旧Clawdbot）」を、Cloudflareのプラットフォーム上で動作させるための実装「Moltworker」を公開しました。通常、この種のAIエージェントを自前で動かすには、Mac miniのような常時稼働する物理的なハードウェアが必要になりますが、Moltworkerを利用することで、Cloudflareの強力なエッジコンピューティング環境上に自分専用のAIアシスタントを構築できるようになります。

### Moltworkerの概要
Moltworkerは、AIエージェントがWebを閲覧したり、コードを実行したり、スケジュールを管理したりといった複雑なタスクを、クラウド上の隔離された環境で実行可能にするプロジェクトです。Cloudflareが提供する最新のインフラ機能をフル活用している点が特徴です。

1.  **Node.jsとの高い互換性**: Cloudflare WorkersのNode.js互換性が飛躍的に向上したことで、これまで困難だった複雑なライブラリ（Playwright等）の動作が可能になりました。主要なNPMパッケージの約98.5%がそのまま動作するレベルに達しています。
2.  **Sandbox SDK (Cloudflare Containers)**: AIが作成したコードを安全に実行するための「隔離された砂場（サンドボックス）」を提供します。これにより、メインのシステムを危険にさらすことなく、AIに動的なタスクを任せられます。
3.  **Browser Rendering**: AIが人間と同じようにブラウザを操作し、Webサイトから情報を取得したり、フォームに入力したりするための機能です。
4.  **R2ストレージ**: コンテナ環境は通常、再起動するとデータが消えてしまいますが、R2をマウントすることでセッション情報や会話履歴を永続化しています。
5.  **AI Gateway**: AnthropicなどのAIモデルへの接続をプロキシし、コストの可視化やモデルの切り替え、失敗時のフォールバックを容易にします。

### 制約と留意点
*   **概念実証（PoC）としての公開**: MoltworkerはCloudflareの正式な製品ではなく、あくまで開発者プラットフォームの可能性を示すためのサンプルプロジェクト（オープンソース）です。
*   **利用コスト**: Sandboxコンテナ機能を利用するため、Cloudflare Workersの有料プラン（月額5ドル〜）への加入が必要となります。
*   **セットアップの前提**: 動作にはCloudflareアカウントが必要であり、各種APIキーの設定や環境構築のステップが必要です。

新人エンジニアの皆さんにとって、このニュースは「サーバーレス技術を組み合わせることで、従来は物理サーバーが必要だった高度なAIアプリケーションがいかにスマートに実装できるか」を学ぶ絶好の事例です。GitHubのリポジトリも公開されているため、インフラとAIを組み合わせたモダンな開発手法に触れる良い機会となるでしょう。

引用元: https://blog.cloudflare.com/moltworker-self-hosted-ai-agent/


- [AGENTS.md outperforms skills in our agent evals - Vercel](https://vercel.com/blog/agents-md-outperforms-skills-in-our-agent-evals)  


Vercelは、AIコーディングエージェントに最新のフレームワーク知識（Next.js 16の新しいAPIなど）を学習させる際、**「AGENTS.md」というファイルにドキュメント情報を直接持たせる手法が、従来の「Skills」というツールベースの手法よりも圧倒的に高い精度を発揮した**という調査結果を公開しました。

### 背景と課題
AIエージェントの学習データは古くなりがちです。例えば、Next.js 16で導入された `'use cache'` や `connection()` といった最新APIを、学習済みのAIモデルは知りません。これを解決するために、以下の2つのアプローチを比較検証しました。

1. **Skills**: エージェントが必要に応じて呼び出す、ドキュメントやツールをパッケージ化した外部標準。
2. **AGENTS.md**: プロジェクトのルートに配置し、エージェントが各ターンで必ず参照するコンテキストファイル（Claude Codeにおける `CLAUDE.md` と同様の仕組み）。

### 驚きの検証結果
検証（Evals）の結果、**Skillsの成功率が最大79%（デフォルトでは53%）にとどまったのに対し、AGENTS.mdを活用した手法は100%の合格率**を叩き出しました。

Skillsが苦戦した主な理由は、「エージェントがドキュメントを読みに行くべきかどうか」を正しく判断できなかったことにあります。56%のケースでエージェントはSkillを一度も呼び出さず、古い知識で回答してしまいました。また、命令文のわずかなニュアンスの違い（例：「まずプロジェクトを調べろ」か「まずドキュメントを読め」か）で結果が大きく変動する脆弱性も見られました。

### なぜ「受動的なコンテキスト」が強いのか
AGENTS.mdが優れている理由は以下の3点に集約されます。
- **判断が不要**: 「調べるべきか？」と考える隙を与えず、最初から情報が目の前にある状態を作れる。
- **一貫した可用性**: 非同期に読み込むSkillと違い、常にシステムプロンプトに含まれるため、情報の欠落がない。
- **順序問題の解消**: プロジェクト探索とドキュメント参照の順序に迷うことがない。

### 実践的な工夫：コンテキストの圧縮
AGENTS.mdに全ドキュメントを書き込むと、入力トークンが肥大化してしまいます。そこでVercelは、**ドキュメントの「インデックス（索引）」のみを約8KBに圧縮してAGENTS.mdに記述する**手法を採用しました。
エージェントはこのインデックスを見て、「どのファイルに何が書いてあるか」を把握し、必要な時だけ特定のドキュメントファイルを読みに行きます。これにより、効率的かつ正確なコード生成が可能になりました。

### 新人エンジニアへのアドバイス
最新のAIエージェント（CursorやClaude Codeなど）を使いこなすには、AIに「何をさせるか」だけでなく、「何を常に意識させるか」が重要です。Next.jsプロジェクトであれば、以下のコマンドを実行するだけで、今回の知見を活かしたAGENTS.md環境を自動構築できます。
`npx @next/codemod@canary agents-md`

AIの「推論」に頼りすぎず、正しい「情報源（リファレンス）」を最短経路で提供することが、開発生産性を最大化する鍵となります。

引用元: https://vercel.com/blog/agents-md-outperforms-skills-in-our-agent-evals


- [Context Management for Deep Agents](https://www.blog.langchain.com/context-management-for-deepagents/)  


AIエージェントが複雑で長期的なタスクを実行する際、避けて通れないのが「LLMの文脈（コンテキスト）制限」の問題です。タスクが長くなるほど履歴が積み重なり、モデルの記憶容量を超えてしまったり、重要な情報が埋もれる「文脈の劣化（context rot）」が起こります。LangChainが公開したオープンソースのフレームワーク「Deep Agents SDK」は、この課題を解決するための高度な文脈管理機能を備えています。

本記事では、Deep Agentsが採用している「コンテキスト圧縮」の3つの主要なテクニックを紹介しています。

1. **巨大なツール実行結果の外出し（Offloading tool results）**
APIレスポンスやファイル読み込みの結果が20,000トークンを超えるような場合、その内容を直接履歴に残さず、ローカルのファイルシステムに保存します。履歴には「ファイルパス」と「最初の10行のプレビュー」だけを残すことで、エージェントは必要に応じてそのファイルを再読込したり検索したりできるようになります。

2. **巨大なツール入力履歴の削除（Offloading tool inputs）**
ファイルの書き込みや編集の履歴は、すでにファイル自体に内容が存在するため、会話履歴に残し続けるのは冗長です。文脈の使用率が85%を超えると、古い書き込み命令の引数などを削除し、ファイルへの参照に置き換えることで容量を確保します。

3. **構造化された要約（Summarization）**
上記の手法でも容量が不足する場合、最終手段として会話履歴の「要約」を行います。単なる要約ではなく、現在のタスクの目的、これまでに作成した成果物、次のステップなどを構造化した「インコンテキスト・サマリー」を生成します。元の詳細な履歴はファイルシステムに保存されるため、エージェントは必要に応じて過去の特定の事実を検索して復元することが可能です。

新人エンジニアへのアドバイスとして、これらの手法を導入する際は「情報の復元可能性」と「目的の喪失（ゴール・ドリフト）」に注意が必要です。要約によってエージェントが本来の目的を見失っていないか、あるいは「干草の山から針を探す（Needle-in-the-haystack）」テストのように、要約された過去の情報を正しくファイル検索で拾い直せるかを評価することが、信頼性の高いエージェント開発の鍵となります。

Deep Agents SDKは、これらの複雑な制御を「ファイルシステム抽象化」などのミドルウェアを通じて自動化しており、エンジニアがロジック構築に集中できる環境を提供しています。

引用元: https://www.blog.langchain.com/context-management-for-deepagents/


- [池袋からイタリアへ“ファーストクラスの旅”に行ってみた！ 豪華な座席と機内食を味わう体験へ「すごい臨場感」「普通に騙されたわw」の声](https://news.nifty.com/article/item/neta/12237-4898564/)  


池袋で体験できる「疑似航空旅行」が話題です。ずんだもんがイタリアへ旅する動画で紹介されたこのサービスは、施設内に再現された「池袋国際空港」からVRで出発します。実際のファーストクラスの座席を使用し、本格的なコース料理を楽しめるのが特徴です。約8,000円で手軽に非日常を味わえるユニークなUXを提供しており、日々の業務で疲れたエンジニアの気分転換や、没入型体験のヒントとして楽しめる内容です。

引用元: https://news.nifty.com/article/item/neta/12237-4898564/



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

VOICEVOX:ずんだもん
