---
actor_ids:
  - 春日部つむぎ
audio_file_path: /audio/マジカルラブリー☆つむぎのピュアピュアA.I.放送局_podcast_20260209.mp3
audio_file_size: 0
date: 2026-02-09 05:00:00 +0900
description: 'なぜ、Claude Codeは、RAGを捨ててAgentic Searchを選んだのか？、Kimi K2.5: Visual Agentic Intelligence、最近のredditは『オタクの英語を忠実にオタクの日本語に翻訳する謎の技術』が実装されていてとても助かるがどういう仕組みなんだ？'
duration: "00:00"
layout: article
title: マジカルラブリー☆つむぎのピュアピュアA.I.放送局 podcast 20260209
image_url: https://zund-arm-on.com/images/tsumugi_podcast_thumbnail.png
thumbnail_url: https://zund-arm-on.com/images/tsumugi_podcast_thumbnail.png
card: summary
---

## 関連リンク


- [なぜ、Claude Codeは、RAGを捨ててAgentic Searchを選んだのか？](https://zenn.dev/karamage/articles/2514cf04e0d1ac)  


Anthropic社のエンジニアであり、Claude Codeの創設者であるBoris Cherny氏が、「初期のClaude CodeではRAG（検索強化生成）を採用していたが、最終的にAgentic Search（エージェントによる自律探索）へ切り替えた」という設計思想を明かし、大きな話題となっています。本記事では、その技術的な判断背景を新人エンジニアにも分かりやすく解説しています。

### 1. RAGとAgentic Searchの違い
まず、従来の「王道RAG」は、あらかじめドキュメントを数値化（Embedding）してデータベース（ベクトルDB）に保存し、質問に似た意味の情報を探し出す仕組みです。試験勉強に例えると「事前に大量の参考書を買い込み、関連しそうなページを付箋で引いておく」ような準備型のアプローチです。

一方、Agentic Searchは、AIがその場で「どのファイルを見るべきか」「どのコマンドを使うべきか」を考えて探索する方式です。grepやglobといった使い慣れたツールを自律的に使い分け、コードベースを直接調査します。これは「問題を見てから、必要な情報をその都度Webや資料で調べに行く」という、人間のエンジニアの行動に近いアドリブ型のアプローチです。

### 2. なぜ「王道RAG」を捨てたのか
Claude Codeがコード探索においてRAGを卒業した理由は、主に4点あります。
- **精度とノイズ**: コード検索では「なんとなく意味が似ている」ことより「正確に一致する」ことが重要です。RAGでは古い仕様や無関係なコードがヒットしやすく、それがAIの「ハルシネーション（もっともらしい嘘）」の原因になっていました。
- **情報の鮮度**: 開発現場ではコードが頻繁に書き換わります。RAGの場合、その都度インデックスを更新するコストが非常に高く、情報が古くなりやすいという欠点がありました。
- **セキュリティとプライバシー**: データを外部のDBに保存・管理する手間を省き、機密性の高いコードをシンプルに扱うためです。
- **LLMの進化**: 最新のモデルは非常に長い文脈を理解でき、複雑な推論が可能になったため、事前の加工なしで直接ファイルを読み解く力が備わったことが背景にあります。

### 3. エンジニアが意識すべき「これからの開発」
広い意味では、外部情報を取得して回答するAgentic SearchもRAGの一種と言えます。しかし、従来の「データベースに頼る検索」から「AIが自律的に探索する」形へと手法が進化しました。

ここで重要なのは、AIの賢さは「人間が用意した環境」に依存するという点です。どれほど優秀なAIエージェントでも、整理されていないクソコードや古いドキュメントの中では正解を見つけられません。お掃除ロボットの「ルンバ」が効率よく動くために、人間が床の荷物を片付ける必要があるのと同様に、エンジニアには「AIが読みやすいようにコードを整理し、ディレクトリ構造を整える」という新しい役割が求められています。

結局のところ、読みやすいコードを書き、適切にドキュメントを整備するというエンジニアの基本こそが、最新AIの性能を最大限に引き出す鍵となるのです。

引用元: https://zenn.dev/karamage/articles/2514cf04e0d1ac


- [Kimi K2.5: Visual Agentic Intelligence](https://simonwillison.net/2026/Jan/27/kimi-k25/)  


AI技術の急激な進化を象徴する、新たな大規模言語モデル「Kimi K2.5」が登場しました。1兆パラメータを誇るオープンウェイトモデル「Kimi K2」シリーズの最新版であり、新人エンジニアの方にとっても、今後の「AIエージェント」の在り方を占う上で非常に重要なニュースです。

今回のアップデートの目玉は、テキストのみだった従来モデルから、15兆トークンに及ぶ画像・テキスト混合データでの学習を経て「ネイティブマルチモーダル」に進化した点です。これにより、視覚情報の理解と高度なコーディング能力が統合されました。

特筆すべきは、Kimi K2.5が提唱する「自己主導型エージェント・スウォーム（Self-directed agent swarm）」という概念です。これは複雑な指示を受けた際、AIが自律的に最大100個の「サブエージェント」を作り出し、最大1500回ものツール呼び出しを並列で実行する仕組みです。人間が細かなワークフローを定義しなくても、AIが勝手に「分身」を作って効率的に仕事を片付けてくれるイメージです。この並列処理により、従来のシングルエージェント方式に比べて実行時間を最大4.5倍も短縮することに成功しています。

実際の性能検証では、自転車に乗るペリカンのSVGコードを生成させたり、複雑なプラグイン開発の工程を「並列実行可能な10個のタスク」へと論理的に分解させたりといったテストが行われました。その結果、Claude 4.5やGPT-5.2といった最新のトップクラスモデルに匹敵する、極めて精緻なプランニング能力を示しています。

技術的な仕様としては、Hugging Faceで公開されているモデルサイズは約595GBと非常に巨大です。ローカル環境で動かすには512GBのRAMを積んだハイエンドなMac Studioが2台必要になるほどの規模ですが、オープンな形でこれほどの性能が提供される点は驚異的です。

ライセンス面では「修正MITライセンス」というユニークな形式を採用しており、月間ユーザー数が1億人を超えるような超大規模サービスで商用利用する場合にのみ、UI上に「Kimi K2.5」の名称を表示する義務が生じます。

AIが単なる「チャット相手」から、複数のエージェントを指揮して複雑なタスクを完遂する「オーケストレーター」へと進化していることを示す、技術者として見逃せないアップデートと言えます。

引用元: https://simonwillison.net/2026/Jan/27/kimi-k25/


- [最近のredditは『オタクの英語を忠実にオタクの日本語に翻訳する謎の技術』が実装されていてとても助かるがどういう仕組みなんだ？](https://togetter.com/li/2661357)  


世界最大級のソーシャル掲示板「Reddit（レディット）」において、英語の投稿を日本語へ翻訳する精度が劇的に向上し、日本のユーザー、特にエンジニアやネット文化に親しみのある人々の間で大きな注目を集めています。

これまでの機械翻訳は、意味は通じるものの「翻訳調」と呼ばれる独特の不自然さが残るものが一般的でした。しかし、現在Redditで体験できる翻訳は、ネット掲示板特有の「砕けた表現」や「特有のスラング」、さらには「投稿者の熱量や感情」までをも巧みに汲み取っています。その結果、海外のユーザーによる英語の書き込みが、まるで日本のネット掲示板に住むオタクが書いたかのような、極めて自然な「オタク日本語」へと変換されるようになっています。

SNS上の反応では、「あまりに自然すぎて、Redditの日本サーバーが活発になったのかと勘違いした」「日本人がちょっと洒落た口調で書いているのかと思った」という驚きの声が多数上がっています。特に、PCパーツのトラブルシューティングやUnityなどのゲーム開発、最新のAI技術に関するエラー解決など、マニアックで深い情報が必要な場面において、この翻訳技術が非常に役立っているとのことです。

エンジニアリングの現場では、解決策が英語圏のコミュニティにしかないケースが多々あります。新人エンジニアの方々にとっても、これまでは「英語だから」と敬遠しがちだった海外の一次情報が、この技術によって一気に身近なものになりました。多くのユーザーが「Yahoo!知恵袋の完全上位互換」としてRedditを真っ先に検索するようになるほど、その情報の密度とアクセスのしやすさが評価されています。

この技術的背景には、大規模言語モデル（LLM）の進化によるコンテキスト（文脈）理解力の向上が大きく寄与していると考えられます。LLMは単なる単語の置き換えではなく、そのコミュニティが持つ文化的な背景や、テキストの背後にある意図を推論する能力に長けています。Redditの事例は、LLMが専門的な知見や感情の入り混じるコミュニティにおいても、言語の壁を意識させないスムーズなコミュニケーションを実現できることを示す、非常に優れた活用例と言えるでしょう。

世界中のエンジニアの知恵が詰まったRedditが、最高品質の翻訳によって「日本語の技術リソース」として機能し始めている現在は、学習や問題解決において非常に恵まれた環境と言えます。最新のAI技術がもたらす恩恵を肌で感じられる、ワクワクするようなニュースです。

引用元: https://togetter.com/li/2661357



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

VOICEVOX:春日部つむぎ
