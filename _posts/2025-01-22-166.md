---
actor_ids:
  - ずんだもん
audio_file_path: https://storage.googleapis.com/podcast-zund-arm-on/audio/株式会社ずんだもん技術室AI放送局_podcast_20250122.mp3
audio_file_size: 0
date: 2025-01-22 05:00:00 +0900
description: 'AIやテクノロジーに関する記事を紹介  
How Captide is redefining equity research with agentic workflows running on LangGraph Platform、GitHub - MoonshotAI/Kimi-k1.5、Fastly、初の AI ソリューション「Fastly AI Accelerator」の一般提供を開始、Amazon Bedrock の Rerank API を活用してRAGの精度を向上させる'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20250122
---

## 関連リンク


- [How Captide is redefining equity research with agentic workflows running on LangGraph Platform](https://blog.langchain.dev/how-captide-is-redefining-equity-research-with-agentic-workflows-built-on-langgraph-and-langsmith/)  


Captideは、LangGraph Platform上で動作するエージェントワークフローを用いて、金融調査のあり方を革新しています。彼らのプラットフォームは、規制当局への提出書類や投資家向け資料から洞察や指標を自動的に抽出することで、アナリストが効率的にカスタムデータセットを作成し、分析することを可能にします。

主なポイントは以下の通りです。

*   **自然言語による分析:** ユーザーは自然言語で複雑な分析タスクを記述でき、金融指標の抽出、カスタムデータセットの作成、文脈的な洞察の発見が容易になります。
*   **LangGraphによる並列処理:** LangGraphの並列処理能力により、複数のエージェントが同時にドキュメントを処理し、待ち時間を短縮し、コードの複雑さを軽減します。
*   **構造化された出力:** LangGraphのtrustcallライブラリを利用することで、カスタムスキーマを持つテーブル出力を生成し、一貫性と信頼性を確保しています。
*   **LangSmithによるリアルタイムな監視:** LangSmithは、エージェントのパフォーマンスを追跡し、出力を評価し、ユーザーフィードバックを収集するためのツールを提供します。これにより、システムの改善を継続的に行うことができます。
*   **LangGraph Platformへのデプロイ:** Captideは、LangGraph Platformにエージェントをデプロイし、APIエンドポイントを簡単に作成しました。また、LangGraph StudioとLangSmithとの統合も容易に行えました。

Captideは、LangGraphとLangSmithの能力を最大限に活用し、金融分析の未来を切り開いています。


引用元: https://blog.langchain.dev/how-captide-is-redefining-equity-research-with-agentic-workflows-built-on-langgraph-and-langsmith/


- [GitHub - MoonshotAI/Kimi-k1.5](https://github.com/MoonshotAI/Kimi-k1.5)  


MoonshotAIが開発した「Kimi k1.5」は、強化学習（RL）を用いて訓練されたマルチモーダルLLMです。このモデルは、特に推論能力において、GPT-4oやClaude Sonnet 3.5を大幅に上回る性能を示しています。長文脈での推論能力も高く、複数ベンチマークでOpenAIのo1に匹敵する結果を達成しています。

Kimi k1.5の主な特徴は以下の通りです。

*   **長文脈スケーリング:** RLのコンテキストウィンドウを128kまで拡張し、コンテキスト長を長くすることで性能が向上することを発見しました。
*   **ポリシー最適化の改善:** 長文CoT（Chain-of-Thought）を用いたRLの定式化と、オンラインミラー降下法の応用により、ロバストなポリシー最適化を実現しました。
*   **シンプルなフレームワーク:** 長文脈スケーリングとポリシー最適化の改善により、モンテカルロ木探索などの複雑な手法に頼らずに高い性能を達成しました。
*   **マルチモーダル:** テキストと画像データを同時に学習し、両方のモダリティにわたる推論能力を備えています。

Kimi k1.5は、[https://kimi.ai](https://kimi.ai/) で近日中に利用可能になる予定です。API経由でのテスト利用も可能で、フォームから申し込みができます。


引用元: https://github.com/MoonshotAI/Kimi-k1.5


- [Fastly、初の AI ソリューション「Fastly AI Accelerator」の一般提供を開始](https://prtimes.jp/main/html/rd/p/000000057.000037639.html)  


Fastly社が、初のAIソリューション「Fastly AI Accelerator」の提供を開始しました。これは、大規模言語モデル（LLM）を使ったAIアプリ開発で、応答速度の向上とコスト削減を支援するものです。具体的には、セマンティックキャッシュという技術を使い、同じような質問に対しては、毎回AIプロバイダーに問い合わせるのではなく、Fastlyのサーバーに保存された回答を返すことで、平均9倍の応答速度向上を実現しています。導入も簡単で、わずか1行のコード変更とAPIエンドポイントの更新だけで利用可能です。OpenAIのChatGPTとMicrosoftのAzure AI Foundryに対応しており、AIアプリ開発をより効率的に進めたいエンジニアにとって、非常に役立つツールとなるでしょう。


引用元: https://prtimes.jp/main/html/rd/p/000000057.000037639.html


- [Amazon Bedrock の Rerank API を活用してRAGの精度を向上させる](https://acro-engineer.hatenablog.com/entry/2025/01/21/120000)  


この記事では、RAG（検索拡張生成）の精度向上に不可欠なリランク技術について、Amazon BedrockのRerank APIを活用する方法を解説しています。従来、リランク処理にはSageMakerなどでモデルをホストする必要がありましたが、BedrockではAPIを呼び出すだけでリランクが可能になり、運用コストを削減できます。

記事では、BedrockのInvokeModel API、Knowledge BaseのRerank API、Retrieve APIの3つの方法でリランクを試しています。特にRetrieve APIでは、ベクトル検索の結果をリランクすることで、ユーザーの検索意図に合致するドキュメントを上位に表示できるようになり、RAGの精度向上が期待できます。

また、Amazon RerankモデルとCohere Rerankモデルの比較も行い、Cohereモデルの方が処理速度が速いことを示しています。料金はAmazon Rerankモデルが1000クエリあたり$1、Cohere Rerankモデルが1000クエリあたり$2です。

Bedrockのリランク機能を活用することで、より精度の高いRAGシステムを開発できる可能性が示唆されています。


引用元: https://acro-engineer.hatenablog.com/entry/2025/01/21/120000



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
