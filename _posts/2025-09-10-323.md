---
actor_ids:
  - ずんだもん
audio_file_path: /audio/株式会社ずんだもん技術室AI放送局_podcast_20250910.mp3
audio_file_size: 0
date: 2025-09-10 05:00:00 +0900
description: 'SafetyKit’s blueprint for scaling risk agents with OpenAI’s most capable models、AIAgentにAI最新情報まとめ資料を作ってもらう会【LangGraph&amp;LangSmith】、Agent Middleware、ゲームを作っていて、先手か後手かをランダムに決定するようにしたら、なぜか何度試しても後手に… 1時間ほど調べてみて分かったが、単に10回連続後手を引いただけだった「ランダムって難しい」'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20250910
---

## 関連リンク


- [SafetyKit’s blueprint for scaling risk agents with OpenAI’s most capable models](https://openai.com/index/safetykit)  


新人エンジニアの皆さん、こんにちは！今回は、OpenAIの最新AIモデル、特にまだ未公開の「GPT-5」が、オンラインの安全を守るためにどのように活用されているかをご紹介します。

「SafetyKit」という会社は、オンラインマーケットプレイスや決済サービス、金融テック企業（フィンテック）が抱える、詐欺や規約違反といった問題に対処するAIエージェントを開発しています。彼らのAIは、テキストだけでなく画像や取引データなど、さまざまな種類の情報（マルチモーダル）を分析し、人間では見逃しやすいような複雑なルール違反（例えば、詐欺画像に隠された電話番号や地域ごとの特別な規制など）を検出します。これにより、ユーザーは安心してサービスを使え、企業は法規制違反のリスクを減らせるだけでなく、人間が不快に感じるようなコンテンツのチェック作業から解放され、より高度な判断業務に集中できるようになります。

SafetyKitは、OpenAIの強力なAIモデルを、タスクの特性に合わせて賢く使い分けています。
*   **GPT-5**：複数の情報源（テキスト、画像、UIなど）を横断的に分析し、複雑な状況から隠れたリスクを深く推論して、精密な意思決定を支援します。まるで探偵がさまざまな証拠を合わせて事件を解決するようなイメージです。
*   **GPT-4.1**：大量のコンテンツを効率的に処理し、詳細な利用規約（ポリシー）に厳密に沿ったモデレーションを安定して行う役割を担います。
これらのモデルに、AIの精度を高める「強化学習によるファインチューニング」や、自動でオンライン調査を行う「Computer Using Agent (CUA)」といった技術を組み合わせることで、95%以上の高い精度で、すべてのコンテンツを網羅的にレビューできる体制を構築しています。

特に、グレーゾーンで判断が難しい場面ではGPT-5の能力が光ります。例えば、ある商品が特定の地域で販売される際に、法律で定められた注意書きが必要かどうかを判断する場合、GPT-5はポリシーの細かなニュアンスを理解し、記載内容が適切かを精密に評価します。これにより、従来のシンプルなルールでは見分けられないような、複雑で微妙な判断も正確に行えるようになりました。

SafetyKitは、OpenAIが新しいAIモデルをリリースすると、すぐにその性能を検証し、効果があれば自社のシステムに迅速に導入しています。このスピード感が、常に進化する詐欺の手口やリスクに対応し続ける原動力となっています。実際に、彼らが処理するデータ量は短期間で大幅に増加しており、支払リスク、詐欺、不適切なコンテンツ対策など、さまざまな分野でその適用範囲を広げています。

このように、SafetyKitはOpenAIの最先端AI技術を巧みに組み合わせることで、私たちのデジタル生活をより安全で信頼できるものにしています。AIエージェントが、複雑なオンライン環境における「目に見えない守り手」として活躍する、先進的な事例と言えるでしょう。

引用元: https://openai.com/index/safetykit


- [AIAgentにAI最新情報まとめ資料を作ってもらう会【LangGraph&LangSmith】](https://zenn.dev/microsoft/articles/create_doc_by_aiagent)  


この記事では、AIエージェントが最新のAI情報を集め、自動でプレゼンテーション資料を作成するPoC（概念実証）について、具体的な実装を通して解説しています。Pythonを使って、LangChain、LangGraph、LangSmithといった主要なAI開発ツールを組み合わせた事例で、新人エンジニアの方でもAIエージェント開発の全体像と各ツールの役割を理解しやすい内容です。

資料作成の自動化フローは、以下のステップで構成されます。
1.  **情報収集 (collect_info)**: Web検索API「Tavily」を使って、AI関連の最新情報を自動で集めます。
2.  **アウトライン生成 (make_outline)**: 収集した情報を基に、スライドの骨子（重要ポイントの箇条書き）を作成します。
3.  **目次生成 (make_toc)**: アウトラインから、スライドの章立て（目次）を生成します。
4.  **スライド本文生成 (write_slides)**: MarpというMarkdownベースのスライド作成ツールを活用し、情報と目次に基づいてスライドの本文を作成します。
5.  **自動評価とリトライ (evaluate_slides)**: 生成されたスライドの品質を自動で評価します。もし品質が低いと判断されれば、より良い資料を作るために目次生成のステップに戻って作り直しを試みます。
6.  **保存 & レンダリング (save_and_render)**: 最終的なスライド（Markdown形式）をPDFなどの形式に変換して保存します。

このPoCで使われている主要なツールは以下の通りです。
*   **LangChain**: 大規模言語モデル（LLM）を使ってアプリケーションを開発するためのフレームワークで、LLMを外部ツールやデータベースと連携させ、より賢いAIアプリケーション（AIエージェントやRAGシステム）を作ることを目指します。
*   **LangGraph**: LangChainを基盤とし、AIエージェントの複雑な処理の流れを「グラフ（ノードとエッジ）」のように設計・可視化できるフレームワークです。条件分岐や繰り返し処理など、高度な制御が可能になります。
*   **LangSmith**: LangChain公式が提供する、LLMアプリケーションの評価・デバッグ・監視プラットフォームです。AIエージェントの動作を詳しく「見える化」し、開発者が問題を発見・修正し、品質を改善するのに役立ちます。
*   **Tavily**: AI向けにWebから最新情報を効率的に収集するための検索APIです。LLMが扱いやすい、要約された形式で検索結果を提供します。
*   **Marp**: Markdown形式でプレゼンテーションスライドを作成できるオープンソースのフレームワークです。Markdownで書いたシンプルなテキストを、PDFやHTML形式の美しいスライドに簡単に変換できます。

この記事は、これらのツールを連携させることで、AIが自律的に情報を収集し、高品質な資料を自動生成する仕組みを実践的に示しています。特にLangGraphとLangSmithは、複雑なAIエージェントのワークフローを設計し、その挙動を可視化・デバッグする上で非常に強力なツールであることが強調されており、AIエージェント開発に興味がある新人エンジニアにとって、実践的な学びが多い記事と言えるでしょう。

引用元: https://zenn.dev/microsoft/articles/create_doc_by_aiagent


- [Agent Middleware](https://blog.langchain.com/agent-middleware/)  


LangChainは、AIエージェント開発をより堅牢で実用的なものにするため、バージョン1.0で「Agent Middleware」という新しい仕組みを導入します。これは、従来のAIエージェントフレームワークが抱えていた、本番環境での信頼性や柔軟性の課題を解決するための重要な改善点です。

これまでのエージェントは、AIモデル、プロンプト、利用するツールの組み合わせで構成され、ユーザーの入力に対してツールを呼び出し、状態を更新しながら目的を達成するというシンプルなループで動作していました。しかし、複雑なタスクや実際のビジネスシーンで利用する際には、AIモデルに入力する情報（コンテキスト）を細かく制御する「コンテキストエンジニアリング」が難しく、エージェントの動作が不安定になったり、期待通りの結果が得られにくかったりするという問題がありました。その結果、多くの開発者は、フレームワークが提供する抽象化では物足りず、独自のコードでエージェントを実装することが多かったのです。

LangChainはこれまでも、このような課題に対応するため、動的にプロンプトを生成したり、モデル呼び出しの前後に処理を挟む「フック」機能を追加したりと、改善を重ねてきました。しかし、これらの機能は多くの個別のパラメータとして提供され、設定が複雑になる上、互いに依存関係があるために管理が難しくなっていました。

そこでLangChain 1.0では、Webサーバーで一般的に使われるミドルウェアの考え方を取り入れました。エージェントの核となる「モデル呼び出し」や「ツール実行」の前後や途中に、開発者が独自の処理を簡単に差し込めるようにするものです。具体的には以下の3つのポイントでエージェントの振る舞いをカスタマイズできます。

1.  **`before_model`**: モデルが呼び出される直前に処理を実行し、エージェントの状態を更新したり、次のステップを変更したりできます。
2.  **`after_model`**: モデルが結果を返した直後に処理を実行し、同様に状態の更新や次のステップの制御が可能です。
3.  **`modify_model_request`**: モデルへのリクエスト内容（使用するツール、プロンプト、メッセージリスト、モデルの種類など）を、その呼び出し時のみ柔軟に変更できます。

複数のMiddlewareを組み合わせて使うことで、例えば、会話履歴が長くなりすぎたら自動で要約する「Summarization」や、重要なツールの実行前に人間の確認を挟む「Human-in-the-loop」といった高度な機能を、モジュール化された形で簡単にエージェントに組み込めるようになります。これにより、エージェントのロジックが整理され、開発者はより信頼性が高く、柔軟で再利用しやすいAIエージェントを構築できるようになるでしょう。LangChainは、すぐに使えるMiddlewareを提供し、コミュニティでの共有も促進していく方針です。

引用元: https://blog.langchain.com/agent-middleware/


- [ゲームを作っていて、先手か後手かをランダムに決定するようにしたら、なぜか何度試しても後手に… 1時間ほど調べてみて分かったが、単に10回連続後手を引いただけだった「ランダムって難しい」](https://togetter.com/li/2600325)  


ゲーム開発で先手・後手をランダムに決めたら10回連続で後手になり、原因を調べたら本当に連続で引いただけだった、という「あるある」エピソードです。プログラムの「乱数」は実は「擬似乱数」で、統計的には偏りがないはずでも、短い試行では連続する事も。ユーザーが不公平だと感じないよう、ゲームでは意図的に偏りを調整し「人間が感じるランダム」にする工夫が重要だと学ぶ、面白く奥深い話題です。

引用元: https://togetter.com/li/2600325



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
