---
actor_ids:
  - ずんだもん
audio_file_path: /audio/株式会社ずんだもん技術室AI放送局_podcast_20250110.mp3
audio_file_size: 0
date: 2025-01-10 05:00:00 +0900
description: 'AIやテクノロジーに関する記事を紹介  
低コスト＆爆速でコード修正！AIエージェントを実務の開発でも試してみる、Why a Perplexity Pro Subscription Is Absolutely Worth the Money、Visualize and understand GPU memory in PyTorch、Kaggleで高額賞金のChess AIのコンペが始まる  やねうら王 公式サイト'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20250110
---

## 関連リンク


- [低コスト＆爆速でコード修正！AIエージェントを実務の開発でも試してみる](https://zenn.dev/ubie_dev/articles/624c9034cc9b43)  


この記事では、ローカルで動作するAIエージェント（CursorとRoo-Cline）を、実務規模のコードベースで試した結果を報告しています。
CursorはVSCodeベースのエディタで、エージェント機能が強化されています。Roo-ClineはVSCodeの拡張機能で、ClineというAIエージェントをフォークしたものです。
両エージェントともClaude 3.5 Sonnetモデルを使用し、テストコードの追加や既存コードの修正を試しました。

Cursorでは、テストコードの自動生成や、フロントエンドとバックエンドにまたがる機能の追加を、複数回の指示と修正で実現できました。
Roo-Clineでは、テストコードの生成を1回の指示で完了させ、フロントエンドの修正も試しましたが、既存コードの重複により、修正に手間取りました。
両エージェントとも、ローカルで動作するため高速で、コストも低いことが分かりました。Cursorは月額制で、Roo-ClineはAPI使用量に応じた従量課金制です。

結論として、AIエージェントは実務レベルで活用可能であり、特にローカルで動作するものは高速かつ低コストです。ただし、コンテキストの理解や、プロジェクトの知識、落とし穴への対応など、エンジニアの関与は不可欠です。
今後は、AIエージェントを使いこなす能力が、エンジニアの生産性を大きく左右する可能性があるでしょう。


引用元: https://zenn.dev/ubie_dev/articles/624c9034cc9b43


- [Why a Perplexity Pro Subscription Is Absolutely Worth the Money](https://www.makeuseof.com/why-perplexity-pro-subscription-worth-the-money/)  


Perplexity Proは、無料版と比較して大幅に機能が向上した有料版AIチャットボットです。月額20ドルで、以下の点が強化されます。
- 1日に利用できる検索回数が大幅に増加（無料版5回に対し、Pro版は300回以上）。
- 公式Discordチャンネルへのアクセスが可能になり、他のユーザーとの交流や、サポートチームへの迅速な問い合わせが可能。
- 検索結果の根拠が明示されるため、より深く理解した上で情報を活用可能。
- 複数のAIモデル（Claude, Sonar, Grok, OpenAIなど）から選択可能。画像生成モデルも選択可能。
- 自身のファイルや画像をアップロードして分析可能。
特に、詳細な調査や研究を行う際に役立ちます。
Perplexity Proは、AIチャットボットを検索に活用したいユーザーにとって、非常に価値のあるサービスです。


引用元: https://www.makeuseof.com/why-perplexity-pro-subscription-worth-the-money/


- [Visualize and understand GPU memory in PyTorch](https://huggingface.co/blog/train_memory)  


PyTorchでのGPUメモリ使用量を可視化し理解するためのチュートリアルです。GPUメモリ不足のエラーに遭遇した際に、その原因を特定し対処するための知識を提供します。

**PyTorch Visualizer**

PyTorchの`torch.cuda.memory`モジュールを利用して、GPUメモリ使用履歴を記録し、`profile.pkl`ファイルとして保存できます。このファイルを[https://pytorch.org/memory\_viz](https://pytorch.org/memory_viz)で可視化することで、メモリ使用状況をグラフで確認できます。

**メモリ使用の内訳**

*   **モデルの生成:** モデルのパラメータがGPUメモリを消費します。
*   **入力テンソルの生成:** 入力データがGPUメモリを消費します。
*   **順伝播:** 中間出力（アクティベーション）がGPUメモリを消費します。
*   **逆伝播:** 勾配計算時にGPUメモリを消費し、アクティベーションが解放されます。
*   **オプティマイザステップ:** モデルパラメータ更新時にGPUメモリを消費します。

**メモリ使用量の見積もり**

GPUメモリ使用量の見積もりは、以下の要素を考慮する必要があります。

*   **モデルパラメータ:** モデルのサイズに比例します（パラメータ数×精度）。
*   **オプティマイザの状態:** AdamWオプティマイザの場合、パラメータごとに2つのモーメントを保持します。
*   **アクティベーション:** 順伝播時に生成される中間出力で、モデル構造や入力サイズに依存します。
*   **勾配:** モデルパラメータと同じサイズになります。
*   **オプティマイザの中間値:** パラメータ更新時に一時的に使用されるメモリです。

総メモリ使用量は、モデルパラメータ、オプティマイザの状態、勾配とオプティマイザ中間値の合計、またはアクティベーションのいずれか大きい方を足した値で近似できます。

**アクティベーションの推定**

アクティベーションの正確な見積もりは難しいですが、モデルのパラメータ数とアクティベーション数にはおおよその線形関係があります。この関係を利用して、モデルを実行せずにアクティベーションメモリを推定できます。

**次のステップ**

メモリ使用量を理解することで、メモリ不足を解消するための対策を立てることができます。TRLドキュメントの[Reducing Memory Usage](https://huggingface.co/docs/trl/main/en/reducing_memory_usage)セクションは、メモリ使用量を最適化するためのヒントを提供します。


引用元: https://huggingface.co/blog/train_memory


- [Kaggleで高額賞金のChess AIのコンペが始まる  やねうら王 公式サイト](https://yaneuraou.yaneu.com/2025/01/03/a-high-prize-chess-ai-competition-is-starting-on-kaggle/)  


KaggleでチェスAIのコンペが開催されています。優勝賞金は$15,000と高額ですが、実行環境にはRAM5MiB、ファイルサイズは64KiBという厳しい制限があります。この制約下で動くAIを開発するのは非常に困難です。将棋AI開発者のドリームチームも参戦しており、記事投稿時点では暫定1位でしたが、上位陣は僅差です。コンペの最終投稿は2月11日、結果発表は2月25日の予定です。興味のある方はぜひ参加してみてください。


引用元: https://yaneuraou.yaneu.com/2025/01/03/a-high-prize-chess-ai-competition-is-starting-on-kaggle/



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
