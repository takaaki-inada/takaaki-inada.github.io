---
actor_ids:
  - お嬢様ずんだもん
audio_file_path: /audio/私立ずんだもん女学園放送部_podcast_20251107.mp3
audio_file_size: 0
date: 2025-11-07 05:00:00 +0900
description: 'Introducing Parallel Search: the highest accuracy web search API engineered for AI、ビジネス出身PMが、「AIのことはエンジニアにお任せ派」から「PMもAIエージェントを自作しよう派」になるまで、Code execution with MCP: building more efficient AI agents、夜のハンマーヘッドは...by中卒チック症ずんだもん  スニーカーダンク'
duration: "00:00"
layout: article
title: 私立ずんだもん女学園放送部 podcast 20251107
image_url: https://zund-arm-on.com/images/ojousama_zundamon_square.jpg
thumbnail_url: https://zund-arm-on.com/images/ojousama_zundamon_thumbnail.jpg
---

## youtube版(スライド付き)

<div class="article-video"><iframe src="https://www.youtube.com/embed/ysb1yn2WjDM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></div>


## 関連リンク


- [Introducing Parallel Search: the highest accuracy web search API engineered for AI](https://parallel.ai/blog/introducing-parallel-search)  


皆さん、こんにちは！今回は、AI（人工知能）開発に役立つ新しいWeb検索API、「Parallel Search」が発表されたというニュースをお届けします。特にAIエージェントを作るエンジニアさんにとっては、とても興味深い内容ですよ。

これまで主流だったWeb検索エンジンは、人間がキーワードで検索し、表示されたリンクをクリックして情報を見つけることを前提に作られていました。しかし、AIエージェントは少し違います。彼らは「何をすべきか」という意図（目的）を理解し、そのタスクを効率的に達成するための「情報（トークンと呼ばれるテキストの最小単位）」を求めているのです。AIにとって最適なのは、クリック率が高いページではなく、モデルが思考・推論するために最も関連性の高い情報が詰まった部分になります。

Parallel Search APIは、このAIのニーズに特化してゼロから設計されました。主な特徴は以下の通りです。

1.  **セマンティックな目標理解**: キーワードだけでなく、AIエージェントの「目的」を深く理解して検索します。
2.  **トークン関連性ランキング**: AIがreasoning（推論）しやすいように、最も関連性の高い情報（トークン）を優先的に提供します。
3.  **情報密度の高い抜粋**: 長いページ全体ではなく、必要な情報が凝縮された部分を効率的に抽出してくれます。
4.  **単一呼び出しでの複雑なクエリ解決**: 通常、何度も検索を繰り返さないと解決できないような複雑な質問でも、少ないAPI呼び出しで答えを見つけやすくします。

これらの工夫により、AIエージェントはより少ない検索回数で、高い精度で必要な情報を手に入れられ、結果としてAPI呼び出しのコスト削減や処理速度の向上に繋がります。

実際に様々なベンチマークテストでは、Parallel Search APIは他の既存サービスと比較して、特に複数の情報源を組み合わせたり、深い理解が必要な「複雑な検索」において、約2倍の精度と約半分のコストで優れたパフォーマンスを発揮しています。シンプルな検索でも、業界トップレベルの精度を維持しつつ、最も低いコストを実現していることが示されています。

この高い性能は、Parallel社が過去2年間で独自のWebインデックスを構築し、Webクローリングからデータのインデックス化、そしてAIに最適なランキング付けまで、検索の全工程を自社で垂直統合しているからこそ実現できたものです。

AIエージェントが「コンテキストウィンドウ」（LLMが一度に処理できる情報の範囲）に、いかに質の高い情報を取り込むかが、タスク達成の鍵となります。Parallel Search APIは、この課題を解決し、AIエージェントの能力を最大限に引き出す強力なツールとなるでしょう。もし皆さんがAIエージェントの開発に携わる機会があれば、ぜひこの新しい検索APIを試してみてはいかがでしょうか。

引用元: https://parallel.ai/blog/introducing-parallel-search


- [ビジネス出身PMが、「AIのことはエンジニアにお任せ派」から「PMもAIエージェントを自作しよう派」になるまで](https://tech.layerx.co.jp/entry/2025/11/06/080000)  


この記事は、コーディング経験のないビジネス出身プロダクトマネージャー（PM）が、AIエージェント開発に挑戦し、その過程で得た実践的な学びを共有しています。

筆者が開発したのは、自社サービス「バクラク申請・経費精算」のお客様の社内運用ルールを、システムで使えるルールに自動翻訳し、AIによる申請レビューが可能か評価するAIエージェントです。これにより、お客様と社内担当者の設定作業負担を減らすことを目指しました。

このエージェントを実用的なものにするため、以下の3つの工夫を凝らしています。
1.  **「利用可能な項目」をTool（ツール）で外部から与える**: LLM（大規模言語モデル）に自由にルールを生成させるのではなく、データベースの項目リストを「Tool」として提供し、その中からしか使えないように制限しました。これにより、LLMが架空の項目を作るのを防ぎ、出力の正確さを向上させています。
2.  **要所で人間がレビューを挟む（HITL: Human-in-the-Loop）**: エージェントが重要な判断をする際には、必ず人間が確認・修正できるステップを組み込みました。これにより、AIの誤った解釈が進行するのを防ぎ、最終的なルールの品質を保証します。
3.  **対象ルールと動作検証済ルールの「構造」が似ているかをRAGで検索する**: 「タクシー代であれば〇〇」「リムジンバス代であれば〇〇」のように、具体的な値は違ってもルールの「構造」が同じものを検出するため、ルールを変数化した上でRAG（検索拡張生成）のベクトルデータベースに登録し、構造的な類似度で検索できるようにしました。

開発を通じて、筆者は以下の重要な学びを得たと述べています。
*   普段使っているChatGPTのような「よしなに」動くAIは、裏で多くの「お膳立て」があって初めて実現できる。素のLLMを動かすには、その土台作りが必要。
*   特にビジネスで使うAIエージェントは、自由にさせるのではなく、Toolやプロンプトで適切に「制御」することで初めて価値を出せる。
*   AIはあくまで課題解決のための「手段」であり、AI技術そのものにこだわるのではなく、お客様への価値提供という本来の目的を冷静に評価することが重要。

非エンジニアがAIエージェントを自作するには、Pythonの基礎やAI関連ライブラリの知識など、多くのスキルが求められ、一人で完遂するのは非常に困難です。しかし、社内のエンジニアからのサポートがあれば、実践を通じてPMもAI技術への理解を深めることができます。PMとエンジニアが協力してAIを活用することで、プロダクトの価値提供スピードを加速できる、というメッセージで締めくくられています。

引用元: https://tech.layerx.co.jp/entry/2025/11/06/080000


- [Code execution with MCP: building more efficient AI agents](https://www.anthropic.com/engineering/code-execution-with-mcp)  


この記事は、AIエージェントをより効率的に動かすための新しい技術「コード実行」について解説しています。特に、AIエージェントが外部システムと連携するための標準プロトコル「MCP（Model Context Protocol）」利用時の課題解決に焦点を当てています。

新人エンジニアの皆さん、AIエージェントはGoogle DriveやSalesforceのような様々なツールと連携して複雑なタスクをこなしますが、その連携方法には工夫が必要です。

**MCPの課題：AIの情報処理負担**
MCPは、AIエージェントが多くの外部ツールと効率的につながるための共通ルールです。しかし、接続するツールが増えると、AI（LLM）が処理できる情報量（コンテキストウィンドウ）に負担がかかるという問題が発生します。

1.  **ツール定義で情報過多**：エージェントが使えるツールの説明が多すぎると、AIは毎回大量の情報を読み込む必要があり、処理が遅くなりコストも増えます。まるで、必要なページを探すために分厚い辞書を毎回全てめくるような状態です。
2.  **中間結果も負担に**：ツールを使って得られたデータ（例：会議の議事録全文）も、AIのコンテキストウィンドウを通過するたびに情報量が増え、AIの処理負担となります。これにより、データ量が多いとエラーを起こしやすくなることもあります。

**コード実行による解決策：効率的な連携**
この課題を解決するのが「コード実行」というアプローチです。これは、MCPサーバーを「コードAPI（プログラムから呼び出せる機能）」として扱い、AIエージェントが自分でプログラムコードを書いてツールを操作する方法です。

このアプローチには、以下のようなメリットがあります。

*   **必要なツールだけ読み込む**：AIエージェントは、タスクに必要なツールの定義だけをオンデマンドで読み込みます。これにより、無駄な情報でコンテキストウィンドウを圧迫することがなくなり、処理速度とコストを大幅に削減できます（例：15万トークンが2千トークンへ、98.7%削減）。
*   **効率的なデータ処理**：大量のデータ（例：1万行の表データ）を処理する場合でも、AIエージェントはコードを使って必要な部分だけをフィルタリングしたり整形したりできます。AIには処理済みの少ないデータだけが渡されるため、負担が軽くなります。
*   **複雑な処理をコードで**：繰り返し処理（ループ）や条件分岐、エラー処理といった複雑なロジックも、AIが直接ツールを呼び出すよりも、コードとして書く方が効率的かつ確実に実行できます。
*   **プライバシー保護**：コード実行環境の中でデータ処理が行われるため、機密情報（個人情報など）がAIのコンテキストウィンドウに直接入ることなく、安全に扱えます。
*   **スキルの蓄積と再利用**：一度うまく書けたコードを「スキル」として保存し、将来のタスクで再利用できます。これにより、AIエージェントは徐々に高度なタスクを効率よくこなせるようになります。

**考慮すべき点**
ただし、AIが生成したコードを実行するには、安全な実行環境（サンドボックスなど）の準備が必要で、セキュリティや運用面でのコストも発生します。

**まとめ**
MCPとコード実行を組み合わせることで、AIエージェントはより多くのツールを効率的・安全に使いこなし、賢くタスクをこなせるようになります。ソフトウェア開発の知恵をAIエージェントに適用する、実践的で重要な技術です。

引用元: https://www.anthropic.com/engineering/code-execution-with-mcp


- [夜のハンマーヘッドは...by中卒チック症ずんだもん  スニーカーダンク](https://snkrdunk.com/post/958810/)  


スニーカーダンクに投稿された記事で、ユーザー名「中卒チック症ずんだもん」さんが、夜のハンマーヘッドが「くっそ寒い」とカジュアルに注意喚起しています。親しみやすいずんだもんの口調で、これからハンマーヘッドを訪れる人に「各位気を付けるように」と呼びかける内容は、新人エンジニアの方々が少し疲れた時にクスッと笑える、心温まる一言です。寒い日も油断せず、体調管理に気をつけましょう。

引用元: https://snkrdunk.com/post/958810/



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

VOICEVOX:ずんだもん
