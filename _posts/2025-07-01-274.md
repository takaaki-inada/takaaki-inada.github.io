---
actor_ids:
  - ずんだもん
audio_file_path: /audio/株式会社ずんだもん技術室AI放送局_podcast_20250701.mp3
audio_file_size: 0
date: 2025-07-01 05:00:00 +0900
description: 'Best-in-Class Multimodal RAG: How the Llama 3.2 NeMo Retriever Embedding Model Boosts Pipeline、Claude Codeを実際のプロジェクトにうまく適用させていくTips10選、オープンＡＩ、グーグル半導体を使用　初の非エヌビディア製か、ずんだもんの『世界化計画』は“曖昧さ”を肯定する　ストリートに接続しながらメジャーデビューを果たす意義'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20250701
---

## 関連リンク


- [Best-in-Class Multimodal RAG: How the Llama 3.2 NeMo Retriever Embedding Model Boosts Pipeline](https://developer.nvidia.com/blog/best-in-class-multimodal-rag-how-the-llama-3-2-nemo-retriever-embedding-model-boosts-pipeline-accuracy/)  


データはテキストだけでなく、画像や動画、音声など多様な形式で存在します。これまでの情報検索システム（RAG: Retrieval Augmented Generation）はテキスト中心で、PDFや画像からテキストを抽出する際に、図や表といった視覚情報が失われる課題がありました。

この課題を解決するために、画像とテキストの両方を理解できる「ビジョン言語モデル（VLM: Vision Language Models）」が登場しました。VLMは、機械が視覚とテキスト情報を組み合わせて理解することを可能にし、質問応答やマルチモーダル検索など、より自然で便利なアプリケーションを実現します。

近年、VLMの進化により、「マルチモーダルRAG」の構築が注目されています。マルチモーダルRAGでは、複雑なテキスト抽出ステップが不要になり、文書の画像を直接処理できるため、RAGパイプラインをシンプルにできます。ただし、VLMはテキスト専用のLLMに比べて「幻覚」（事実と異なる情報を生成すること）を起こしやすい傾向があるため、より正確な情報検索（Retrieval）が重要になります。

ここで中心となるのが「マルチモーダル埋め込みモデル」です。これは、画像とテキストを共通の数値表現（ベクトル）に変換し、互いの関連性を効率的に見つけられるようにする技術です。これにより、テキストクエリで関連画像を検索したり、画像から関連テキストを検索したりすることが可能になります。

NVIDIAは、このマルチモーダルRAGの課題に対応するため、新しいマイクロサービス「NVIDIA NeMo Retriever」をリリースしました。特に注目すべきは、最新の「Llama 3.2 NeMo Retriever Multimodal Embedding 1Bモデル」です。これは16億パラメータと小さいながらも非常に強力なVLM埋め込みモデルで、NVIDIA NIMという形で提供され、大規模で効率的なマルチモーダル情報検索システム構築を可能にします。

このモデルは、画像処理を行うVision Encoderと、Llama 3.2ベースの言語モデル、そして両者をつなぐ層で構成されており、テキストの質問と文書画像の埋め込みが一致するように学習されています。そのため、高い精度で関連情報を検索できます。複数のベンチマークデータセットで、他の同規模のVLM埋め込みモデルと比較して優れた検索精度（Recall@5）を示し、特に図表やテキストなど、様々な種類の情報を含む文書からの検索で高い性能を発揮することが確認されています。

「Llama 3.2 NeMo Retriever Multimodal Embedding 1Bモデル」は、OpenAI APIと互換性のあるインターフェースで利用できます。これにより、開発者は簡単なコードでテキストクエリや画像入力から埋め込みベクトルを生成し、マルチモーダルな情報検索システムを迅速に構築できます。NVIDIA NeMo Retrieverは、高精度かつセキュアな情報検索を企業にもたらし、リアルタイムでのビジネス洞察生成を支援します。AIを活用した情報検索システムの開発に関心のある新人エンジニアにとって、この新しい技術は、マルチモーダルデータ活用の強力な一歩となるでしょう。

引用元: https://developer.nvidia.com/blog/best-in-class-multimodal-rag-how-the-llama-3-2-nemo-retriever-embedding-model-boosts-pipeline-accuracy/


- [Claude Codeを実際のプロジェクトにうまく適用させていくTips10選](https://qiita.com/nokonoko_1203/items/67f8692a0a3ca7e621f3)  


この記事は、コーディング用AIエージェント「Claude Code」を実際の開発プロジェクトで効果的に活用するための10個の具体的なテクニックを紹介しています。AIを使っていると「コードが複雑になるとうまくいかない」「意図しない動きをする」といった課題に直面しがちですが、これらを軽減し、AIを強力な味方にするための知見が詰まっています。

まず基本的な使い方として、`npm install -g @anthropic-ai/claude-code`で導入し、プロジェクトディレクトリで`claude`と実行するだけで使い始められます。`-c`で前回の会話を継続したり、`/model`でAIモデルを切り替えたり、`/clear`で会話履歴をクリアするといった便利コマンドも活用しましょう。Claude Codeは頻繁にアップデートされるため、`claude update`で常に最新の状態に保つことが推奨されています。

次に、より高度な活用術です。
1.  **設計・タスク整理・実装の明確な分離**: 複雑なタスクは、設計、タスクの細分化、実装と段階を分けてAIに指示することで、質の高い結果を得やすくなります。
2.  **CLAUDE.mdによるグローバル設定**: ホームディレクトリの`~/.claude/CLAUDE.md`ファイルにプロジェクト全体のルールを記述できます。例えば、「AIは英語で思考し、日本語で応答する」「ドキュメントは英語、コードコメントは日本語」といった指示や、タスク完了時の自動通知設定などが可能です。
3.  **MCPによる機能拡張**: Model Context Protocol（MCP）を利用すると、Claude Codeの能力を大幅に広げられます。例えば、GitHubリポジトリの操作、最新のライブラリドキュメントの取得、Webスクレイピングといった機能を追加できます。
4.  **効果的なコードレビュー**: `/review`コマンドや、詳細なプロンプトを与えることで、AIにコードレビューを依頼し、品質向上に役立てられます。
5.  **思考拡張による精度向上**: プロンプトに`think hard`や`ultrathink`といったキーワードを含めることで、AIがより深く複雑な分析を行うよう促し、回答の精度を高めることができます。
6.  **セキュリティを考慮したpermissions設定**: `~/.claude/settings.json`で、AIのファイルアクセスやコマンド実行権限を細かく制御できます。「危険なコマンドは禁止し、必要な操作だけ許可する」というバランスが重要です。
7.  **Git Worktreeの活用**: Git Worktreeを使って複数のブランチで同時に作業を進め、`ccmanager`のようなツールでAIのセッション管理を効率化することで、並行開発がスムーズになります。
8.  **作業完了通知の自動化**: `CLAUDE.md`に設定を記述することで、AIがタスクを完了した際に自動的に通知を受け取れるようになり、進捗管理がしやすくなります。
9.  **カスタムスラッシュコマンドの作成**: `~/.claude/commands/`に独自のコマンドファイルを作成することで、特定の作業（例: Markdownからスライドを自動生成）をAIに任せたり、Gemini CLIと連携してWeb検索を効率化したりできます。

これらのTipsを活用することで、Claude Codeの持つ力を最大限に引き出し、開発効率とコード品質を大きく向上させることができるでしょう。新人エンジニアの皆さんもぜひこれらのテクニックを試して、AIとの開発を楽しんでみてください。

引用元: https://qiita.com/nokonoko_1203/items/67f8692a0a3ca7e621f3


- [オープンＡＩ、グーグル半導体を使用　初の非エヌビディア製か](https://jp.reuters.com/economy/industry/LQW3LAQ5WJMGDPMOEABXN2E3MM-2025-06-29/)  


AI技術をリードするOpenAIが、ChatGPTなどのAIサービスを動かすために、これまで主に使っていたNVIDIA（エヌビディア）製のAI向け半導体（GPU）だけでなく、Google（グーグル）が開発したAI専用の半導体「TPU」の利用を始めたことが分かりました。これは、AI業界のハードウェア戦略において大きな変化を示すニュースです。

これまでOpenAIは、AIの学習や推論（AIが答えを出すこと）に必要な計算処理のほとんどを、エヌビディア製のGPUに頼っていました。しかし、AIサービスの高度化に伴い、OpenAIはより多くの計算能力を必要としており、その対応策としてGoogleのクラウドサービス活用を計画していると以前から報じられていました。

今回のTPU利用開始の背景には、Googleが自社開発してきたTPUを、社内だけでなく外部の企業にも提供する戦略を進めていることがあります。OpenAIがエヌビディア製以外のAI半導体を本格的に使うのは初めてとみられ、これは彼らを支援するマイクロソフトのデータセンターへの依存を減らそうとしている可能性も示唆しています。

この動きは、AI半導体市場においてTPUがエヌビディア製GPUの「安価な代替品」として台頭する可能性を秘めており、OpenAIはTPUの利用によってAIサービスを動かす費用（推論コスト）の削減を期待しているようです。ただし、Googleは最も高性能なTPUを競合他社にはまだ提供していないとされています。

新人エンジニアの皆さんにとって、このニュースはAI技術の裏側で動いているハードウェアの変化、そしてその変化がAI開発やサービスのコスト、さらには業界全体の競争にどう影響するかを知る良い機会です。AIの進化はソフトウェアだけでなく、それを支えるハードウェアの多様化と競争によっても加速していることを理解すると、これからの技術トレンドを読み解く上で役立つでしょう。

引用元: https://jp.reuters.com/economy/industry/LQW3LAQ5WJMGDPMOEABXN2E3MM-2025-06-29/


- [ずんだもんの『世界化計画』は“曖昧さ”を肯定する　ストリートに接続しながらメジャーデビューを果たす意義](https://realsound.jp/2025/06/post-2072118.html)  


「ずんだもん」がビクターからメジャーデビューし、「世界化計画」をスタートしました。人気の理由は、性別などに“曖昧さ”という余白を持たせたキャラクター設定と、二次創作を自由に認める運営側の“寛容な姿勢”にあります。これにより、ユーザーが多様な作品を生み出し、まるでストリートカルチャーのように広まりました。今回のメジャーデビューは、この“曖昧さ”を肯定し、ファンと共に作り上げてきた文化を世界に発信する意義深い一歩です。

引用元: https://realsound.jp/2025/06/post-2072118.html



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
