---
actor_ids:
  - ずんだもん
audio_file_path: /audio/株式会社ずんだもん技術室AI放送局_podcast_20260108.mp3
audio_file_size: 0
date: 2026-01-08 05:00:00 +0900
description: 'Googleが開発した次世代AIエージェントIDE「Antigravity」がやばすぎる、育てるほど楽になる AI 開発体制を作っている話  BLOG - DeNA Engineering、Claude Codeで他社 LLM を使う方法：OpenAIのgpt-5.2-proで実践、聞きたい曲があるけど歌詞とか全然思い出せない！一枚絵は割と覚えてるのに！→ワンチャン“それっぽい絵”を描いて画像検索すればいけるんじゃ…？→その結果'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20260108
---

## youtube版(スライド付き)

<div class="article-video"><iframe src="https://www.youtube.com/embed/OpjNod58MUs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></div>


## 関連リンク


- [Googleが開発した次世代AIエージェントIDE「Antigravity」がやばすぎる](https://zenn.dev/mitsuo119/articles/5e6cbda8ada83d)  


Google DeepMindが発表した「Antigravity」は、これまでの開発環境の常識を覆す、AIエージェントを中心（Agent-First）に据えた次世代の統合開発環境（IDE）です。従来のIDEが「人間が書き、AIが補完する」ものだったのに対し、Antigravityは「AIエージェントが自律的に動き、人間がそれを監督・共創する」という新しいパラダイムを提示しています。

新人エンジニアの方にとっても、これからの開発スタイルのスタンダードを知る上で非常に重要な技術です。主な要点は以下の通りです。

### 1. 「Gemini 3」を搭載したエージェント・ファーストな設計
Antigravityは、Googleの最新AIモデル「Gemini 3」シリーズをエンジンとして採用しています。最大の特徴は、AIが単なる「コード補完ツール」ではなく、意思を持ってタスクを完遂する「エージェント」として機能する点です。
エージェントは、必要なAPIのドキュメントを自ら読み込み、実装に向けた具体的な計画を立て、実際にコードを書き、エラーが出れば自律的にデバッグまで行います。これにより、開発者は細かい構文に悩む時間から解放され、システム全体の設計や「どんな価値を提供するか」という本質的な意思決定に集中できるようになります。

### 2. ブラウザを自ら操作し、動くところまで責任を持つ
このIDEにはブラウザが統合されており、AIエージェントは人間と同じようにブラウザを操作できます。コードを書いて終わりではなく、実際にアプリを立ち上げ、クリックやスクロールをしてUIが正しく動作するかをテストします。エラー画面のスクリーンショットを撮って原因を分析する姿は、まさに「自律して動く同僚」そのものです。

### 3. 「Artifacts（アーティファクト）」による作業の可視化
AIに作業を任せきりにすると「中で何をやっているか分からない」という不安が生まれがちですが、Antigravityは「Artifacts」という仕組みでこれを解決しています。
AIは作業の過程で、TODOリストや実装計画書、作業ログなどを逐次作成し、ユーザーに提示します。開発者はこれらをチェックすることで、AIの思考プロセスを把握し、必要に応じて「そこはこう直して」と指示を出したり、承認したりすることができます。この透明性が、人間とAIの信頼関係を築く鍵となっています。

### 4. 開発者の脳を「マルチスレッド化」する
DeepMindは、この環境を「開発者の脳をマルチスレッド化するもの」と表現しています。一人のエンジニアが複数の機能をAIエージェントに並行して任せ、自分はそれらの進捗を確認・統合していくような、高度なチーム開発に近い体験が可能になります。

### まとめ
Antigravityは、AIを「便利な道具」から「頼れるパートナー」へと昇華させる試みです。現在はWindows、macOS、Linux向けにパブリックプレビュー版が公開されており、誰でもこの未来の開発体験に触れることができます。これからエンジニアとしてのキャリアを歩む皆さんにとって、AIとどのように手を取り合って生産性を高めていくか、そのヒントが詰まったツールと言えるでしょう。

引用元: https://zenn.dev/mitsuo119/articles/5e6cbda8ada83d


- [育てるほど楽になる AI 開発体制を作っている話  BLOG - DeNA Engineering](https://engineering.dena.com/blog/2026/01/ai-driven-develop/)  


本記事は、DeNAの新規サービス開発チームにおいて、生成AI（Claude CodeやCursor等）を単なる「個人の補助ツール」から「プロジェクトの文脈を理解したチームメンバー」へと引き上げ、開発生産性を劇的に向上させた事例を紹介しています。新人エンジニアの方にとっても、モダンなAI駆動開発の理想形を知る上で非常に参考になる内容です。

### 1. 背景と課題
複雑なドメインを持つ新規開発プロジェクトでは、「AIの出力がプロジェクト固有のルールに従わない」「レビューでAIが汎用的なことしか言わない」といった課題がありました。これを解決するため、AIに与える「コンテキスト（文脈）」をリポジトリ内で一元管理し、AIを「育てる」仕組みを構築しました。

### 2. ワークフロー設計の2つの指針
- **レビュー作業の「量」を減らす**: 機械的なチェック（規約違反や単純なバグ）はAIによる一次レビューで完結させ、人間はビジネスロジックなどの本質的な検討に集中できる状態を目指しました。
- **開発成果物の「品質」を標準化する**: スキルや経験に依存せず、誰でもガイドラインに沿った高品質なコードを生成できるよう、AIが参照するドキュメントを整備しました。

### 3. 具体的な取り組み
- **特定のタスクに特化した「サブエージェント」**: 「API設計」「Go言語レビュー」など、役割を限定した小さなエージェントを定義。責務を絞ることで、AIの回答精度を大幅に向上させました。
- **Claude Code Actionsによる自動レビュー**: GitHub Actionsと連携し、プルリクエスト（PR）作成時にAIが自動でガイドライン準拠チェックを行います。重要度付きで具体的な指摘が入るため、人間による修正指示が大幅に減りました。
- **Serena MCPの導入**: コードの依存関係やシンボルをAIが正確に把握できるツールを導入し、大規模なコードベースでもAIが迷わない環境を構築しました。
- **ドキュメント自動更新フロー**: レビュー時の指摘事項をAIが分析し、自動でプロジェクトのガイドラインを更新するPRを作成します。これにより、「レビューするほどAIが賢くなる」循環が生まれました。

### 4. 導入の効果
この体制の導入後、1つのPRあたりの人間のレビュー回数は平均7.2回から2.7回へと激減しました。AIをチームの一員として適切に管理・育成することで、開発スピードと品質の両立に成功しています。AIを使いこなす鍵は、ツールそのものよりも「プロジェクト固有の知識をどうAIに教え込むか」という仕組み作りにあります。

引用元: https://engineering.dena.com/blog/2026/01/ai-driven-develop/


- [Claude Codeで他社 LLM を使う方法：OpenAIのgpt-5.2-proで実践](https://dev.classmethod.jp/articles/claude-code-third-party-llm-litellm-proxy/)  


本記事は、Anthropicが提供するエンジニア向けCLIツール「Claude Code」において、Anthropic以外のLLM（OpenAIのgpt-5.2-proなど）を利用するための具体的な構成方法を解説しています。最新のAI技術を柔軟に使い分けたいエンジニアにとって、非常に実用的なハック手法を紹介しています。

通常、Claude CodeはAnthropicのAPI形式を前提として設計されているため、そのままでは他社のLLMと通信することができません。そこで、APIの「翻訳役」として「LiteLLM Proxy」というツールを中継させるのが本手法の核となります。LiteLLM Proxyは、異なるプロバイダー間のAPI仕様の差分を吸収し、共通のインターフェースを提供するオープンソースのソフトウェアです。

■ 実装の3つのステップ
1. 設定ファイルの作成：利用したいモデル（例：gpt-5.2-pro）のAPIキーを指定した「config.yaml」を用意します。
2. Proxyの起動：DockerまたはPython環境（uv等）を使用して、ローカル環境でLiteLLM Proxyを立ち上げます。これにより、自分のPC内に他社LLMへの窓口が作られます。
3. 接続先の切り替え：Claude Codeが標準で参照する通信先を、環境変数（ANTHROPIC_BASE_URLなど）を用いて、先ほど立ち上げたローカルのProxyへとリダイレクトします。

■ 本手法のメリットと注意点
この構成の最大の利点は、Claude Codeという強力なツールを維持したまま、タスクの性質に応じて最適なモデルを自由に選択できる柔軟性にあります。記事では、環境変数を一時的に設定する方法を推奨しており、既存のClaude利用環境を汚さずに試行錯誤できる点も、新人エンジニアにとって取り組みやすいポイントです。

ただし、モデルごとにトークン単価や課金体系が大きく異なる点には注意が必要です。特に高性能な最新モデルはコストが高くなる傾向があるため、利用量を確認しながら進めることが推奨されています。

エンジニアとして「APIの互換性をどう解決するか」という設計思想を学ぶ上でも非常に参考になる内容であり、複数のAIモデルを目的別に使いこなす「AIエージェント活用時代」の標準的なテクニックの一つと言えるでしょう。

引用元: https://dev.classmethod.jp/articles/claude-code-third-party-llm-litellm-proxy/


- [聞きたい曲があるけど歌詞とか全然思い出せない！一枚絵は割と覚えてるのに！→ワンチャン“それっぽい絵”を描いて画像検索すればいけるんじゃ…？→その結果](https://togetter.com/li/2648670)  


歌詞や曲名を忘れた際、記憶にあるイラストを自ら描き、画像検索で見事に目的の曲を探し当てたというクリエイティブな解決事例です。特徴的な色合いや構図を再現することで、曖昧な記憶を検索可能なデータへと変換し、既存の検索技術を最大限に活用しています。この「無いなら作る」というハック精神は、新人エンジニアにとっても問題解決の良きヒントになるでしょう。作者との心温まる交流も描かれた、技術の可能性を感じる話題です。

引用元: https://togetter.com/li/2648670



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
