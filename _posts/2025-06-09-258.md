---
actor_ids:
  - 春日部つむぎ
audio_file_path: /audio/マジカルラブリー☆つむぎのピュアピュアA.I.放送局_podcast_20250609.mp3
audio_file_size: 0
date: 2025-06-09 05:00:00 +0900
description: 'AIの著作権問題に終止符か？ 8TBの巨大オープンデータセット「Common Pile」登場、Llama 2に匹敵するLLMもリリース  XenoSpectrum、うさぎでもわかる🐰ヤバすぎclaude-bridgeでClaude CodeにGPT、Gemini、ローカルLLMを接続！無料でエージェント機能使い放題の革命的ツール、The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity、特急に乗ってきた上品な感じのお婆さんが後ろの外国人に席を倒して良いか聞こうとして、翻訳アプリの発音機能を使ったら、響き渡った翻訳がこれで口角が上がりまくってしまった… たぶん駄目だよ'
duration: "00:00"
layout: article
title: マジカルラブリー☆つむぎのピュアピュアA.I.放送局 podcast 20250609
image_url: https://zund-arm-on.com/images/tsumugi_podcast_thumbnail.png
thumbnail_url: https://zund-arm-on.com/images/tsumugi_podcast_thumbnail.png
card: summary
---

## 関連リンク


- [AIの著作権問題に終止符か？ 8TBの巨大オープンデータセット「Common Pile」登場、Llama 2に匹敵するLLMもリリース  XenoSpectrum](https://xenospectrum.com/8tb-massive-open-dataset-common-pile-now-available/)  


近年、生成AIは膨大なデータを学習して進化しましたが、その中には著作権保護コンテンツも多く含まれ、無断利用による著作権問題が深刻化しています。これによりAI開発企業は学習データの詳細を公開せず、研究の透明性が失われる「透明性の冬」という状況に陥っていました。

このような状況を打破するため、EleutherAIを中心とする共同研究チームが、画期的なテキストデータセット「Common Pile v0.1」を公開しました。これは8テラバイト（TB）もの膨大なデータ量を持つ点が特徴です。最大のポイントは、**パブリックドメイン（著作権が消滅したものなど、誰もが自由に使える状態のコンテンツ）と、オープンライセンスのコンテンツ（使用、研究、変更、再配布が自由に許諾されているもの）のみで構築されている**点です。特に「オープンの定義2.1版」という厳格な基準を採用し、誰もが自由に利用できるライセンスのコンテンツだけを選び、商用利用や改変が制限されるライセンスは排除されています。

Common Pileは、データ量だけでなく内容も非常に多様です。オープンソースのソースコード、政府・法律関連文書、学術論文など、30種類もの信頼できるソースから収集されています。また、インターネットに存在する誤ったライセンス表記（ライセンスロンダリング）や、個人情報、有害なコンテンツ、重複するデータなどを徹底的に取り除き、高品質を維持するための厳しい管理が行われています。

さらに驚くべきは、この「クリーンな」Common Pileで学習させた新しい言語モデル「Comma v0.1」が、Meta社の「Llama 2」など、ライセンスの透明性が低いデータで学習された既存の高性能モデルに匹敵する、あるいは一部で凌駕する能力を示したことです。これは「著作権を遵守すると高性能なAIは作れない」という従来の常識を覆す画期的な成果と言えます。

Commaモデルの高性能は、Common Pileに含まれる多様なデータソースの「混ぜ方（データミキシング）」を工夫した点にあります。品質の高いデータを優先的に学習させることで、限られた計算資源で効率的に知識を習得できました。

この「Common Pile」は、過去のデータセットにおける著作権問題の反省を活かし、法的・倫理的な正当性を最優先に据えた「The Pileの正統進化形」と位置づけられます。Common Pileの登場は、AI開発における著作権リスクを低減し、透明で倫理的なAI研究を加速させるための大きな一歩となるでしょう。これにより、開発者は安心してAIを開発でき、社会全体として説明可能で信頼できるAIの実現に貢献すると期待されています。

引用元: https://xenospectrum.com/8tb-massive-open-dataset-common-pile-now-available/


- [うさぎでもわかる🐰ヤバすぎclaude-bridgeでClaude CodeにGPT、Gemini、ローカルLLMを接続！無料でエージェント機能使い放題の革命的ツール](https://note.com/taku_sid/n/n189f2696a30e)  


この記事では、AI開発ツール「Claude Code」をさらに便利にするオープンソースツール「claude-bridge」を紹介します。これまでClaude CodeはAnthropic社のAIモデルに限定されていましたが、「GPT-4oのような新しいモデルも試したいけど、そのためだけに別のツールを覚えるのは大変…」と感じていたエンジニアの皆さんに朗報です。claude-bridgeを使えば、Claude CodeからOpenAIのGPTシリーズ、GoogleのGemini、さらにはご自身のPCで動かせるローカルLLMまで、様々なAIモデルを利用できるようになります。

claude-bridgeは、Claude Codeが出すAIへのリクエストを「翻訳」し、指定された他のAIプロバイダーが理解できる形式に変換して転送する「プロキシ」として機能します。これにより、Claude Codeは普段通りに動作しますが、裏では自由に選んだAIモデルと連携できる「魔法」を実現しています。

このツールの最大の魅力は、特に「Ollama」というツールと組み合わせることで、自宅のPCに高性能なGPU（画像処理装置）があれば、**AIエージェント機能を完全に無料で、そして無制限に使い放題**にできる点です。これにより、高額なAPI利用料を気にすることなく、またプライベートなコードや機密情報が外部に送られる心配もなく、安全にAIを活用できるようになります。これは、コスト削減やプライバシー保護を重視する企業や個人の開発者にとって、非常に大きなメリットとなります。

インストールは「`npm install -g @mariozechner/claude-bridge`」と簡単で、使い方も「`claude-bridge openai gpt-4o`」のようにプロバイダーとモデルを指定するだけと非常にシンプルです。複数のAIモデルを比較しながらコード生成を行うなど、開発効率の劇的な向上が期待できます。

ただし、いくつかの制限事項もあります。例えば、Claude Codeの表示するAIのトークン使用量や費用は正確でなかったり、画像のアップロード機能が動作しなかったりします。また、OpenAIの特定のモデルではAIの「思考過程」が詳細に表示されない場合もあります。これらの制限を理解し、「あくまでハック的なツール」であることを念頭に置き、重要なプロジェクトで使う前には十分にテストを行うことが推奨されています。

claude-bridgeは、AIモデルの選択肢を広げ、コストを削減し、プライバシーを守りながら、AIエージェント機能を活用した開発を進めるための革新的なツールです。AI開発に興味のある新人エンジニアの皆さんは、ぜひ一度試して、その便利さを体験してみてください。

引用元: https://note.com/taku_sid/n/n189f2696a30e


- [The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity](https://machinelearning.apple.com/research/illusion-of-thinking)  


最近のAIモデル（LLM）には、Large Reasoning Models（LRM）と呼ばれる、答えを出す前に詳細な「思考プロセス」を生成するものが登場しました。これらは推論能力のベンチマークで高い性能を示す一方で、その基本的な能力や、問題の規模が大きくなった時の特性、そして限界についてはまだ十分に理解されていませんでした。

これまでの評価は、主に数学やプログラミングの問題で、最終的な答えの正確さに注目していました。しかし、この評価方法には、学習データが汚染されている（テスト問題がすでにモデルの学習に使われている）可能性があり、モデルがどういう思考プロセスで答えを出したのか、その質や構造が分かりにくいという課題がありました。

そこでこの研究では、制御可能なパズル環境を使って、これらの課題を体系的に調べました。この環境では、問題の論理構造は変えずに、その「複雑さ」だけを細かく調整できます。これにより、最終的な答えだけでなく、LRMの内部でどのように「思考」が進んでいるのか（推論の軌跡）を詳細に分析することが可能になりました。

様々なパズルで広範な実験を行った結果、最新のLRMは、ある一定の複雑さを超えると、その回答精度が完全に崩壊してしまうことが分かりました。さらに、非常に興味深いことに、問題の複雑さが増すにつれて、LRMの「推論の努力」（思考に費やすリソース）は最初は増えるものの、ある時点を境に、たとえ十分な思考のためのリソース（トークン予算）があっても、かえってその努力が減少してしまうという、直感に反する限界があることが判明しました。

また、LRMと、思考プロセスを生成しない通常のLLMを同じ計算資源で比較すると、3つの異なる性能領域が見られました。1つ目は、簡単な問題では、意外にも通常のLLMの方がLRMよりも良い結果を出すことがあります。2つ目は、中程度の複雑さの問題では、LRMが追加の思考を行うことで有利になることが示されました。そして3つ目は、非常に難しい問題では、どちらのモデルも完全に問題を解けなくなる、という結果でした。

研究では、LRMが正確な計算に限界があること、明確な手順（アルゴリズム）を使えないこと、そしてパズルによって推論の仕方が一貫しないことも明らかになりました。これらの分析は、LRMの強みと限界を浮き彫りにし、最終的に彼らの本当の推論能力について重要な疑問が提起されています。

引用元: https://machinelearning.apple.com/research/illusion-of-thinking


- [特急に乗ってきた上品な感じのお婆さんが後ろの外国人に席を倒して良いか聞こうとして、翻訳アプリの発音機能を使ったら、響き渡った翻訳がこれで口角が上がりまくってしまった… たぶん駄目だよ](https://togetter.com/li/2561307)  


特急列車内で、お婆さんが席をリクライニングするためAI翻訳アプリを利用したところ、「あなたを倒していいですか？」と誤訳され、周囲の笑いを誘うハプニングがありました。これは日本語の「倒す」が「リクライニング」と「打ち負かす」で多義的であることが原因です。AI翻訳の奥深さや、人間らしいユーモアに触れる面白い事例として、AIが身近な存在となった現代の微笑ましい一面を示しています。正しい英語表現についても解説されています。

引用元: https://togetter.com/li/2561307



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

VOICEVOX:春日部つむぎ
