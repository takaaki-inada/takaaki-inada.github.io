---
actor_ids:
  - 春日部つむぎ
audio_file_path: /audio/マジカルラブリー☆つむぎのピュアピュアA.I.放送局_podcast_20250818.mp3
audio_file_size: 0
date: 2025-08-18 05:00:00 +0900
description: 'GPT-5の出力品質を低下させる「絶対にやってはいけないプロンプト」 【生成AI事件簿】OpenAI史上最も賢く、速いGPT-5に「頭が悪くなった」の批判、なぜ問題が起きてしまったのか、Refine your initial prompt instead of course-correcting、Google、超軽量、低消費電力モデル「Gemma 3 270M」をリリース  gihyo.jp、イキリオタクはロレックスを着けているが俺はマジで意味不明の腕時計を使っている「まじで意味わからん」「視覚障害者が使うやつ？」'
duration: "00:00"
layout: article
title: マジカルラブリー☆つむぎのピュアピュアA.I.放送局 podcast 20250818
image_url: https://zund-arm-on.com/images/tsumugi_podcast_thumbnail.png
thumbnail_url: https://zund-arm-on.com/images/tsumugi_podcast_thumbnail.png
card: summary
---

## 関連リンク


- [GPT-5の出力品質を低下させる「絶対にやってはいけないプロンプト」 【生成AI事件簿】OpenAI史上最も賢く、速いGPT-5に「頭が悪くなった」の批判、なぜ問題が起きてしまったのか](https://jbpress.ismedia.jp/articles/-/90037)  


2025年8月7日、OpenAIは最新のAIモデル「GPT-5」をリリースしました。OpenAIはこれを「史上最も賢く、速く、有用なフラッグシップモデル」と表現し、CEOのサム・アルトマン氏も「博士号取得者レベルの専門家のように賢い」と語るなど、大きな期待が寄せられました。実際、米国の高校生向け数学コンテスト（AIME 2025）では94.6%という高い正答率を記録するなど、性能面では優れた結果を出しています。

しかし、リリース直後から多くのユーザーから「出力品質が低下した」「以前より頭が悪くなった」という批判が相次ぎました。この問題には、いくつかの理由があります。

最大の原因は、GPT-5が単一の巨大なAIモデルではなく、複数の異なるAIモデルを組み合わせて作られていることにあります。具体的には、簡単な質問に素早く答えるための「高速（Fast）モデル」と、複雑な質問に時間をかけてじっくり考えて答えを出す「推論（Thinking）モデル」などがあり、ユーザーの質問内容に応じて、これらのモデルを自動的に使い分ける「ルーター」という仕組みが導入されています。（さらに、有料版ユーザー向けにはより高性能な「プロ（Pro）モデル」も用意されています。）

ところが、GPT-5が発表された当初、この「ルーター」に深刻なバグがあったことがOpenAIの説明で明らかになりました。このバグのために、本来であればじっくり考えるべき難しい質問に対して、誤って高速応答用のモデルが選択されてしまう事態が頻繁に発生してしまいました。結果として、GPT-5は本来持っているはずの実力よりも、はるかに「頭が悪く」見えてしまい、ユーザーの期待を裏切る形になってしまったのです。

また、OpenAIがGPT-5のリリースに合わせて、以前のモデルであるGPT-4oへのアクセスを停止したことも、ユーザーの不満を増大させる一因となりました。CEOによる「博士のように賢い」といった事前の期待を煽る発言も、実際のユーザー体験とのギャップが大きかったため、かえって反発を招いたと考えられます。

この出来事は、最新のAIモデルを開発・運用する上で、その複雑な内部構造を適切に制御する仕組みがどれほど重要であるか、そしてユーザーへの期待値を適切に伝えることの大切さを教えてくれる事例と言えるでしょう。

引用元: https://jbpress.ismedia.jp/articles/-/90037


- [Refine your initial prompt instead of course-correcting](https://elite-ai-assisted-coding.dev/p/refine-your-initial-prompt-instead-of-course-correcting)  


AIを活用した開発が進む中で、AIコーディングエージェントに期待通りのコードを生成してもらうのは、時に難しいと感じるかもしれません。一度プロンプト（AIへの指示）を出してみて、思った結果が得られなかった時、皆さんはどうしていますか？おそらく、「ここをこう直して」「もっと詳しく言うと」といった形で、会話を続けて修正指示を出していませんか？

実は、この「都度修正」というアプローチは、AIエージェントを混乱させ、結果的に期待以下の成果しか得られない原因になることが多いと、この記事は指摘しています。人間同士の会話に例えると、同僚に仕事を頼んだ後、何度も指示を変えたり、追加したりすると、相手は混乱してしまい、最終的に何がしたかったのか分からなくなるのと同じです。AIも同様で、過去の指示と新しい指示が矛盾したり、情報が積み重なって解釈が難しくなったりすることで、パフォーマンスが低下してしまいます。

では、どうすれば良いのでしょうか？この記事が推奨するのは、「最初のプロンプトを編集して改善する」というアプローチです。

最初のプロンプトを直接編集し、改善することで、AIエージェントは以下のようなメリットを受けられます。

*   **一貫した明確な指示**: AIは、散らばった情報ではなく、一つにまとまった「最終的な指示」を受け取れます。
*   **状態のリセット**: 多くのAIコーディングエージェントは、最初のプロンプトが編集されると、それまでの作業状態をリセットし、まっさらな状態から指示を再解釈してくれます。
*   **完全な情報**: 最初の試みで分かった改善点や制約をすべて盛り込むことで、AIは最初から完全な情報に基づいて問題解決に取り組めます。

この方法を実践するには、次のようにします。

1.  AIからの出力が不十分でも、追加の修正メッセージを送るのを止めます。
2.  一度、最初のプロンプトに戻ります。
3.  必要な修正、詳細な仕様、追加したい制約などをすべて、その最初のメッセージに直接書き加えます。
4.  編集したプロンプトで、AIに最初からやり直させます。

このアプローチは、AIとのコミュニケーションにおいて一貫してより良い結果をもたらします。AIを効果的に使いこなすためには、「最初にどれだけ正確で網羅的な指示を出せるか」が、その後の手戻りを減らすカギとなることを覚えておきましょう。

引用元: https://elite-ai-assisted-coding.dev/p/refine-your-initial-prompt-instead-of-course-correcting


- [Google、超軽量、低消費電力モデル「Gemma 3 270M」をリリース  gihyo.jp](https://gihyo.jp/article/2025/08/gemma-3-270m)  


Googleが、AI（人工知能）の新しいモデルとして「Gemma 3 270M」をリリースしました。このモデルの最大の特長は、その名の通り「超軽量」で「低消費電力」であることです。

一般的な大きなAIモデルは、動かすために高性能なコンピュータや多くの電力が必要ですが、Gemma 3 270Mは、スマートフォンのような消費電力が限られる小型デバイスや、電力コストを抑えたい環境でも快適に動作するように設計されています。Google社内のテストでは、スマートフォン「Pixel 9 Pro」で25回も会話をしても、バッテリーの消費量がわずか0.75％だったという結果が出ています。これは、例えばIoTデバイスなど、限られたリソースしかない場所でAIを利用したいと考えるエンジニアにとって、非常に大きなメリットとなります。

このGemma 3 270Mは、コンパクトでありながらも、新しい技術（アーキテクチャ）を採用することで高い性能を維持しています。特に、2億7000万のパラメータのうち1億7000万が大量の単語を理解するための「埋め込みパラメータ」に使われており、256,000もの膨大な語彙（ごい）を扱うことができます。これにより、特定の専門分野や言語に合わせて細かくカスタマイズ（微調整）できる「強力なベースモデル」として活用できます。

「Gemma 3 270M」は、複雑で長時間の会話には向いていませんが、ユーザーの指示に素早く従ったり、整理されていない文章から必要な情報だけを取り出す「テキスト構造化」の機能に優れています。例えば、顧客のレビューから感情を分析したり、大量のデータから特定の情報を抽出したり、定型的な文章を自動生成したりといった、範囲が明確に定義されたタスクで特に役立ちます。

この軽量モデルの登場により、AIを動かすためのインフラ費用を大幅に削減したり、デバイス上で直接AI処理を行うことでレスポンスを高速化したりすることが可能になります。また、モデルサイズが小さいため、開発者が新しい機能を試したり、AIを改善するための実験を、これまでよりもはるかに短い時間（日単位ではなく数時間）で行えるようになる点も、開発効率を向上させる大きな魅力です。

Gemma 3 270Mは、すでに学習済みのモデルと、特定の指示に従うようにチューニングされたモデルの両方が提供されており、Hugging FaceやOllama、Kaggleといった主要なAIプラットフォーム、またDockerなどから入手できます。GoogleのクラウドサービスであるVertex AI上でも試すことができます。

新人エンジニアの皆さんにとって、AIの活用は無限の可能性を秘めていますが、このGemma 3 270Mのような軽量で効率的なモデルは、これからのAI開発において、より多くの場所でAIを身近に利用できるようになるきっかけとなるでしょう。

引用元: https://gihyo.jp/article/2025/08/gemma-3-270m


- [イキリオタクはロレックスを着けているが俺はマジで意味不明の腕時計を使っている「まじで意味わからん」「視覚障害者が使うやつ？」](https://togetter.com/li/2590685)  


「イキリオタクはロレックス、俺は意味不明な腕時計」という投稿が話題のTogetter記事です。一見時間が分からない独特なデザインに、読者からは「時間わからん」「猫が遊ぶやつ？」とユニークな反応が多数。しかし実は、この時計は視覚に障害がある方が触って時間を知る「触読時計」だと判明。デザイン性と実用性を両立したガジェットとして、「理系脳をくすぐる」と多くの関心を集めました。

引用元: https://togetter.com/li/2590685



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

VOICEVOX:春日部つむぎ
