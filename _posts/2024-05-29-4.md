---
actor_ids:
  - ずんだもん
audio_file_path: https://storage.googleapis.com/podcast-zund-arm-on-tech/audio/株式会社ずんだもん技術室AI放送局_pdocast_20240529.mp3
audio_file_size: 0
date: 2024-05-29 07:00:00 +0900
description: 'AIやテクノロジーに関する記事を紹介  
- 釘宮理恵の5周年特番  
- llm.cでのGPT-2再現  
- 日本語特化のLLM開発についてのELYZAインタビュー'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20240529 ※6/14まで平日試験配信中
---

## 関連リンク

- [【釘宮理恵のいつだって、はじめのいっぽ】くぎっぽ５周年特番〜５愛顧いただき５年で５ざいます！〜](https://www.youtube.com/watch?v=umQPBYzDyQA)  
タイトル: 【釘宮理恵のいつだって、はじめのいっぽ】くぎっぽ５周年特番〜５愛顧いただき５年で５ざいます！〜\n\n要約:\n人気声優の釘宮理恵さんの番組「釘宮理恵のいつだって、はじめのいっぽ」が、5周年を迎えたことを記念した特番のタイトルである。番組では、釘宮さんがさまざまな挑戦や企画に取り組む姿が配信されており、5周年という節目を祝う内容となっているようだ。釘宮さんのファンはもちろん、多くのアニメファンや声優ファンからも注目を集めそうだ。

- ["Reproducing GPT-2 (124M) in llm.c in 90 minutes for $20 · karpathy/llm.c · Discussion #481 · GitHub](https://github.com/karpathy/llm.c/discussions/481")  
タイトル: Reproducing GPT-2 (124M) in llm.c in 90 minutes for $20\n\n要約: \n\nllm.c を用いて、OpenAIが2019年にリリースしたGPT-2の最小モデルであるGPT-2 (124M) を90分間で再現する方法が紹介されています。llm.c は非常に効率的で、最大で約60% のモデルFLOPS 利用率を達成できます。Lambda 社の8X A100 80GB SXM ノード1 つを使用して、約90 分間でこのモデルを再現することができます。コストは約$20 かかります。\n\nこのモデルは、12 層、12 ヘッド、768 次元、124M パラメータのTransformer であり、100 億トークンのFineWeb データセットでトレーニングされます。著者は、FineWeb データセットの保留された検証セットとHellaSwag ベンチマークの両方で、OpenAI によってリリースされたチェックポイントを上回る結果を達成しました。\n\n著者は、Linux x86 64bit Ubuntu 22.04 システムでこの結果を再現する手順を詳しく説明しています。これには、必要なライブラリのインストール、FineWeb データセットのトークン化、llm.c のコンパイル、トレーニングスクリプトの実行が含まれます。\n\nトレーニングの詳細とハイパーパラメータの設定も提供されています。著者は、メモリの問題が発生した場合の対処方法や、バッチサイズを調整してメモリ使用量を削減する方法など、トレーニング中に発生する可能性のある問題について説明しています。\n\nさらに、トレーニングの可視化、トークナイザーの生成、サンプリング、コードの概要についても説明されています。著者はまた、350M パラメータのモデルを再現した結果も共有しており、より大規模なモデルをトレーニングする計画についても言及しています。\n\n最後に、FAQ セクションでは、サンプリング、チャット、マルチノード トレーニング、ビット単位の再現性、fp8 トレーニング、CPU での実行、PyTorch との比較など、さまざまなトピックが取り上げられています。llm.c プロジェクトに貢献した開発者も紹介されています。

- [「RAGはそんなに簡単じゃない」──AIエンジニア主導でLLMを導入すると失敗に？　日本語特化のELYZA・曽根岡CEOに聞く、LLM開発＆活用のいま（1/2 ページ） - ITmedia AI＋](https://www.itmedia.co.jp/aiplus/articles/2405/28/news104.html)  
タイトル: 「RAGはそんなに簡単じゃない」──AIエンジニア主導でLLMを導入すると失敗に？ 日本語特化のELYZA・曽根岡CEOに聞く、LLM開発＆活用のいま\n\n要約: \n\nELYZAの曽根岡侑也CEOが、日本語特化型LLMの開発やKDDI傘下入りなどについてインタビューに応じた。700億パラメータモデルの「ELYZA-japanese-Llama-2-70b」は、ChatGPTが行っているアプローチを参考に、モデル規模の拡大や日本語学習量の増加、RLHFによるチューニングを実施することで性能向上を実現した。開発アプローチは、オープンなLLMモデルをベースに日本語特化のタスク処理を学習させるポストトレーニングを採用し、計算リソースと時間を削減している。また、指示学習データを整備する専門チームを設置し、柔軟な指示対応を可能にしている。700億パラメータモデルはマシンパワーを要するため、公開からAPI提供へと方針転換し、企業向けに安定的に提供することを目指す。KDDI傘下入りは、計算基盤や営業体制、アライアンスの強化につながり、研究開発の加速と事業展開の強化が期待できる。曽根岡CEOは、LLMの世界はマネーゲームや影響力ゲームに変わりつつあると述べ、KDDIとの提携を日本におけるOpenAIとMicrosoftの連合に相当すると位置づけている。

- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
