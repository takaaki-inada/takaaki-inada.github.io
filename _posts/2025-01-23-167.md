---
actor_ids:
  - ずんだもん
audio_file_path: /audio/株式会社ずんだもん技術室AI放送局_podcast_20250123.mp3
audio_file_size: 0
date: 2025-01-23 05:00:00 +0900
description: 'AIやテクノロジーに関する記事を紹介  
GitHub - sauravpanda/BrowserAI: Run local LLMs inside your browser、Hugging Face and FriendliAI partner to supercharge model deployment on the Hub、AIエンジニア devinを使ってみる｜Kan Hatakeyama、オタクやめる原因ランキング第1位『オタクのせい』「マジでこれ」「そんな理由でやめるならオタクではないのでは？」'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20250123
---

## 関連リンク


- [GitHub - sauravpanda/BrowserAI: Run local LLMs inside your browser](https://github.com/sauravpanda/BrowserAI)  


BrowserAIは、ブラウザ内でLLM（大規模言語モデル）を実行するためのオープンソースプロジェクトです。主な特徴は以下の通りです。

*   **プライバシー重視:** 全ての処理がブラウザ内でローカルに行われ、データが外部に送信されることはありません。
*   **コスト効率:** サーバー費用や複雑なインフラが不要です。
*   **オフライン対応:** 初回ダウンロード後、モデルはオフラインで動作します。
*   **高速処理:** WebGPUアクセラレーションにより、ネイティブに近いパフォーマンスを実現します。
*   **開発者フレンドリー:** シンプルなAPIと複数のエンジンサポート、すぐに使えるモデルが提供されています。

BrowserAIは、AIを活用したWebアプリケーションを開発するエンジニア、プライバシーを重視する企業、ブラウザベースのAIを研究する研究者、インフラコストを抑えてAIを試したいユーザーにとって最適です。

主な機能として、ブラウザ内でのAIモデル実行、WebGPUによる高速推論、MLCとTransformersエンジン間のシームレスな切り替え、事前設定済みの人気モデルの利用、テキスト生成などのための使いやすいAPIがあります。

現在、チャットデモが利用可能で、音声チャットデモも開発中です。また、npmやyarnで簡単にインストールでき、基本的なテキスト生成、カスタムパラメータを使用したテキスト生成、システムプロンプト付きのチャット、音声認識、テキスト読み上げなどの例が提供されています。

対応モデルとして、MLCモデル（Llama-3.2-1b-Instructなど）とTransformersモデル（Whisper-tiny-enなど）が利用可能です。今後のロードマップでは、モデル初期化の簡略化、基本的なモニタリング、RAGの実装、開発者ツール統合、RAG機能の強化、高度な監視機能、セキュリティ機能、高度な分析、マルチモデルオーケストレーションなどが予定されています。

このプロジェクトはMITライセンスで提供されており、貢献も歓迎されています。


引用元: https://github.com/sauravpanda/BrowserAI


- [Hugging Face and FriendliAI partner to supercharge model deployment on the Hub](https://huggingface.co/blog/friendliai-partnership)  


Hugging FaceとFriendliAIが提携し、Hugging Face HubでのAIモデルのデプロイを大幅に簡素化しました。FriendliAIの推論インフラがHugging Face Hubに統合され、「Deploy this model」ボタンから直接利用可能になりました。この提携により、開発者は高性能で費用対効果の高い推論インフラに簡単にアクセスできるようになります。FriendliAIは、GPUベースの生成AI推論プロバイダーとして最速と評価されており、連続バッチ処理、ネイティブ量子化、自動スケーリングなどの最先端技術を持っています。これにより、AIモデルのデプロイにおける処理速度の向上、遅延の削減、コスト削減が実現します。Hugging Faceのユーザーは、FriendliAIの技術を活用して、オープンソースまたはカスタムの生成AIモデルを効率的かつ確実にデプロイできます。FriendliAIのDedicated Endpointsでは、NVIDIA H100 GPU上でモデルをデプロイでき、コスト効率を維持しながら高いパフォーマンスを実現します。また、Serverless Endpointsでは、FriendliAIによって最適化されたオープンソースモデルを簡単に利用できます。この提携により、AI開発者はインフラ管理の複雑さから解放され、AIイノベーションに集中できるようになります。


引用元: https://huggingface.co/blog/friendliai-partnership


- [AIエンジニア devinを使ってみる｜Kan Hatakeyama](https://note.com/kan_hatakeyama/n/n939264b3b95b)  


Devinは全自動AIエンジニアで、月額500ドルで利用できます。GitHubやSlackと連携し、ブラウザ上でVS Codeのような環境が提供されます。基本的なコード作成やプッシュは問題なく行えますが、ローカルマシンへのリモート接続は推奨されていません。既存プロジェクトのコードをアップロードしてリファクタリングを指示したところ、問題なく実行されました。ただし、機械学習アルゴリズムの実装は、具体的な指示がないと期待通りの結果にならない場合もあります。作業速度は人間より遅く、1時間程度のタスクを細かく指示するのが良いでしょう。作業履歴が肥大化するため、定期的にセッションを再開する必要があります。DevinはSlackで指示を出し、進捗を確認するスタイルが向いており、スマホからの指示も可能です。パソコンを使わずにプログラミングできるため、隙間時間を活用できます。


引用元: https://note.com/kan_hatakeyama/n/n939264b3b95b


- [オタクやめる原因ランキング第1位『オタクのせい』「マジでこれ」「そんな理由でやめるならオタクではないのでは？」](https://togetter.com/li/2499954)  


この記事では、オタクをやめる原因として「オタクのせい」が1位になっているというSNSの投稿が話題になっています。多くの人がこの意見に共感しており、具体的には、オタク界隈でのマウント、古参気取り、民度の低さなどが原因として挙げられています。
また、一部の意見として、そのような理由でオタクをやめるのは「愛がない」「甘えだ」という厳しい意見もあります。
オタク界隈の人間関係のトラブルや、排他的な雰囲気がオタクをやめる大きな要因になっていることが伺えます。


引用元: https://togetter.com/li/2499954



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
