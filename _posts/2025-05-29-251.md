---
actor_ids:
  - ずんだもん
audio_file_path: https://storage.googleapis.com/podcast-zund-arm-on/audio/株式会社ずんだもん技術室AI放送局_podcast_20250529.mp3
audio_file_size: 0
date: 2025-05-29 05:00:00 +0900
description: 'Large Language Model Agent: A Survey on Methodology, Applications and Challenges、CodeAgents + Structure: A Better Way to Execute Actions、Large Language Models can run tools in your terminal with LLM 0.26'
duration: "00:00"
layout: article
title: 株式会社ずんだもん技術室AI放送局 podcast 20250529
---

## 関連リンク


- [Large Language Model Agent: A Survey on Methodology, Applications and Challenges](https://speakerdeck.com/shunk031/large-language-model-agent-a-survey-on-methodology-applications-and-challenges)  


この資料は、LLM（大規模言語モデル）の能力向上に伴い注目度が高まっている「LLMエージェント」に関する、最新の研究動向や応用例、そして技術的な課題をまとめたサーベイ資料です。LLMエージェントとは、ユーザーからの指示を受け、環境を認識し、自分で考えて行動を計画・実行することで、タスクを自律的に達成するAIシステムのことです。従来のAIシステムが事前に決められた応答をするだけだったのに対し、LLMエージェントはより複雑な問題に対応し、継続的に学習して賢くなる点が異なります。その進化の鍵は、高い推論能力、外部ツールを利用する能力、そして過去の情報を覚えておく記憶力にあります。

このサーベイ資料では、LLMエージェントの研究開発を体系的に整理しています。まず、エージェントをどうやって「構築」するかについて説明されています。これには、エージェントの役割や個性（プロファイル）の設定、過去のやり取りや知識を保存・利用する「メモリ機構」、複雑なタスクをステップごとに分解して解決策を考える「計画能力」、そして計算ツールや外部APIなどを使って実際に行動を起こす「行動実行」といった技術要素が含まれます。

次に、複数のLLMエージェントが協力してより大きなタスクに取り組む「協調」の仕組みが紹介されています。タスクを割り振る中心的なエージェントがいる構成や、エージェント同士が直接話し合って問題を解決する構成など、様々な協力のアーキテクチャが研究されています。

さらに、LLMエージェントが自律的に「進化」していくためのアプローチも解説されています。これは、人間からのフィードバックなしに自分で学習を進めたり、自分の出した結果を「反省」して修正したり、目標達成度を自分で評価して改善したりする方法（自己最適化・自己学習）や、他のエージェントとの協力や競争を通じて互いを高め合う仕組み（マルチエージェント共進化）です。

また、LLMエージェントの性能を適切に評価するための「評価ベンチマーク」の重要性や、現実世界で利用する上で避けられない「課題」にも触れています。特に、悪意のある攻撃からエージェントを守るセキュリティ問題や、個人情報の扱いに関するプライバシー問題、そしてAIが学習データから偏見を学んでしまう可能性といった倫理的な懸念が挙げられており、これらの課題解決に向けた研究も進んでいます。

応用例としては、科学研究における新しい発見の支援、医療現場での診断サポートや仮想的な患者シミュレーション、さらには経済や社会における人間の行動をモデル化してシミュレーションするなど、幅広い分野での活用が期待されています。

このように、LLMエージェントの研究は多岐にわたっており、その構築技術から複数での連携、自律的な賢さの向上、そして実用化に向けた課題解決まで、活発に研究が進められている注目の分野です。このサーベイ資料を読むことで、LLMエージェントの全体像と最新の研究動向を掴むことができるでしょう。

引用元: https://speakerdeck.com/shunk031/large-language-model-agent-a-survey-on-methodology-applications-and-challenges


- [CodeAgents + Structure: A Better Way to Execute Actions](https://huggingface.co/blog/structured-codeagent)  


AI（人工知能）が私たちに代わってタスクをこなす「AI Agent」の開発が進んでいます。これらのAgentが「行動」を起こす方法には、いくつかの進化がありました。

最初は「JSON Agent」という、事前に決められたツール（APIのようなもの）を呼び出すために、決められた形式（JSON）で指示を出す方法が主流でした。これは信頼性は高いのですが、できることが限られていたり、複数のツールを組み合わせて複雑な処理をするのが苦手でした。

次に登場したのが「Code Agent」です。これは、Agent自身がPythonなどのコードを書いて、そのコードの中でツールを呼び出す方法です。これにより、ループや条件分岐など、プログラムの柔軟性を活かして複雑なタスクをこなせるようになりました。例えば、複数の場所の天気情報を取得して平均を計算するなど、より賢いツールの使い方や、状況に応じた柔軟な対応が可能になりました。

しかし、Code Agentには問題がありました。LLM（大規模言語モデル）が出力するテキストからコード部分を正確に読み取る（パースする）のが難しく、形式が少し崩れただけでコードが実行できず、Agentがタスクを完了できなくなるエラーが頻繁に発生したのです。ベンチマークテストでも、最初のステップでパースエラーが起きると、成功率が大きく下がることが確認されました。

そこで、この記事では「Structured CodeAgent」という新しいアプローチが提案されています。これは、Code Agentの「コードを書く柔軟性」と、JSON Agentの「決められた形式（構造）で出力する信頼性」を組み合わせたものです。具体的には、LLMに「思考（thoughts）」と「コード（code）」を**構造化されたJSON形式**で強制的に出力させます。

```json
{
  "thoughts": "タスクをどう進めるか考える内容",
  "code": "実際に実行するPythonコード"
}
```

このようにすることで、Agentは行動を起こす前に「思考」を整理することが促され、さらに、コード部分がJSON内の明確なフィールドとして提供されるため、パースエラーが劇的に減り、コードの実行が信頼できるようになります。

このStructured CodeAgentを様々なテストで試したところ、特に高性能なLLMを使う場合、従来のCode Agentよりも2〜7%性能が向上することがわかりました。これは、パースエラーの減少と、思考プロセスが明示されることによる計画性の向上が主な理由と考えられます。

ただし、注意点もあります。JSON形式の出力や、それに加えてコードを書くという作業は、LLMにとってある種の「負担（Structure Tax）」になることがあります。特に小さなモデルでは、この負担が大きすぎて、かえって性能が落ちてしまうケースも見られました。

したがって、Structured CodeAgentは、高性能なLLMを使って、複雑なタスクをより信頼性高く実行したい場合に非常に有効なアプローチと言えます。簡単なタスクや、小規模なモデルを使う場合は、従来のCode AgentやJSON Agentの方が適しているかもしれません。

この記事は、AI Agentの設計において、「Agentが何を**できるか**」だけでなく、「Agentがどう**考えるべきか**」という視点が重要になっていることを示唆しており、今後のAgent開発のヒントになる研究です。

引用元: https://huggingface.co/blog/structured-codeagent


- [Large Language Models can run tools in your terminal with LLM 0.26](https://simonwillison.net/2025/May/27/llm-tools/)  


OSSで開発されているLLM（大規模言語モデル）を扱うツール「LLM」の最新バージョン 0.26がリリースされました。今回のアップデートで一番大きな機能追加は、「ツールサポート」です。

「ツールサポート」とは、LLMに外部の機能（ツール）を使わせることで、LLM単体では難しかったタスクをこなせるようにする機能です。具体的には、Python関数として定義された様々な機能をツールとしてLLMに提供し、LLMが質問や指示に応じて最適なツールを選んで実行します。例えば、正確な計算をツールに任せたり、外部のデータベースから最新情報を取得したり、Web検索を実行したりといったことが可能になります。

この機能は、OpenAI、Anthropic、Google Geminiといった主要なLLMはもちろん、ローカルで動かせるOllamaのモデルなど、多くのLLMで利用できます。

使い方は簡単で、LLMのコマンドラインツール（CLI）を使う場合は、`--tool` オプションや、一時的にPython関数を渡せる`--functions` オプションを使います。また、PythonライブラリとしてLLMを利用している場合は、新しく追加された `model.chain()` メソッドを通してツール機能を活用できます。

今回のアップデートで、例えばLLMが苦手な数学計算も、計算ツールを使うことで正確に行えるようになりました。また、外部のデータベースに問い合わせるツールを使えば、最新のデータに基づいた回答を生成することも可能です。これは、LLMの能力を外部機能と連携させることで、大きく拡張できることを示しています。

このツールを使った一連の処理は、「エージェント」と呼ばれるAIの応用概念にも繋がる重要な技術です。LLMが自律的にツールを判断・実行し、複雑なタスクを達成する道が開かれます。

今後のLLMツール開発では、ツールを簡単に作る・共有する仕組みの強化や、AIと外部連携の新しい標準規格への対応なども進められる予定です。

今回のLLM 0.26のツールサポート機能は、LLMをより実用的でパワフルなものにするための大きな一歩と言えます。AIを活用したアプリケーション開発に興味のある新人エンジニアの皆さんにとって、ぜひチェックしておきたいアップデート内容です。

引用元: https://simonwillison.net/2025/May/27/llm-tools/



- [お便り投稿フォーム](https://forms.gle/ffg4JTfqdiqK62qf9)

（株式会社ずんだもんは架空の登場組織です）
