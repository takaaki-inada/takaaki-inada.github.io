[
    {
        "page": 0,
        "section": "opening",
        "line": "皆さん、こんにちは！ぼくは、ずんだもんなのだ。今日は、2024年9月25日(水曜日)なのだ。",
        "slide_text": "ずんだもんのAI技術解説！2024年9月25日放送",
        "question_to_guest": "",
        "prompts": "zundamon, a cute green monster, standing in front of a futuristic cityscape, bright colors, anime style, 4k resolution, detailed, intricate"
    },
    {
        "page": 1,
        "section": "opening",
        "line": "水曜日は、ずんだ餅を食べる日なのだ。今日は、最新のAI技術についての記事を紹介するのだ。",
        "slide_text": "最新のAI技術を紹介！ずんだもんと一緒に学ぼう！",
        "question_to_guest": "",
        "prompts": "zundamon, holding a plate of zunda mochi, smiling, futuristic background, vibrant colors, anime style, 4k resolution, detailed, intricate"
    },
    {
        "page": 2,
        "section": "agenda",
        "line": "1つ目の記事は、「Updated production-ready Gemini models, reduced 1.5 Pro pricing, increased rate limits, and more」というタイトルの記事なのだ。2つ目の記事は、「RAGを超えた新技術登場！その名も「セルフ-ルート」」というタイトルの記事なのだ。3つ目の記事は、「話題のグラフRAGにAWSで挑戦しよう！（ラーマインデックスとネプチューンに入門）」というタイトルの記事なのだ。",
        "slide_text": "今日の放送内容：Gemini 1.5、セルフ-ルート、グラフRAG",
        "question_to_guest": "",
        "prompts": "a futuristic calendar, dates and events highlighted, Gemini 1.5, Self-Route, Graph RAG, clean and modern design, bright colors, digital art"
    },
    {
        "page": 3,
        "section": "article1",
        "line": "グーグルが、ジェミニ 1.5シリーズの最新モデルである「ジェミニ-1.5-プロ-002」と「ジェミニ-1.5-フラッシュ-002」をリリースしたのだ。これらのモデルは、グーグル I/Oで発表されたジェミニ 1.5モデルをベースに、性能が大幅に向上しているのだ。主な改善点は、性能向上、価格改定、速度向上、利用制限緩和、安全対策などがあるのだ。ジェミニ-1.5-プロは、最大200万トークンの長いコンテキストを処理できるため、複雑な文書や動画の処理に適しているのだ。今回のアップデートにより、ジェミニ 1.5シリーズはより高速で、コスト効率が高く、使いやすくなったのだ。これらのモデルを活用することで、より高度なAIアプリケーションを開発できるようになるだろう。",
        "slide_text": "Gemini 1.5シリーズ最新モデル！性能向上、価格改定など",
        "question_to_guest": "",
        "prompts": "a futuristic computer screen, code and data displayed, Gemini 1.5 logo, Google logo, AI related graphics, dark background, glowing colors, cyberpunk style, digital art"
    },
    {
        "page": 4,
        "section": "article1",
        "line": "グーグルが、ジェミニ 1.5シリーズの最新モデルである「ジェミニ-1.5-プロ-002」と「ジェミニ-1.5-フラッシュ-002」をリリースしたのだ。これらのモデルは、グーグル I/Oで発表されたジェミニ 1.5モデルをベースに、性能が大幅に向上しているのだ。主な改善点は、性能向上、価格改定、速度向上、利用制限緩和、安全対策などがあるのだ。ジェミニ-1.5-プロは、最大200万トークンの長いコンテキストを処理できるため、複雑な文書や動画の処理に適しているのだ。今回のアップデートにより、ジェミニ 1.5シリーズはより高速で、コスト効率が高く、使いやすくなったのだ。これらのモデルを活用することで、より高度なAIアプリケーションを開発できるようになるだろう。",
        "slide_text": "ジェミニ1.5プロは最大200万トークン処理可能！",
        "question_to_guest": "",
        "prompts": "a futuristic robot, holding a tablet, displaying data and charts, Gemini 1.5 logo, Google logo, AI related graphics, bright background, clean lines, futuristic style, digital art"
    },
    {
        "page": 5,
        "section": "article1",
        "line": "グーグルが、ジェミニ 1.5シリーズの最新モデルである「ジェミニ-1.5-プロ-002」と「ジェミニ-1.5-フラッシュ-002」をリリースしたのだ。これらのモデルは、グーグル I/Oで発表されたジェミニ 1.5モデルをベースに、性能が大幅に向上しているのだ。主な改善点は、性能向上、価格改定、速度向上、利用制限緩和、安全対策などがあるのだ。ジェミニ-1.5-プロは、最大200万トークンの長いコンテキストを処理できるため、複雑な文書や動画の処理に適しているのだ。今回のアップデートにより、ジェミニ 1.5シリーズはより高速で、コスト効率が高く、使いやすくなったのだ。これらのモデルを活用することで、より高度なAIアプリケーションを開発できるようになるだろう。",
        "slide_text": "高速で、コスト効率が高く、使いやすくなったジェミニ1.5",
        "question_to_guest": "",
        "prompts": "a futuristic cityscape, with holographic displays and flying cars, Gemini 1.5 logo, Google logo, AI related graphics, dark background, neon lights, cyberpunk style, digital art"
    },
    {
        "page": 6,
        "section": "comment1",
        "line": "今回のアップデートにより、ジェミニ 1.5シリーズはより高速で、コスト効率が高く、使いやすくなったのだ。",
        "slide_text": "ジェミニ1.5のアップデートで何が変わった？",
        "question_to_guest": "{GUEST}、ジェミニ1.5のアップデートについてどう思いますか？",
        "prompts": "a person sitting at a desk, using a laptop, speech bubble,  'What do you think about Gemini 1.5 updates?', ensuring it is highly visible, modern office, natural light, realistic style, photorealistic",
        "notes": "タイトル: Updated production-ready Gemini models, reduced 1.5 Pro pricing, increased rate limits, and more\n\n\n要約:\nGoogleは、Gemini 1.5シリーズの最新モデルである「Gemini-1.5-Pro-002」と「Gemini-1.5-Flash-002」をリリースしました。これらのモデルは、Google I/Oで発表されたGemini 1.5モデルをベースに、性能が大幅に向上しています。\n\n**主な改善点**は以下の通りです。\n\n* **性能向上**: 数学、長文処理、画像認識などのタスクで、特にGemini-1.5-Proは性能が約7%向上しました。\n* **価格改定**: Gemini-1.5-Proの入力と出力のトークン価格が50%以上削減されました。\n* **速度向上**: 出力速度が2倍、レイテンシが3倍削減されました。\n* **利用制限緩和**: Gemini-1.5-FlashとGemini-1.5-Proの利用制限がそれぞれ2倍と3倍に緩和されました。\n* **安全対策**: デフォルトの安全フィルター設定が変更され、開発者が用途に合わせて設定できるようになりました。\n\n\nこれらのモデルは、Google AI Studio、Gemini API、Vertex AIを通じて利用可能です。特に、Gemini-1.5-Proは最大200万トークンの長いコンテキストを処理できるため、複雑な文書や動画の処理に適しています。\n\n\n今回のアップデートにより、Gemini 1.5シリーズはより高速で、コスト効率が高く、使いやすくなりました。これらのモデルを活用することで、より高度なAIアプリケーションを開発できるようになるでしょう。\n\n\n**制約事項**としては、Gemini-1.5-Proの価格改定は128Kトークン未満のプロンプトに適用される点、安全フィルターはデフォルトで適用されない点などに注意が必要です。詳細な情報は、Gemini APIのドキュメントを参照ください。 \n"
    },
    {
        "page": 7,
        "section": "article2",
        "line": "近年、大規模言語モデル（LLM）は複雑な質問に答えられる一方、計算コストが課題となっているのだ。一方、検索拡張生成（RAG）は低コストで迅速な回答を提供できるが、複雑な処理には不向きなのだ。「セルフ-ルート」は、LLMとRAGの長所を組み合わせた新しい技術で、クエリの内容に応じて、LLMとRAGを使い分けることで、コストと精度のバランスを最適化するのだ。セルフ-ルートの仕組みは、まずRAGでクエリに関連する情報を検索し、RAGだけでは処理できない複雑なクエリの場合、LLMが全文脈を解析し、回答を生成するのだ。クエリに応じてLLMとRAGを自動的に使い分けることで、無駄なくリソースを活用するのだ。セルフ-ルートのメリットは、コスト効率の向上、高精度な回答、柔軟な適応性などがあるのだ。",
        "slide_text": "LLMとRAGの長所を組み合わせた新技術「セルフ-ルート」",
        "question_to_guest": "",
        "prompts": "a network of interconnected nodes and lines, representing data flow, LLM and RAG text labels, bright colors, abstract art, futuristic style, 4k resolution, detailed, intricate"
    },
    {
        "page": 8,
        "section": "article2",
        "line": "近年、大規模言語モデル（LLM）は複雑な質問に答えられる一方、計算コストが課題となっているのだ。一方、検索拡張生成（RAG）は低コストで迅速な回答を提供できるが、複雑な処理には不向きなのだ。「セルフ-ルート」は、LLMとRAGの長所を組み合わせた新しい技術で、クエリの内容に応じて、LLMとRAGを使い分けることで、コストと精度のバランスを最適化するのだ。セルフ-ルートの仕組みは、まずRAGでクエリに関連する情報を検索し、RAGだけでは処理できない複雑なクエリの場合、LLMが全文脈を解析し、回答を生成するのだ。クエリに応じてLLMとRAGを自動的に使い分けることで、無駄なくリソースを活用するのだ。セルフ-ルートのメリットは、コスト効率の向上、高精度な回答、柔軟な適応性などがあるのだ。",
        "slide_text": "セルフ-ルートはクエリに応じてLLMとRAGを使い分ける",
        "question_to_guest": "",
        "prompts": "a brain with interconnected neurons, data flowing through, LLM and RAG text labels, dark background, glowing colors, science fiction style, 4k resolution, detailed, intricate"
    },
    {
        "page": 9,
        "section": "article2",
        "line": "近年、大規模言語モデル（LLM）は複雑な質問に答えられる一方、計算コストが課題となっているのだ。一方、検索拡張生成（RAG）は低コストで迅速な回答を提供できるが、複雑な処理には不向きなのだ。「セルフ-ルート」は、LLMとRAGの長所を組み合わせた新しい技術で、クエリの内容に応じて、LLMとRAGを使い分けることで、コストと精度のバランスを最適化するのだ。セルフ-ルートの仕組みは、まずRAGでクエリに関連する情報を検索し、RAGだけでは処理できない複雑なクエリの場合、LLMが全文脈を解析し、回答を生成するのだ。クエリに応じてLLMとRAGを自動的に使い分けることで、無駄なくリソースを活用するのだ。セルフ-ルートのメリットは、コスト効率の向上、高精度な回答、柔軟な適応性などがあるのだ。",
        "slide_text": "コスト効率向上、高精度な回答、柔軟な適応性がメリット",
        "question_to_guest": "",
        "prompts": "a futuristic robot hand, holding a magnifying glass, examining a complex network of data, LLM and RAG text labels, bright background, clean lines, futuristic style, digital art"
    },
    {
        "page": 10,
        "section": "comment2",
        "line": "セルフ-ルートは、LLMとRAGの利点を融合した画期的な技術であり、今後、様々な分野で活用されることが期待されているのだ。",
        "slide_text": "セルフ-ルートは様々な分野で活用が期待される！",
        "question_to_guest": "{GUEST}、セルフ-ルートの将来性についてどう思いますか？",
        "prompts": "a futuristic cityscape, with holographic projections of data and information, speech bubble, 'What do you think about the future of Self-Route?', ensuring it is highly visible, dark background, neon lights, cyberpunk style, digital art",
        "notes": "タイトル: RAGを超えた新技術登場！その名も「Self-Route」\n\n\n要約:\n近年、大規模言語モデル（LLM）は複雑な質問に答えられる一方、計算コストが課題となっています。一方、検索拡張生成（RAG）は低コストで迅速な回答を提供できますが、複雑な処理には不向きです。\n\n「Self-Route」は、LLMとRAGの長所を組み合わせた新しい技術です。クエリの内容に応じて、LLMとRAGを使い分けることで、コストと精度のバランスを最適化します。\n\n**Self-Routeの仕組み**\n1. **RAG-and-Routeステップ**: まず、RAGでクエリに関連する情報を検索します。\n2. **長文コンテキスト予測ステップ**: RAGだけでは処理できない複雑なクエリの場合、LLMが全文脈を解析し、回答を生成します。\n3. **動的ルーティング**: クエリに応じてLLMとRAGを自動的に使い分けることで、無駄なくリソースを活用します。\n\n**Self-Routeのメリット**\n- コスト効率の向上：RAGで処理できるクエリはRAGで処理し、LLMの使用を最小限に抑えることで、コストを削減できます。\n- 高精度な回答：複雑なクエリにはLLMが対応するため、精度の高い回答を得られます。\n- 柔軟な適応性：クエリに応じて適切な技術を選択することで、幅広い種類のクエリに対応できます。\n\n\n**Self-Routeの制約**\n- 多段階推論が必要な質問、曖昧な質問、長くて複雑な質問、暗黙的な理解を要する質問など、RAGだけでは処理できないクエリには限界があります。\n\n\n**今後の課題**\n- RAGの多段階推論能力の向上\n- 実際のデータセットを用いた評価\n\n\nSelf-Routeは、LLMとRAGの利点を融合した画期的な技術であり、今後、様々な分野で活用されることが期待されています。新人エンジニアの皆さんも、この新しい技術に注目してみてはいかがでしょうか。 \n"
    },
    {
        "page": 11,
        "section": "article3",
        "line": "近年、LLM（大規模言語モデル）において、RAG（リトゥリーヴァル オーグメンティド ジェネレイション）という検索結果を組み合わせる技術が注目されているのだ。従来のRAGは、ドキュメントをベクトルに変換して検索していたが、マイクロソフトが公開したグラフRAGは、ドキュメントを「グラフ」として保存することで検索精度向上を目指しているのだ。グラフとは、ノードとエッジで関係性を表すもので、グラフRAGでは知識グラフを扱うことが多いのだ。知識グラフを保存するにはグラフDBが必要で、AWSではAmazon ネプチューンが利用できるのだ。一方、RAGの実装にはラングチェインなどのフレームワークが用いられるが、ラーマインデックスは特にRAGに特化したフレームワークなのだ。　今回は、LlamaIndexを使ってAmazon Neptune上でGraphRAGを試す方法を紹介しているのだ。　、。",
        "slide_text": "グラフRAGとは？知識グラフで検索精度向上！",
        "question_to_guest": "",
        "prompts": "a complex network of interconnected nodes and edges, representing a knowledge graph, AWS logo, Amazon Neptune logo, LlamaIndex logo, bright colors, abstract art, futuristic style, 4k resolution, detailed, intricate"
    },
    {
        "page": 12,
        "section": "article3",
        "line": "近年、LLM（大規模言語モデル）において、RAG（リトゥリーヴァル オーグメンティド ジェネレイション）という検索結果を組み合わせる技術が注目されているのだ。従来のRAGは、ドキュメントをベクトルに変換して検索していたが、マイクロソフトが公開したグラフRAGは、ドキュメントを「グラフ」として保存することで検索精度向上を目指しているのだ。グラフとは、ノードとエッジで関係性を表すもので、グラフRAGでは知識グラフを扱うことが多いのだ。知識グラフを保存するにはグラフDBが必要で、AWSではAmazon ネプチューンが利用できるのだ。一方、RAGの実装にはラングチェインなどのフレームワークが用いられるが、ラーマインデックスは特にRAGに特化したフレームワークなのだ。　今回は、LlamaIndexを使ってAmazon Neptune上でGraphRAGを試す方法を紹介しているのだ。　、。",
        "slide_text": "グラフDBはAmazon Neptune、フレームワークはLlamaIndex",
        "question_to_guest": "",
        "prompts": "a person working on a laptop, code displayed on the screen, knowledge graph visualized, AWS logo, Amazon Neptune logo, LlamaIndex logo, modern office, natural light, realistic style, photorealistic"
    },
    {
        "page": 13,
        "section": "article3",
        "line": "近年、LLM（大規模言語モデル）において、RAG（リトゥリーヴァル オーグメンティド ジェネレイション）という検索結果を組み合わせる技術が注目されているのだ。従来のRAGは、ドキュメントをベクトルに変換して検索していたが、マイクロソフトが公開したグラフRAGは、ドキュメントを「グラフ」として保存することで検索精度向上を目指しているのだ。グラフとは、ノードとエッジで関係性を表すもので、グラフRAGでは知識グラフを扱うことが多いのだ。知識グラフを保存するにはグラフDBが必要で、AWSではAmazon ネプチューンが利用できるのだ。一方、RAGの実装にはラングチェインなどのフレームワークが用いられるが、ラーマインデックスは特にRAGに特化したフレームワークなのだ。　今回は、LlamaIndexを使ってAmazon Neptune上でGraphRAGを試す方法を紹介しているのだ。　、。",
        "slide_text": "グラフRAGは従来のRAGより高度なユースケースに対応",
        "question_to_guest": "",
        "prompts": "a futuristic data center, with servers and network equipment, knowledge graph visualized on a large screen, AWS logo, Amazon Neptune logo, LlamaIndex logo, dark background, glowing lights, cyberpunk style, digital art"
    },
    {
        "page": 14,
        "section": "comment3",
        "line": "グラフRAGは、従来のRAGでは難しかったユースケースで効果を発揮する可能性を秘めているのだ。",
        "slide_text": "グラフRAGの将来性！",
        "question_to_guest": "{GUEST}、グラフRAGについてどう思いますか？",
        "prompts": "a group of people brainstorming around a table, knowledge graph visualized on a whiteboard, speech bubble, 'What do you think about Graph RAG?', ensuring it is highly visible, modern office, natural light, realistic style, photorealistic",
        "notes": "タイトル: 話題のGraphRAGにAWSで挑戦しよう！（LlamaIndexとNeptuneに入門）\n\n\n要約:\n近年、LLM（大規模言語モデル）において、RAG（Retrieval Augmented Generation）という検索結果を組み合わせる技術が注目されています。従来のRAGは、ドキュメントをベクトルに変換して検索していましたが、Microsoftが公開したGraphRAGは、ドキュメントを「グラフ」として保存することで検索精度向上を目指しています。\n\nグラフとは、ノードとエッジで関係性を表すもので、GraphRAGでは知識グラフを扱うことが多いです。知識グラフを保存するにはグラフDBが必要で、AWSではAmazon Neptuneが利用できます。Neptuneは、データベース機能に加え、大規模グラフを高速に分析できるNeptune Analyticsも提供しています。\n\n一方、RAGの実装にはLangChainなどのフレームワークが用いられますが、LlamaIndexは特にRAGに特化したフレームワークです。今回は、LlamaIndexを使ってAmazon Neptune上でGraphRAGを試す方法を紹介します。\n\n**GraphRAGを試すための制約**\n\nAWSのサービスを利用するため、AWSアカウントが必要です。また、Amazon Bedrockのモデルを有効化し、Neptune Databaseを構築する必要があります。構築には無料利用枠のインスタンスを利用可能ですが、検証後は不要なリソースを削除する必要があります。\n\n**GraphRAGの試しかた**\n\n1. AWSアカウントとAmazon Bedrockのモデルを有効化します。\n2. Amazon Neptune Databaseを作成します。\n3. JupyterLab上で、LlamaIndexのサンプルコードを実行します。\n4. 対象のドキュメントをPDF形式でダウンロードし、Neptune Databaseに登録します。\n5. Neptune Graph Explorerで、グラフを可視化して確認します。\n6. サンプルコードでクエリを実行し、GraphRAGの動作を確認します。\n\n\n今回の記事では、AWSのサービスを使ってGraphRAGを体験できる手順を紹介しました。GraphRAGは、従来のRAGでは難しかったユースケースで効果を発揮する可能性を秘めています。生成AIアプリケーションの開発に携わるエンジニアは、ぜひGraphRAGやグラフDBについて学習し、今後の開発に役立ててください。 \n"
    },
    {
        "page": 15,
        "section": "closing",
        "line": "今日の放送は以上なのだ。",
        "slide_text": "本日の放送、おつかれさまでした！",
        "question_to_guest": "",
        "prompts": "zundamon, waving goodbye, standing in front of a sunset, warm colors, anime style, 4k resolution, detailed, intricate"
    },
    {
        "page": 16,
        "section": "closing",
        "line": "今日は、ジェミニ 1.5シリーズの最新モデル、セルフ-ルート、グラフRAGについて紹介したのだ。AI技術は日進月歩で進化しているのだ。これからも、最新のAI技術について情報を発信していくので、楽しみにしていてください。番組への感想は、ずんだもん技術室AI放送局のホームページまで、ぜひ送ってください。それでは、また次回お会いしましょう。",
        "slide_text": "AI技術は進化し続ける！次回も見てね！",
        "question_to_guest": "",
        "prompts": "zundamon, smiling, holding a microphone, standing in front of a futuristic audience, bright colors, anime style, 4k resolution, detailed, intricate"
    }
]